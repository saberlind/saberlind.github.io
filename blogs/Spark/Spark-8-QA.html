<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark面试题 | Awaken&#39;s blogs</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/wtw.jpg">
    <meta name="description" content="Awaken's blogs">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.dfeb017d.css" as="style"><link rel="preload" href="/assets/js/app.03646987.js" as="script"><link rel="preload" href="/assets/js/3.a8134f0a.js" as="script"><link rel="preload" href="/assets/js/1.a394b090.js" as="script"><link rel="preload" href="/assets/js/102.48df0133.js" as="script"><link rel="prefetch" href="/assets/js/10.0aed174e.js"><link rel="prefetch" href="/assets/js/100.02914097.js"><link rel="prefetch" href="/assets/js/101.95f6c81a.js"><link rel="prefetch" href="/assets/js/103.200f5642.js"><link rel="prefetch" href="/assets/js/104.080c910a.js"><link rel="prefetch" href="/assets/js/105.943605b5.js"><link rel="prefetch" href="/assets/js/106.55d2b7c0.js"><link rel="prefetch" href="/assets/js/107.dbf3105f.js"><link rel="prefetch" href="/assets/js/108.3a747b28.js"><link rel="prefetch" href="/assets/js/109.e9453b81.js"><link rel="prefetch" href="/assets/js/11.38bfbf06.js"><link rel="prefetch" href="/assets/js/110.15ce5269.js"><link rel="prefetch" href="/assets/js/111.e2a2b309.js"><link rel="prefetch" href="/assets/js/112.83e22ec5.js"><link rel="prefetch" href="/assets/js/113.4c53e21e.js"><link rel="prefetch" href="/assets/js/114.3fdb14e5.js"><link rel="prefetch" href="/assets/js/115.24fd8b47.js"><link rel="prefetch" href="/assets/js/116.fa4af7d3.js"><link rel="prefetch" href="/assets/js/117.c5bc84c0.js"><link rel="prefetch" href="/assets/js/118.6ad3d598.js"><link rel="prefetch" href="/assets/js/119.fd9eb4ba.js"><link rel="prefetch" href="/assets/js/12.088628ed.js"><link rel="prefetch" href="/assets/js/120.36824fa8.js"><link rel="prefetch" href="/assets/js/121.6edd4478.js"><link rel="prefetch" href="/assets/js/122.228b556b.js"><link rel="prefetch" href="/assets/js/123.a51f4b7b.js"><link rel="prefetch" href="/assets/js/124.32fa9997.js"><link rel="prefetch" href="/assets/js/125.29138718.js"><link rel="prefetch" href="/assets/js/126.bfeae404.js"><link rel="prefetch" href="/assets/js/127.bbe78f94.js"><link rel="prefetch" href="/assets/js/128.6a9fd1ab.js"><link rel="prefetch" href="/assets/js/129.a26030ce.js"><link rel="prefetch" href="/assets/js/13.50987128.js"><link rel="prefetch" href="/assets/js/130.5a29c5e3.js"><link rel="prefetch" href="/assets/js/131.83dd6a40.js"><link rel="prefetch" href="/assets/js/132.31961e3b.js"><link rel="prefetch" href="/assets/js/133.12379872.js"><link rel="prefetch" href="/assets/js/134.2f630670.js"><link rel="prefetch" href="/assets/js/135.516248e9.js"><link rel="prefetch" href="/assets/js/136.c9fb3676.js"><link rel="prefetch" href="/assets/js/137.0d58b935.js"><link rel="prefetch" href="/assets/js/138.106b8051.js"><link rel="prefetch" href="/assets/js/139.3a4177bb.js"><link rel="prefetch" href="/assets/js/14.d98ee26c.js"><link rel="prefetch" href="/assets/js/140.cf104912.js"><link rel="prefetch" href="/assets/js/141.917d5919.js"><link rel="prefetch" href="/assets/js/142.d0c49c8f.js"><link rel="prefetch" href="/assets/js/143.e5647fcb.js"><link rel="prefetch" href="/assets/js/144.42362cf2.js"><link rel="prefetch" href="/assets/js/145.9f603000.js"><link rel="prefetch" href="/assets/js/146.9b30f1cd.js"><link rel="prefetch" href="/assets/js/147.00acaf92.js"><link rel="prefetch" href="/assets/js/148.0c69b088.js"><link rel="prefetch" href="/assets/js/149.2f219e93.js"><link rel="prefetch" href="/assets/js/15.d642d730.js"><link rel="prefetch" href="/assets/js/150.375474c6.js"><link rel="prefetch" href="/assets/js/151.66a582d5.js"><link rel="prefetch" href="/assets/js/152.1665682e.js"><link rel="prefetch" href="/assets/js/153.5a97da8e.js"><link rel="prefetch" href="/assets/js/154.3b76b78d.js"><link rel="prefetch" href="/assets/js/155.c92a6111.js"><link rel="prefetch" href="/assets/js/156.a247cd62.js"><link rel="prefetch" href="/assets/js/16.172153f0.js"><link rel="prefetch" href="/assets/js/17.ca69a778.js"><link rel="prefetch" href="/assets/js/18.3be7ba8f.js"><link rel="prefetch" href="/assets/js/19.4f66b5d8.js"><link rel="prefetch" href="/assets/js/20.8f0cd2cb.js"><link rel="prefetch" href="/assets/js/21.20681ba8.js"><link rel="prefetch" href="/assets/js/22.53b5baea.js"><link rel="prefetch" href="/assets/js/23.8b55cb0e.js"><link rel="prefetch" href="/assets/js/24.3328372c.js"><link rel="prefetch" href="/assets/js/25.ec23edd8.js"><link rel="prefetch" href="/assets/js/26.76e210a5.js"><link rel="prefetch" href="/assets/js/27.29b300ec.js"><link rel="prefetch" href="/assets/js/28.682ad17a.js"><link rel="prefetch" href="/assets/js/29.e1db4b89.js"><link rel="prefetch" href="/assets/js/30.796c2e36.js"><link rel="prefetch" href="/assets/js/31.912d2fae.js"><link rel="prefetch" href="/assets/js/32.60a749df.js"><link rel="prefetch" href="/assets/js/33.d87002b1.js"><link rel="prefetch" href="/assets/js/34.40a8b3f6.js"><link rel="prefetch" href="/assets/js/35.670ac802.js"><link rel="prefetch" href="/assets/js/36.e9f74d88.js"><link rel="prefetch" href="/assets/js/37.6d6f43d0.js"><link rel="prefetch" href="/assets/js/38.ef496ae1.js"><link rel="prefetch" href="/assets/js/39.fc216f43.js"><link rel="prefetch" href="/assets/js/4.01043612.js"><link rel="prefetch" href="/assets/js/40.3bd13625.js"><link rel="prefetch" href="/assets/js/41.3f331b95.js"><link rel="prefetch" href="/assets/js/42.3b26f469.js"><link rel="prefetch" href="/assets/js/43.744d42da.js"><link rel="prefetch" href="/assets/js/44.8b9a8908.js"><link rel="prefetch" href="/assets/js/45.19c8ed8e.js"><link rel="prefetch" href="/assets/js/46.29927647.js"><link rel="prefetch" href="/assets/js/47.e4f53070.js"><link rel="prefetch" href="/assets/js/48.108272d7.js"><link rel="prefetch" href="/assets/js/49.c1e35862.js"><link rel="prefetch" href="/assets/js/5.80b3dd9d.js"><link rel="prefetch" href="/assets/js/50.8af695e4.js"><link rel="prefetch" href="/assets/js/51.33ef3df2.js"><link rel="prefetch" href="/assets/js/52.58bb8f89.js"><link rel="prefetch" href="/assets/js/53.4c6b5e8a.js"><link rel="prefetch" href="/assets/js/54.5763a55d.js"><link rel="prefetch" href="/assets/js/55.15295e7d.js"><link rel="prefetch" href="/assets/js/56.61c94966.js"><link rel="prefetch" href="/assets/js/57.46def60f.js"><link rel="prefetch" href="/assets/js/58.119434b5.js"><link rel="prefetch" href="/assets/js/59.f712c9c5.js"><link rel="prefetch" href="/assets/js/6.a702a72d.js"><link rel="prefetch" href="/assets/js/60.2072c323.js"><link rel="prefetch" href="/assets/js/61.09518814.js"><link rel="prefetch" href="/assets/js/62.35a494eb.js"><link rel="prefetch" href="/assets/js/63.d31876c6.js"><link rel="prefetch" href="/assets/js/64.8f68a737.js"><link rel="prefetch" href="/assets/js/65.6b094c4b.js"><link rel="prefetch" href="/assets/js/66.7c5599cd.js"><link rel="prefetch" href="/assets/js/67.625cd24c.js"><link rel="prefetch" href="/assets/js/68.371f4f22.js"><link rel="prefetch" href="/assets/js/69.c45293ee.js"><link rel="prefetch" href="/assets/js/7.076cee01.js"><link rel="prefetch" href="/assets/js/70.7a22bd02.js"><link rel="prefetch" href="/assets/js/71.729213ff.js"><link rel="prefetch" href="/assets/js/72.0f07bfbc.js"><link rel="prefetch" href="/assets/js/73.4d0355d4.js"><link rel="prefetch" href="/assets/js/74.0f47f56e.js"><link rel="prefetch" href="/assets/js/75.d11ecf15.js"><link rel="prefetch" href="/assets/js/76.727f8a27.js"><link rel="prefetch" href="/assets/js/77.f71a8653.js"><link rel="prefetch" href="/assets/js/78.cb1a43c1.js"><link rel="prefetch" href="/assets/js/79.9e83573b.js"><link rel="prefetch" href="/assets/js/8.d5f02645.js"><link rel="prefetch" href="/assets/js/80.ffafa3ff.js"><link rel="prefetch" href="/assets/js/81.30de8c9b.js"><link rel="prefetch" href="/assets/js/82.4cb0a9a6.js"><link rel="prefetch" href="/assets/js/83.6bf25e9a.js"><link rel="prefetch" href="/assets/js/84.984a50d8.js"><link rel="prefetch" href="/assets/js/85.81009c16.js"><link rel="prefetch" href="/assets/js/86.3325dd7c.js"><link rel="prefetch" href="/assets/js/87.d9dea564.js"><link rel="prefetch" href="/assets/js/88.620d3c46.js"><link rel="prefetch" href="/assets/js/89.414375c4.js"><link rel="prefetch" href="/assets/js/9.f9048235.js"><link rel="prefetch" href="/assets/js/90.07be05fd.js"><link rel="prefetch" href="/assets/js/91.5b6132ee.js"><link rel="prefetch" href="/assets/js/92.efd68e29.js"><link rel="prefetch" href="/assets/js/93.4e37aebc.js"><link rel="prefetch" href="/assets/js/94.a306e6d9.js"><link rel="prefetch" href="/assets/js/95.ddbaa2e0.js"><link rel="prefetch" href="/assets/js/96.b4c98c12.js"><link rel="prefetch" href="/assets/js/97.3bca48ba.js"><link rel="prefetch" href="/assets/js/98.f52f497a.js"><link rel="prefetch" href="/assets/js/99.588f017d.js">
    <link rel="stylesheet" href="/assets/css/0.styles.dfeb017d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Awaken's blogs</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>Awaken's blogs</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>Awaken</span>
            
          <!---->
          2024
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/wtw.jpg" alt="Awaken's blogs" class="logo"> <span class="site-name">Awaken's blogs</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/BigData/" class="nav-link"><i class="undefined"></i>
  BigData
</a></li><li class="dropdown-item"><!----> <a href="/categories/DAG/" class="nav-link"><i class="undefined"></i>
  DAG
</a></li><li class="dropdown-item"><!----> <a href="/categories/ES/" class="nav-link"><i class="undefined"></i>
  ES
</a></li><li class="dropdown-item"><!----> <a href="/categories/Flink/" class="nav-link"><i class="undefined"></i>
  Flink
</a></li><li class="dropdown-item"><!----> <a href="/categories/JUC/" class="nav-link"><i class="undefined"></i>
  JUC
</a></li><li class="dropdown-item"><!----> <a href="/categories/JVM/" class="nav-link"><i class="undefined"></i>
  JVM
</a></li><li class="dropdown-item"><!----> <a href="/categories/JavaSE/" class="nav-link"><i class="undefined"></i>
  JavaSE
</a></li><li class="dropdown-item"><!----> <a href="/categories/Java/" class="nav-link"><i class="undefined"></i>
  Java
</a></li><li class="dropdown-item"><!----> <a href="/categories/LeetCode/" class="nav-link"><i class="undefined"></i>
  LeetCode
</a></li><li class="dropdown-item"><!----> <a href="/categories/LINUX/" class="nav-link"><i class="undefined"></i>
  LINUX
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/DB/" class="nav-link"><i class="undefined"></i>
  DB
</a></li><li class="dropdown-item"><!----> <a href="/categories/SSM/" class="nav-link"><i class="undefined"></i>
  SSM
</a></li><li class="dropdown-item"><!----> <a href="/categories/RK/" class="nav-link"><i class="undefined"></i>
  RK
</a></li><li class="dropdown-item"><!----> <a href="/categories/MQ/" class="nav-link"><i class="undefined"></i>
  MQ
</a></li><li class="dropdown-item"><!----> <a href="/categories/redis/" class="nav-link"><i class="undefined"></i>
  redis
</a></li><li class="dropdown-item"><!----> <a href="/categories/Spark/" class="nav-link"><i class="undefined"></i>
  Spark
</a></li><li class="dropdown-item"><!----> <a href="/categories/SpringBoot/" class="nav-link"><i class="undefined"></i>
  SpringBoot
</a></li><li class="dropdown-item"><!----> <a href="/categories/projects/" class="nav-link"><i class="undefined"></i>
  projects
</a></li><li class="dropdown-item"><!----> <a href="/categories/SpringCloud/" class="nav-link"><i class="undefined"></i>
  SpringCloud
</a></li><li class="dropdown-item"><!----> <a href="/categories/project1/" class="nav-link"><i class="undefined"></i>
  project1
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tools/" class="nav-link"><i class="undefined"></i>
  Tools
</a></li><li class="dropdown-item"><!----> <a href="/categories/arthas/" class="nav-link"><i class="undefined"></i>
  arthas
</a></li><li class="dropdown-item"><!----> <a href="/categories/deploy/" class="nav-link"><i class="undefined"></i>
  deploy
</a></li><li class="dropdown-item"><!----> <a href="/categories/k8s/" class="nav-link"><i class="undefined"></i>
  k8s
</a></li><li class="dropdown-item"><!----> <a href="/categories/mall/" class="nav-link"><i class="undefined"></i>
  mall
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/others/" class="nav-link"><i class="undefined"></i>
  others
</a></li><li class="dropdown-item"><!----> <a href="/categories/Spring/" class="nav-link"><i class="undefined"></i>
  Spring
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Docs
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/docs/documents/" class="nav-link"><i class="undefined"></i>
  documents
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/recoluan" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/wtw.jpg" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    Awaken
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>144</h3> <h6 data-v-828910c6>Articles</h6></div> <div data-v-828910c6><h3 data-v-828910c6>78</h3> <h6 data-v-828910c6>Tags</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/BigData/" class="nav-link"><i class="undefined"></i>
  BigData
</a></li><li class="dropdown-item"><!----> <a href="/categories/DAG/" class="nav-link"><i class="undefined"></i>
  DAG
</a></li><li class="dropdown-item"><!----> <a href="/categories/ES/" class="nav-link"><i class="undefined"></i>
  ES
</a></li><li class="dropdown-item"><!----> <a href="/categories/Flink/" class="nav-link"><i class="undefined"></i>
  Flink
</a></li><li class="dropdown-item"><!----> <a href="/categories/JUC/" class="nav-link"><i class="undefined"></i>
  JUC
</a></li><li class="dropdown-item"><!----> <a href="/categories/JVM/" class="nav-link"><i class="undefined"></i>
  JVM
</a></li><li class="dropdown-item"><!----> <a href="/categories/JavaSE/" class="nav-link"><i class="undefined"></i>
  JavaSE
</a></li><li class="dropdown-item"><!----> <a href="/categories/Java/" class="nav-link"><i class="undefined"></i>
  Java
</a></li><li class="dropdown-item"><!----> <a href="/categories/LeetCode/" class="nav-link"><i class="undefined"></i>
  LeetCode
</a></li><li class="dropdown-item"><!----> <a href="/categories/LINUX/" class="nav-link"><i class="undefined"></i>
  LINUX
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/DB/" class="nav-link"><i class="undefined"></i>
  DB
</a></li><li class="dropdown-item"><!----> <a href="/categories/SSM/" class="nav-link"><i class="undefined"></i>
  SSM
</a></li><li class="dropdown-item"><!----> <a href="/categories/RK/" class="nav-link"><i class="undefined"></i>
  RK
</a></li><li class="dropdown-item"><!----> <a href="/categories/MQ/" class="nav-link"><i class="undefined"></i>
  MQ
</a></li><li class="dropdown-item"><!----> <a href="/categories/redis/" class="nav-link"><i class="undefined"></i>
  redis
</a></li><li class="dropdown-item"><!----> <a href="/categories/Spark/" class="nav-link"><i class="undefined"></i>
  Spark
</a></li><li class="dropdown-item"><!----> <a href="/categories/SpringBoot/" class="nav-link"><i class="undefined"></i>
  SpringBoot
</a></li><li class="dropdown-item"><!----> <a href="/categories/projects/" class="nav-link"><i class="undefined"></i>
  projects
</a></li><li class="dropdown-item"><!----> <a href="/categories/SpringCloud/" class="nav-link"><i class="undefined"></i>
  SpringCloud
</a></li><li class="dropdown-item"><!----> <a href="/categories/project1/" class="nav-link"><i class="undefined"></i>
  project1
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tools/" class="nav-link"><i class="undefined"></i>
  Tools
</a></li><li class="dropdown-item"><!----> <a href="/categories/arthas/" class="nav-link"><i class="undefined"></i>
  arthas
</a></li><li class="dropdown-item"><!----> <a href="/categories/deploy/" class="nav-link"><i class="undefined"></i>
  deploy
</a></li><li class="dropdown-item"><!----> <a href="/categories/k8s/" class="nav-link"><i class="undefined"></i>
  k8s
</a></li><li class="dropdown-item"><!----> <a href="/categories/mall/" class="nav-link"><i class="undefined"></i>
  mall
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/others/" class="nav-link"><i class="undefined"></i>
  others
</a></li><li class="dropdown-item"><!----> <a href="/categories/Spring/" class="nav-link"><i class="undefined"></i>
  Spring
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Docs
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/docs/documents/" class="nav-link"><i class="undefined"></i>
  documents
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/recoluan" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Spark面试题</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>Awaken</span>
            
          <!---->
          2024
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">Spark面试题</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>Awaken</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>7/20/2023</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>Problem</span></i></div></div> <div class="theme-reco-content content__default"><h2 id="_1-spark面试题"><a href="#_1-spark面试题" class="header-anchor">#</a> 1. Spark面试题</h2> <h3 id="_1-spark负责什么事情-为什么要设计自己的调度器"><a href="#_1-spark负责什么事情-为什么要设计自己的调度器" class="header-anchor">#</a> 1.Spark负责什么事情?为什么要设计自己的调度器?</h3> <p>Spark是基于内存的快速、通用、可扩展的大数据分析计算引擎</p> <p>Hadoop的Yarn框架比Spark框架诞生的晚，所以Spark自己也设计了一套资源调度框架。</p> <h3 id="_2-spark中核心集群角色哪些-分别说明其主要功能。"><a href="#_2-spark中核心集群角色哪些-分别说明其主要功能。" class="header-anchor">#</a> 2.Spark中核心集群角色哪些？分别说明其主要功能。</h3> <h4 id="_2-1-master-和-worker-集群资源管理"><a href="#_2-1-master-和-worker-集群资源管理" class="header-anchor">#</a> 2.1 Master 和 Worker 集群资源管理</h4> <p>Master：</p> <p>Spark 特有资源调度系统的 Leader。掌管着整个集群的资源信息，<strong>类似于 Yarn 框架中的 ResourceManager</strong></p> <p>Worker：</p> <p>Spark 特有资源调度系统的 Slave，有多个。每个 Slave 掌管着所在节点的资源信息，<strong>类似于 Yarn 框架中的 NodeManager</strong></p> <p>​	Master和Worker是Spark的守护进程、集群资源管理者，即Spark在特定模式(Standalone)下正常运行必须要有的后台常驻进程。</p> <h4 id="_2-2-driver-和-executor-任务的管理者"><a href="#_2-2-driver-和-executor-任务的管理者" class="header-anchor">#</a> 2.2 Driver 和 Executor 任务的管理者</h4> <p>Driver：</p> <p>Spark Shell 中预加载的一个叫做 sc 的 SparkContext对象</p> <p>1）把用户程序转为作业（Job）</p> <p>2）跟踪 Executor 的任务运行状况</p> <p>3）为执行器节点调度任务</p> <p>4）UI 展示应用运行状况</p> <p>Executor：</p> <p>负责执行 Spark 的具体任务</p> <p>Driver和Executor是临时程序，当有具体任务提交到Spark集群才会开启的程序。</p> <h3 id="_3-如何提交一个spark任务-主要参数有哪些"><a href="#_3-如何提交一个spark任务-主要参数有哪些" class="header-anchor">#</a> 3.如何提交一个Spark任务?主要参数有哪些?</h3> <p>提交Spark任务的主要步骤包括：</p> <ol><li>构建SparkContext</li> <li>准备Spark应用程序和任务所需的数据</li> <li>调用相应的API</li> <li>处理任务结果。</li></ol> <p>提交任务参数：</p> <ol><li>作业名称</li> <li>应用程序名称</li> <li>资源要求，包括CPU、内存、磁盘空间等</li> <li>作业类型</li> <li>作业参数</li> <li>作业环境变量</li> <li>提交者的ID</li> <li>提交时间</li></ol> <h3 id="_4-简述你所理解的不同运行模式之间的区别。"><a href="#_4-简述你所理解的不同运行模式之间的区别。" class="header-anchor">#</a> 4.简述你所理解的不同运行模式之间的区别。</h3> <p>Local：</p> <p>Local 模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。</p> <p>Standalone：</p> <p>Standalone模式是Spark自带的资源调度引擎，构建一个由Master + Worker构成的Spark集群，Spark运行在集群中。</p> <p>Yarn：</p> <p>Spark有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。</p> <p>yarn-client：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出。</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
--class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--master <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode client <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span class="token punctuation">\</span>
<span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>yarn-cluster：Driver程序运行在由ResourceManager启动的APPMaster，适用于生产环境。</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
--class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--master <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode cluster <span class="token punctuation">\</span>
./examples/jars/spark-examples_2.12-3.0.0.jar <span class="token punctuation">\</span>
<span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h3 id="_5-spark的端口号总结"><a href="#_5-spark的端口号总结" class="header-anchor">#</a> 5.Spark的端口号总结</h3> <p>1）Spark查看当前Spark-shell运行任务情况端口号：4040</p> <p>2）Spark Master内部通信服务端口号：7077	（类比于yarn的8032(RM和NM的内部通信)端口）</p> <p>3）Spark Standalone模式Master Web端口号：8080（类比于Hadoop YARN任务运行情况查看端口号：8088）</p> <p>4）Spark历史服务器端口号：18080（类比于Hadoop历史服务器端口号：19888）</p> <h3 id="_6-什么是rdd"><a href="#_6-什么是rdd" class="header-anchor">#</a> 6.什么是RDD?</h3> <p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象。</p> <p>代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。</p> <h3 id="_7-wordcount代码中算子的具体工作流程-各个算子执行位置-可以画图说明"><a href="#_7-wordcount代码中算子的具体工作流程-各个算子执行位置-可以画图说明" class="header-anchor">#</a> 7.wordCount代码中算子的具体工作流程(各个算子执行位置)?(可以画图说明)</h3> <p>（1）创建Spark编程入口SparkContext</p> <p>（2）读取文件，将文件中的内容保存到RDD</p> <p>（3）将工作分配到各主机节点</p> <p>（4）各主机节点对自己分到的任务进行操作，首先进行单词划分，按空格分隔，生成flatMappedRDD</p> <p>（5）然后将各单词生成Map键值对，输出(Word,1)</p> <p>（6）然后将不同节点上的单词进行局部统计求和，生成局部WordCount的MapPatitionRDD</p> <p>（7）接着对各节点间进行Shuffle，将各节点间的单词进行词频统计，生成最后的MapPatitionRDD</p> <p>（8）最后输出结果</p> <p><img src="https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fspark_wc.png" alt=""></p> <h3 id="_8-简述rdd的五大特性"><a href="#_8-简述rdd的五大特性" class="header-anchor">#</a> 8.简述RDD的五大特性?</h3> <ol><li>RDD由一到多个partition构成，有多少个partition就对应有多少个task。</li> <li>对RDD做计算，相当于对RDD的每个split或partition做计算。</li> <li>RDD之间有依赖关系，可溯源。</li> <li>如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，比如可以按key的hash值分区。</li> <li>每个split一般有多个副本，计算时优先使用本地的副本进行计算，减少数据的IO和网络传输，提高性能。</li></ol> <h3 id="_9-rdd有几种创建方式"><a href="#_9-rdd有几种创建方式" class="header-anchor">#</a> 9.RDD有几种创建方式?</h3> <ol><li>使用程序中的集合创建RDD <code>sc.parallelize(Array(1, 2, 3, 4, 5, 6, 7, 8))</code></li> <li>使用本地文件创建RDD <code>sc.textFile(&quot;input&quot;)</code></li> <li>使用HDFS文件创建RDD <code>sc.textFile(&quot;hdfs://input&quot;)</code></li> <li>使用消息源（例如 Kafka）创建RDD</li></ol> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>    <span class="token comment">// 创建SparkConf</span>
    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;sparkstreaming&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// 创建StreamingContext</span>
    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 定义 Kafka 参数：kafka集群地址、消费者组名称、key序列化、value序列化</span>
    <span class="token keyword">val</span> kafkaPara<span class="token operator">:</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Object<span class="token punctuation">]</span> <span class="token operator">=</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Object<span class="token punctuation">]</span><span class="token punctuation">(</span>
      ConsumerConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG <span class="token operator">-&gt;</span> <span class="token string">&quot;hadoop102:9092,hadoop103:9092,hadoop104:9092&quot;</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>GROUP_ID_CONFIG <span class="token operator">-&gt;</span> <span class="token string">&quot;saberlindGroup&quot;</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG <span class="token operator">-&gt;</span> <span class="token string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// 读取 Kafka 数据创建 DStream</span>
    <span class="token keyword">val</span> kafkaDStream<span class="token operator">:</span> InputDStream<span class="token punctuation">[</span>ConsumerRecord<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
      ssc<span class="token punctuation">,</span>
      LocationStrategies<span class="token punctuation">.</span>PreferConsistent<span class="token punctuation">,</span> <span class="token comment">// 优先位置</span>
      ConsumerStrategies<span class="token punctuation">.</span>Subscribe<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>Set<span class="token punctuation">(</span><span class="token string">&quot;testTopic&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kafkaPara<span class="token punctuation">)</span> <span class="token comment">// 消费策略: (订阅多个主题，配置参数)</span>
    <span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><h3 id="_10-集合创建rdd-默认分区数和设置分区的算法"><a href="#_10-集合创建rdd-默认分区数和设置分区的算法" class="header-anchor">#</a> 10.集合创建RDD,默认分区数和设置分区的算法?</h3> <p>从集合创建rdd,如果不手动写分区数量的情况下,默认分区数跟本地模式的cpu核数有关</p> <p>​	local : 1个</p> <p>​	local[*] : 笔记本所有核心数</p> <p>​	local[K]: K个</p> <p>规则：</p> <p>分区的开始位置 = (分区号 * 数据总长度)/分区总数</p> <p>分区的结束位置 =((分区号 + 1)* 数据总长度)/分区总数</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">object</span> fenqu <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;SparkCoreTest&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
 
    <span class="token comment">//1）4个数据，设置4个分区，输出：0分区-&gt;1，1分区-&gt;2，2分区-&gt;3，3分区-&gt;4</span>
    <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
 
    <span class="token comment">//2）4个数据，设置3个分区，输出：0分区-&gt;1，1分区-&gt;2，2分区-&gt;3,4</span>
    <span class="token comment">//val rdd: RDD[Int] = sc.makeRDD(Array(1, 2, 3, 4), 3)</span>
 
    <span class="token comment">//3）5个数据，设置3个分区，输出：0分区-&gt;9，1分区-&gt;2、3，2分区-&gt;4、5</span>
    <span class="token comment">//val rdd: RDD[Int] = sc.makeRDD(Array(9, 2, 3, 4, 5), 3)</span>
 
    rdd<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">&quot;output&quot;</span><span class="token punctuation">)</span>
 
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p><img src="https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fparbyarray.png" alt=""></p> <p>分区1：1个，分区2：2个，分区3：2个</p> <h3 id="_11-读取文件创建rdd-默认分区数和设置分区数的算法"><a href="#_11-读取文件创建rdd-默认分区数和设置分区数的算法" class="header-anchor">#</a> 11.读取文件创建RDD,默认分区数和设置分区数的算法</h3> <p>默认：</p> <p>​	默认取值为当前核数和2的最小值,一般为2</p> <p>指定：</p> <p>1).分区数量的计算方式:</p> <p>​	totalSize = 10</p> <p>​	goalSize = 10 / 3 = 3(byte) 表示每个分区存储3字节的数据</p> <p>​	分区数= totalSize/ goalSize = 10 /3 =&gt; 3,3,4</p> <p>​	4子节大于3子节的1.1倍,符合hadoop切片1.1倍的策略,因此会多创建一个分区,即一共有4个分区  3,3,3,1</p> <p>2). Spark读取文件，采用的是hadoop的方式读取，所以一行一行读取，跟字节数没有关系</p> <p>3).数据读取位置计算是以偏移量为单位来进行计算的。</p> <p>4).数据分区的偏移量范围的计算</p> <p>​	0 =&gt; [0,3]         1     012        0 =&gt; 1,2</p> <p>​	1 =&gt; [3,6]         2     345        1 =&gt; 3</p> <p>​	2 =&gt; [6,9]         3     678        2 =&gt; 4</p> <p>​	3 =&gt; [9,9]         4      9           3 =&gt; 无</p> <h3 id="_12-使用list-1-2-3-4-5-创建rdd如何控制分区个数-如果是2个分区-怎么分配"><a href="#_12-使用list-1-2-3-4-5-创建rdd如何控制分区个数-如果是2个分区-怎么分配" class="header-anchor">#</a> 12.使用List(1,2,3,4,5)创建rdd如何控制分区个数,如果是2个分区,怎么分配?</h3> <p>start = (分区数 * 数据长度) / 分区数</p> <p>end = ((分区数 + 1) * 数据长度) / 分区数</p> <p>分区1：1，2</p> <p>分区2：3，4，5</p> <h3 id="_13-创建一个rdd-使其一个分区的数据转变为一个string"><a href="#_13-创建一个rdd-使其一个分区的数据转变为一个string" class="header-anchor">#</a> 13.创建一个RDD，使其一个分区的数据转变为一个String</h3> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getName<span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;b&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;c&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;d&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token comment">// 将同一分区数据转为数组</span>
    <span class="token keyword">val</span> glomRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>glom<span class="token punctuation">(</span><span class="token punctuation">)</span>
    glomRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> glomRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>
      arr <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
        arr<span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
    resRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><h3 id="_14-reducebykey跟groupbykey之间的区别。"><a href="#_14-reducebykey跟groupbykey之间的区别。" class="header-anchor">#</a> 14.reduceByKey跟groupByKey之间的区别。</h3> <p>reduceByKey：按照key进行聚合，在shuffle之前，会对分区内数据进行预聚合操作，返回的结果是k-v类型的RDD（RDD[K,V]）。</p> <p>groupByKey：按照key进行分组，直接进行shuffle。返回的结果是k-迭代器类型的RDD（RDD[K,Iterable[V]]）。</p> <p>在不影响业务逻辑的情况下，优先使用reduceByKey。<strong>求和操作不影响业务逻辑，求平均值的操作影响业务逻辑。</strong></p> <h3 id="_15-reducebykey跟aggregatebykey、foldbykey之间的区别与联系。"><a href="#_15-reducebykey跟aggregatebykey、foldbykey之间的区别与联系。" class="header-anchor">#</a> 15.reduceByKey跟aggregateByKey、foldByKey之间的区别与联系。</h3> <p><strong>联系：</strong></p> <ul><li>都是按照key做聚合操作，都会在shuffle之前对数据做预聚合操作。</li></ul> <p><strong>区别：</strong></p> <ul><li>reduceByKey：没有初始值，分区内和分区间的计算规则一致。</li> <li>aggregateByKey：有初始值，初始值参与分区内和分区间的计算，分区内和分区间规则可以不一致。</li> <li>foldByKey：有初始值，初始值参与分区内的计算，分区内和分区间计算规则相同的 aggregateByKey。</li></ul> <h3 id="_16-rdd中随便写出15个转换算子-8个行动算子-并简述其功能"><a href="#_16-rdd中随便写出15个转换算子-8个行动算子-并简述其功能" class="header-anchor">#</a> 16.rdd中随便写出15个转换算子,8个行动算子,并简述其功能</h3> <h3 id="_17-spark中rdd的序列化"><a href="#_17-spark中rdd的序列化" class="header-anchor">#</a> 17.spark中rdd的序列化</h3> <p>为什么要序列化：</p> <ul><li>从计算的角度：算子以外的代码都是 Driver 端执行，算子里面的代码都是 Executor 端执行，因此算子内经常会用到算子外的数据，因此形成<strong>闭包的效果</strong>。（Scala自带闭包检查，代码未运行就报错了）</li> <li>在调用算子外的数据时，数据需要在Driver和Executor中间通过网络进行传输，因此需要序列化</li></ul> <p>怎么序列化：</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code>    val conf<span class="token operator">:</span> <span class="token class-name">SparkConf</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;SerDemo&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span>
      <span class="token comment">// 替换默认的序列化机制</span>
      <span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">&quot;spark.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="token punctuation">)</span>
      <span class="token comment">//.registerKryoClasses(Array(classOf[KryoSerializer]))</span>
      <span class="token comment">// 注册需要使用kryo序列化的自定义类</span>
      <span class="token punctuation">.</span><span class="token function">registerKryoClasses</span><span class="token punctuation">(</span><span class="token class-name">Array</span><span class="token punctuation">(</span>classOf<span class="token punctuation">[</span><span class="token class-name">Searche</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">class</span> <span class="token class-name">Searche</span><span class="token punctuation">(</span>val query<span class="token operator">:</span> <span class="token class-name">String</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">Serializable</span> <span class="token punctuation">{</span>

  def <span class="token function">isMatch</span><span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token class-name">String</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    s<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span>query<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  def <span class="token function">getMatchedRDD1</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    rdd<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>isMatch<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  def <span class="token function">getMatchedRDD2</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    rdd<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>序列化调优：</p> <ul><li>使用Kryo可以节省10倍空间以及更少cpu, 强烈建议使用kryo</li> <li>Kryo在序列化时缓存空间默认大小是2MB, 可以根据业务模型调整大小，设置spark.kryoserilizer.buffer为10MB。</li> <li>在Kryo注册时强烈建议写完整的包名和类名，否则每次序列化都会保存一份整个包名和类名的完整信息，会造成不必要的内存空间浪费。</li></ul> <h3 id="_18-什么叫rdd的血缘"><a href="#_18-什么叫rdd的血缘" class="header-anchor">#</a> 18.什么叫rdd的血缘?</h3> <ul><li>RDD通过转换算子生成一系列的的RDD，Spark会记录每一个RDD之间的依赖关系，此关系称为血缘，可以通过<code>toDebuString</code>算子查看RDD之间的血缘关系。</li> <li>Spark会跟据RDD之间的血缘关系形成 <strong>DAG有向无环图</strong> ，根据此有向无环图，Spark <strong>可以高效的处理容错和数据的恢复工作</strong></li></ul> <h3 id="_19-什么叫rdd的依赖关系-依赖关系有哪些-什么区别"><a href="#_19-什么叫rdd的依赖关系-依赖关系有哪些-什么区别" class="header-anchor">#</a> 19.什么叫rdd的依赖关系? 依赖关系有哪些? 什么区别?</h3> <p>RDD通过转换算子生成一系列的的RDD，上一级RDD即为当前RDD的父RDD</p> <p>依赖关系：</p> <ul><li>窄依赖：(独生子女)
<ul><li>窄依赖指的是每一个父RDD 的Partition 最多被子RDD 的一个Partition 使用</li></ul></li> <li>宽依赖：(超生)
<ul><li>宽依赖指的是多个子RDD 的Partition 会依赖同一个父RDD 的Partition</li></ul></li></ul> <p><strong>shuffle 不一定产生宽依赖,但是宽依赖一定是由 shuffle 产生的。</strong></p> <blockquote><p>​	shuffle过程不一定会产生宽依赖，形如groupByKey，reduceByKey，foldByKey，aggregateByKey，combineByKey等算子有可能不会产生宽依赖，也许相同的key在此前的RDD中已经放到相同的分区了，故不用shuffle也已经达到了聚合的目标。</p></blockquote> <h3 id="_20-什么情况下rdd会进行shuffle"><a href="#_20-什么情况下rdd会进行shuffle" class="header-anchor">#</a> 20.什么情况下rdd会进行shuffle?</h3> <p>​	首先，RDD的计算是分布式的，在需要对发布在不同节点的所有数据进行聚合计算时，需要进行Shuffle将数据落磁盘，将数据根据不同分区进行聚合计算，最终重新将数据根据分区发送到不同的节点上。</p> <h3 id="_21-创建一个rdd-自定义一种分区规则并实现。spark中是否可以按照value分区"><a href="#_21-创建一个rdd-自定义一种分区规则并实现。spark中是否可以按照value分区" class="header-anchor">#</a> 21.创建一个RDD，自定义一种分区规则并实现。Spark中是否可以按照Value分区？</h3> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 自定义分区</span>
<span class="token keyword">class</span> <span class="token class-name">MyPartitioner</span><span class="token punctuation">(</span>num<span class="token operator">:</span> <span class="token class-name">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span> <span class="token punctuation">{</span>

    <span class="token comment">// 设置的分区数</span>
    override def numPartitions<span class="token operator">:</span> <span class="token class-name">Int</span> <span class="token operator">=</span> num

    <span class="token comment">// 具体分区逻辑</span>
    override def <span class="token function">getPartition</span><span class="token punctuation">(</span>key<span class="token operator">:</span> <span class="token class-name">Any</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>isInstanceOf<span class="token punctuation">[</span><span class="token class-name">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

            val keyInt<span class="token operator">:</span> <span class="token class-name">Int</span> <span class="token operator">=</span> key<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span><span class="token class-name">Int</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>keyInt <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
                <span class="token number">0</span>
            <span class="token keyword">else</span>
                <span class="token number">1</span>
        <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>
            <span class="token number">0</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p><strong>按照Value分区：</strong></p> <ul><li>RDD通过map映射，把value和key的位置调换。</li></ul> <h3 id="_22-spark读取hdfs文件默认的切片机制。-1-1倍原则"><a href="#_22-spark读取hdfs文件默认的切片机制。-1-1倍原则" class="header-anchor">#</a> 22.Spark读取HDFS文件默认的切片机制。(1.1倍原则)</h3> <ul><li>创建RDD时，会将文件路径和最小分区数minPartitions传递到HadoopRDD中。</li> <li>调用FileInputFormat中的getSplits方法计算切片信息。</li> <li>首先计算目标切片大小goalSize：目标切片大小 = 文件大小 / 最小分区数 。</li> <li>再计算切片最小值minSize：max(FileInputFormat.SPLIT_MINSIZE,minSplitSize)，最小值为1。</li> <li>接着计算splitSize = Math.max(minSize, Math.min(goalSize, blockSize)),所以SplitSize一般为goalSize和blockSize两者的最小值。</li> <li>如果剩余待处理文件大小 / splitSize &gt; 1.1，那么就切一片。</li></ul> <h3 id="_23-说说spark中累加器和广播变量的区别"><a href="#_23-说说spark中累加器和广播变量的区别" class="header-anchor">#</a> 23.说说spark中累加器和广播变量的区别</h3> <p>**累加器：**分布式共享只写变量</p> <p>**广播变量：**分布式共享只读变量</p> <h3 id="_24-sparksql底层有什么编程抽象"><a href="#_24-sparksql底层有什么编程抽象" class="header-anchor">#</a> 24.SparkSQL底层有什么编程抽象?</h3> <p>datafarme (可以看做特殊类型的dataset  row类型)有列名 没有列的数据类型</p> <p>dataset      有列名 同时有数据类型</p> <h3 id="_25-hive-on-spark-和-spark-on-hive-区别-我们学的sparksql是什么"><a href="#_25-hive-on-spark-和-spark-on-hive-区别-我们学的sparksql是什么" class="header-anchor">#</a> 25.hive on spark 和 spark on hive 区别? 我们学的SparkSQL是什么?</h3> <p>hive on spark本体使用的是hive,只需要修改hive中的运算引擎即可</p> <p>spark on hive 中spark是本体  只需要使用到hive作为元数据的管理 直接使用spark进行编写</p> <p>SparkSQL  属于spark on hive</p> <h3 id="_26-df、ds、rdd三者直接的区别和联系"><a href="#_26-df、ds、rdd三者直接的区别和联系" class="header-anchor">#</a> 26.DF、DS、RDD三者直接的区别和联系?</h3> <blockquote><p>在实际开发的时候，很少会把序列转换成DataSet，更多是通过RDD和DataFrame转换来得到DataSet</p></blockquote> <p><strong>联系：</strong></p> <p>1）都是spark中得弹性分布式数据集，轻量级</p> <p>2）都是惰性机制，延迟计算</p> <p>3）根据内存情况，自动缓存，加快计算速度</p> <p>4）都有partition分区概念</p> <p>5）众多相同得算子：map flatmap 等等</p> <p><strong>区别：</strong></p> <ul><li><p>RDD</p> <ul><li>优点: 编译时类型安全 编译时就能检查出类型错误 面向对象的编程风格 直接通过类名点的方式来操作数据</li> <li>缺点: 序列化和反序列化的性能开销 无论是集群间的通信, 还是IO操作都需要对对象的结构和数据进行序列化和反序列化 GC的性能开销，频繁的创建和销毁对象, 势必会增加GC</li></ul></li> <li><p>DataFrame（DataFrame引入了schema和off-heap）</p> <ul><li><p>schema : RDD每一行的数据, 结构都是一样的.</p> <p>这个结构就存储在schema中. Spark通过schame就能够读懂数据, 因此在通信和IO时就只需要序列化和反序列化数据，而结构的部分就可以省略了。</p></li> <li><p>off-heap : 意味着JVM堆以外的内存</p> <p>这些内存直接受操作系统管理（而不是JVM）。Spark能够以二进制的形式序列化数据(不包括结构)到off-heap中，当要操作数据时，就直接操作off-heap内存。由于Spark理解schema, 所以知道该如何操作 其API不是面向对象的</p> <p>这里我们就可以看出spark为了解决RDD的问题进行的取舍</p></li></ul></li> <li><p>RDD是分布式的Java对象的集合。DataFrame是分布式的Row对象的集合</p></li> <li><p>DataFrame除了提供了比RDD更丰富的算子以外，更重要的特点是提升执行效率、减少数据读取以及执行计划的优化，比如filter下推、裁剪等</p></li> <li><p>Dataset和DataFrame拥有完全相同的成员函数，区别只是每一行的数据类型不同</p></li> <li><p>DataFrame也可以叫Dataset[Row],每一行的类型是Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用getAS方法或者共性中的第七条提到的模式匹配拿出特定字段</p></li> <li><p>而Dataset中，每一行是什么类型是不一定的，在自定义了case class之后可以很自由的获得每一行的信息</p></li></ul> <h3 id="_27-sparksql中有两种什么语法-简述两种语法的区别和练习"><a href="#_27-sparksql中有两种什么语法-简述两种语法的区别和练习" class="header-anchor">#</a> 27.SparkSQL中有两种什么语法? 简述两种语法的区别和练习</h3> <ol><li>SQL风格语法</li></ol> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code> # 临时视图
 df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span>
 <span class="token keyword">val</span> sqlDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM user&quot;</span><span class="token punctuation">)</span>
 # 新的 Session 无法获取临时视图的数据
 spark<span class="token punctuation">.</span>newSession<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT avg(age) from user &quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
# 全局视图
df<span class="token punctuation">.</span>createOrReplaceGlobalTempView <span class="token punctuation">(</span><span class="token string">&quot;user2&quot;</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>newSession<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM global_temp.user2&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><ol start="2"><li>DSL风格语法</li></ol> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code># 只查看某一列的数据
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token symbol">'name</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
# 条件查询
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token string">&quot;age&gt;18&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
# 全查询
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;*&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show

# 运算查询：涉及到运算的时候，每列都必须使用$，或者采用单引号表达式：单引号<span class="token operator">+</span>字段名
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>$<span class="token string">&quot;age&quot;</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
 df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'name, '</span>age <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
 df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'name, '</span>age <span class="token operator">+</span> <span class="token number">1</span> as <span class="token string">&quot;newage&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
 # 过滤
 df<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token string">&quot;age&gt;19&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
 # 分组
 df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">.</span>show
 # 平均值
 df<span class="token punctuation">.</span>agg<span class="token punctuation">(</span>avg<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
 # 求和
 df<span class="token punctuation">.</span>agg<span class="token punctuation">(</span>max<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><h3 id="_28-sparksql中自定义udaf实现求平均年龄"><a href="#_28-sparksql中自定义udaf实现求平均年龄" class="header-anchor">#</a> 28.SparkSQL中自定义UDAF实现求平均年龄</h3> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">object</span> SparkSQL06_UDAF <span class="token punctuation">{</span>

    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

        <span class="token comment">// 1 创建上下文环境配置对象</span>
        <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;SparkSQLTest&quot;</span><span class="token punctuation">)</span>

        <span class="token comment">// 2 创建SparkSession对象</span>
        <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment">// 3 读取数据</span>
        <span class="token keyword">val</span> df<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;input/user.json&quot;</span><span class="token punctuation">)</span>

        <span class="token comment">// 4 创建DataFrame临时视图</span>
        df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span>
        
        <span class="token comment">// 5 注册UDAF</span>
        spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">&quot;myAvg&quot;</span><span class="token punctuation">,</span> functions<span class="token punctuation">.</span>udaf<span class="token punctuation">(</span><span class="token keyword">new</span> MyAvgUDAF<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment">// 6 调用自定义UDAF函数</span>
        spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select myAvg(age) from user&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment">// 7 释放资源</span>
        spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token comment">//输入数据类型</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> Buff<span class="token punctuation">(</span><span class="token keyword">var</span> sum<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token keyword">var</span> count<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span>

<span class="token comment">/**
 * 1,20岁； 2,19岁； 3,18岁
 * IN:聚合函数的输入类型：Long
 * Buff : sum = (18+19+20)  count = 1+1+1
 * OUT:聚合函数的输出类型：Double  (18+19+20) / 3
 */</span>
<span class="token keyword">class</span> MyAvgUDAF <span class="token keyword">extends</span> Aggregator<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">,</span> Buff<span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token punctuation">{</span>

    <span class="token comment">// 初始化缓冲区</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> zero<span class="token operator">:</span> Buff <span class="token operator">=</span> Buff<span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span>

    <span class="token comment">// 将输入的年龄和缓冲区的数据进行聚合</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> reduce<span class="token punctuation">(</span>buff<span class="token operator">:</span> Buff<span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span><span class="token operator">:</span> Buff <span class="token operator">=</span> <span class="token punctuation">{</span>
        buff<span class="token punctuation">.</span>sum <span class="token operator">=</span> buff<span class="token punctuation">.</span>sum <span class="token operator">+</span> age
        buff<span class="token punctuation">.</span>count <span class="token operator">=</span> buff<span class="token punctuation">.</span>count <span class="token operator">+</span> <span class="token number">1</span>
        buff
    <span class="token punctuation">}</span>

    <span class="token comment">// 多个缓冲区数据合并</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>buff1<span class="token operator">:</span> Buff<span class="token punctuation">,</span> buff2<span class="token operator">:</span> Buff<span class="token punctuation">)</span><span class="token operator">:</span> Buff <span class="token operator">=</span> <span class="token punctuation">{</span>
        buff1<span class="token punctuation">.</span>sum <span class="token operator">=</span> buff1<span class="token punctuation">.</span>sum <span class="token operator">+</span> buff2<span class="token punctuation">.</span>sum
        buff1<span class="token punctuation">.</span>count <span class="token operator">=</span> buff1<span class="token punctuation">.</span>count <span class="token operator">+</span> buff2<span class="token punctuation">.</span>count
        buff1
    <span class="token punctuation">}</span>

    <span class="token comment">// 完成聚合操作，获取最终结果</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> finish<span class="token punctuation">(</span>buff<span class="token operator">:</span> Buff<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
        buff<span class="token punctuation">.</span>sum<span class="token punctuation">.</span>toDouble <span class="token operator">/</span> buff<span class="token punctuation">.</span>count
    <span class="token punctuation">}</span>

    <span class="token comment">// SparkSQL对传递的对象的序列化操作（编码）</span>
    <span class="token comment">// 自定义类型就是product   自带类型根据类型选择</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> bufferEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span>Buff<span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>product

    <span class="token keyword">override</span> <span class="token keyword">def</span> outputEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>scalaDouble
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br></div></div><h3 id="_29-rdd实现join的多种方式"><a href="#_29-rdd实现join的多种方式" class="header-anchor">#</a> 29. RDD实现Join的多种方式</h3> <ul><li>rdd1.join(rdd2)：将相同的key对应的value关联到一起。如果key只是某个RDD存在，那么不返回。</li> <li>rdd1.leftOuterJoin(rdd2)：返回rdd1中的全部key-value和关联后的key-value。</li> <li>rdd1.rightOuterJoin(rdd2)：返回rdd2中的全部key-value和关联后的key-value。</li> <li>rdd1.cogroup(rdd2)：每个rdd中先关联自己的key形成集合，然后再合并</li></ul> <h3 id="_30-aggregatebykey与aggregate之间的区别与联系"><a href="#_30-aggregatebykey与aggregate之间的区别与联系" class="header-anchor">#</a> 30. aggregateByKey与aggregate之间的区别与联系</h3> <p><strong>联系：</strong></p> <ul><li>两者都是对分区内和分区间的元素做聚合操作，而且都有初始值。</li></ul> <p><strong>区别：</strong></p> <ul><li>aggregateByKey是转换算子，是对k-v类型的RDD进行操作，初始值参与分区内和分区间的计算，初始值会和RDD中每一个元素进行迭代并运算。</li> <li>aggregate是行动算子，初始值参与分区内和分区间的计算，分区内计算时，初始值和RDD每个分区中的一个元素按照指定规则运算，分区间计算时，初始值只会参与一次运算。</li></ul> <h3 id="_31-rdd的cache和checkpoint的区别和联系"><a href="#_31-rdd的cache和checkpoint的区别和联系" class="header-anchor">#</a> 31. RDD的cache和checkPoint的区别和联系</h3> <p><strong>联系：</strong></p> <ul><li>cache和checkPoint都是对RDD中的数据做缓存，后面计算逻辑相同的RDD，可以直接从缓存中取数据，而不用重新进行计算。</li> <li>只有触发action算子时，才会真正的缓存。</li></ul> <p><strong>区别：</strong></p> <ul><li>cache不会切断RDD的血缘关系，缓存默认存储在内存中，可以设置存储在本地磁盘上，但是随着程序运行结束，cache缓存的数据都会丢失。</li> <li>checkpoint检查点会切断RDD的血缘关系，可以把数据存储在HDFS等高可用、可靠性高的存储系统中。</li> <li>为了确保数据的准确性，checkpoint检查点在第一次使用时，会根据RDD的血缘关系，从头到尾执行一遍。</li> <li>一般checkpoint和cache搭配来使用。</li></ul> <h3 id="_32-spark是如何进行任务切分的-请说明其中涉及到的相关概念"><a href="#_32-spark是如何进行任务切分的-请说明其中涉及到的相关概念" class="header-anchor">#</a> 32. Spark是如何进行任务切分的，请说明其中涉及到的相关概念</h3> <ul><li>应用：一个spark程序就是一个应用，一个应用可以有多个job。</li> <li>job作业：触发一次action算子就是一次job，一个job可以有多个stage。</li> <li>stage阶段：宽依赖切分不同的stage，stage的数量=宽依赖数量+1。一个stage可以有多个task。</li> <li>task任务：每个stage的最后一个RDD的分区数量=task的数量。</li></ul></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">6 months ago</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_1-spark面试题" class="sidebar-link reco-side-_1-spark面试题" data-v-70334359>1. Spark面试题</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_1-spark负责什么事情-为什么要设计自己的调度器" class="sidebar-link reco-side-_1-spark负责什么事情-为什么要设计自己的调度器" data-v-70334359>1.Spark负责什么事情?为什么要设计自己的调度器?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_2-spark中核心集群角色哪些-分别说明其主要功能。" class="sidebar-link reco-side-_2-spark中核心集群角色哪些-分别说明其主要功能。" data-v-70334359>2.Spark中核心集群角色哪些？分别说明其主要功能。</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_3-如何提交一个spark任务-主要参数有哪些" class="sidebar-link reco-side-_3-如何提交一个spark任务-主要参数有哪些" data-v-70334359>3.如何提交一个Spark任务?主要参数有哪些?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_4-简述你所理解的不同运行模式之间的区别。" class="sidebar-link reco-side-_4-简述你所理解的不同运行模式之间的区别。" data-v-70334359>4.简述你所理解的不同运行模式之间的区别。</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_5-spark的端口号总结" class="sidebar-link reco-side-_5-spark的端口号总结" data-v-70334359>5.Spark的端口号总结</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_6-什么是rdd" class="sidebar-link reco-side-_6-什么是rdd" data-v-70334359>6.什么是RDD?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_7-wordcount代码中算子的具体工作流程-各个算子执行位置-可以画图说明" class="sidebar-link reco-side-_7-wordcount代码中算子的具体工作流程-各个算子执行位置-可以画图说明" data-v-70334359>7.wordCount代码中算子的具体工作流程(各个算子执行位置)?(可以画图说明)</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_8-简述rdd的五大特性" class="sidebar-link reco-side-_8-简述rdd的五大特性" data-v-70334359>8.简述RDD的五大特性?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_9-rdd有几种创建方式" class="sidebar-link reco-side-_9-rdd有几种创建方式" data-v-70334359>9.RDD有几种创建方式?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_10-集合创建rdd-默认分区数和设置分区的算法" class="sidebar-link reco-side-_10-集合创建rdd-默认分区数和设置分区的算法" data-v-70334359>10.集合创建RDD,默认分区数和设置分区的算法?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_11-读取文件创建rdd-默认分区数和设置分区数的算法" class="sidebar-link reco-side-_11-读取文件创建rdd-默认分区数和设置分区数的算法" data-v-70334359>11.读取文件创建RDD,默认分区数和设置分区数的算法</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_12-使用list-1-2-3-4-5-创建rdd如何控制分区个数-如果是2个分区-怎么分配" class="sidebar-link reco-side-_12-使用list-1-2-3-4-5-创建rdd如何控制分区个数-如果是2个分区-怎么分配" data-v-70334359>12.使用List(1,2,3,4,5)创建rdd如何控制分区个数,如果是2个分区,怎么分配?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_13-创建一个rdd-使其一个分区的数据转变为一个string" class="sidebar-link reco-side-_13-创建一个rdd-使其一个分区的数据转变为一个string" data-v-70334359>13.创建一个RDD，使其一个分区的数据转变为一个String</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_14-reducebykey跟groupbykey之间的区别。" class="sidebar-link reco-side-_14-reducebykey跟groupbykey之间的区别。" data-v-70334359>14.reduceByKey跟groupByKey之间的区别。</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_15-reducebykey跟aggregatebykey、foldbykey之间的区别与联系。" class="sidebar-link reco-side-_15-reducebykey跟aggregatebykey、foldbykey之间的区别与联系。" data-v-70334359>15.reduceByKey跟aggregateByKey、foldByKey之间的区别与联系。</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_16-rdd中随便写出15个转换算子-8个行动算子-并简述其功能" class="sidebar-link reco-side-_16-rdd中随便写出15个转换算子-8个行动算子-并简述其功能" data-v-70334359>16.rdd中随便写出15个转换算子,8个行动算子,并简述其功能</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_17-spark中rdd的序列化" class="sidebar-link reco-side-_17-spark中rdd的序列化" data-v-70334359>17.spark中rdd的序列化</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_18-什么叫rdd的血缘" class="sidebar-link reco-side-_18-什么叫rdd的血缘" data-v-70334359>18.什么叫rdd的血缘?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_19-什么叫rdd的依赖关系-依赖关系有哪些-什么区别" class="sidebar-link reco-side-_19-什么叫rdd的依赖关系-依赖关系有哪些-什么区别" data-v-70334359>19.什么叫rdd的依赖关系? 依赖关系有哪些? 什么区别?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_20-什么情况下rdd会进行shuffle" class="sidebar-link reco-side-_20-什么情况下rdd会进行shuffle" data-v-70334359>20.什么情况下rdd会进行shuffle?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_21-创建一个rdd-自定义一种分区规则并实现。spark中是否可以按照value分区" class="sidebar-link reco-side-_21-创建一个rdd-自定义一种分区规则并实现。spark中是否可以按照value分区" data-v-70334359>21.创建一个RDD，自定义一种分区规则并实现。Spark中是否可以按照Value分区？</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_22-spark读取hdfs文件默认的切片机制。-1-1倍原则" class="sidebar-link reco-side-_22-spark读取hdfs文件默认的切片机制。-1-1倍原则" data-v-70334359>22.Spark读取HDFS文件默认的切片机制。(1.1倍原则)</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_23-说说spark中累加器和广播变量的区别" class="sidebar-link reco-side-_23-说说spark中累加器和广播变量的区别" data-v-70334359>23.说说spark中累加器和广播变量的区别</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_24-sparksql底层有什么编程抽象" class="sidebar-link reco-side-_24-sparksql底层有什么编程抽象" data-v-70334359>24.SparkSQL底层有什么编程抽象?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_25-hive-on-spark-和-spark-on-hive-区别-我们学的sparksql是什么" class="sidebar-link reco-side-_25-hive-on-spark-和-spark-on-hive-区别-我们学的sparksql是什么" data-v-70334359>25.hive on spark 和 spark on hive 区别? 我们学的SparkSQL是什么?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_26-df、ds、rdd三者直接的区别和联系" class="sidebar-link reco-side-_26-df、ds、rdd三者直接的区别和联系" data-v-70334359>26.DF、DS、RDD三者直接的区别和联系?</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_27-sparksql中有两种什么语法-简述两种语法的区别和练习" class="sidebar-link reco-side-_27-sparksql中有两种什么语法-简述两种语法的区别和练习" data-v-70334359>27.SparkSQL中有两种什么语法? 简述两种语法的区别和练习</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_28-sparksql中自定义udaf实现求平均年龄" class="sidebar-link reco-side-_28-sparksql中自定义udaf实现求平均年龄" data-v-70334359>28.SparkSQL中自定义UDAF实现求平均年龄</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_29-rdd实现join的多种方式" class="sidebar-link reco-side-_29-rdd实现join的多种方式" data-v-70334359>29. RDD实现Join的多种方式</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_30-aggregatebykey与aggregate之间的区别与联系" class="sidebar-link reco-side-_30-aggregatebykey与aggregate之间的区别与联系" data-v-70334359>30. aggregateByKey与aggregate之间的区别与联系</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_31-rdd的cache和checkpoint的区别和联系" class="sidebar-link reco-side-_31-rdd的cache和checkpoint的区别和联系" data-v-70334359>31. RDD的cache和checkPoint的区别和联系</a></li><li class="level-3" data-v-70334359><a href="/blogs/Spark/Spark-8-QA.html#_32-spark是如何进行任务切分的-请说明其中涉及到的相关概念" class="sidebar-link reco-side-_32-spark是如何进行任务切分的-请说明其中涉及到的相关概念" data-v-70334359>32. Spark是如何进行任务切分的，请说明其中涉及到的相关概念</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><div></div><APlayer audio="" fixed="true" mini="true" theme="#f9bcdd" loop="loop" order="random" preload="auto" volume="0.3" mutex="true" lrc-type="0" list-folded="true" list-max-height="250" storage-name="vuepress-plugin-meting" id="aplayer-fixed"></APlayer></div></div>
    <script src="/assets/js/app.03646987.js" defer></script><script src="/assets/js/3.a8134f0a.js" defer></script><script src="/assets/js/1.a394b090.js" defer></script><script src="/assets/js/102.48df0133.js" defer></script>
  </body>
</html>
