(window.webpackJsonp=window.webpackJsonp||[]).push([[150],{673:function(s,t,a){"use strict";a.r(t);var n=a(4),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"_1-发展历程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-发展历程"}},[s._v("#")]),s._v(" 1. 发展历程")]),s._v(" "),a("blockquote",[a("p",[s._v("Scikit-learn的发展始于2007年，由David Cournapeau在Google Summer of Code项目中启动。项目后续得到了许多开发者的贡献，包括INRIA（法国国家信息与自动化研究所），Waikato大学和其他机构。")]),s._v(" "),a("p",[s._v("项目之所以取名为Scikit-Learn，也是因为该算法库是基于SciPy来进行的构建，而Scikit则是SciPy Kit（SciPy衍生的工具套件）的简称")]),s._v(" "),a("p",[s._v("Scikit-learn是目前机器学习领域最完整、同时也是最具影响力的算法库。它基于Numpy, Scipy和matplotlib，包含了大量的机器学习算法实现，包括分类、回归、聚类和降维等，还包含了诸多模型评估及选择的方法。Scikit-learn的API设计的非常清晰，易于使用和理解，适合于新手入门，同时也满足了专业人士在实际问题解决中的需求。")])]),s._v(" "),a("h2",{attrs:{id:"_2-官网结构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-官网结构"}},[s._v("#")]),s._v(" 2. 官网结构")]),s._v(" "),a("p",[s._v("地址："),a("a",{attrs:{href:"https://scikit-learn.org/stable/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Scikit-Learn"),a("OutboundLink")],1)]),s._v(" "),a("h3",{attrs:{id:"六大功能模块"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#六大功能模块"}},[s._v("#")]),s._v(" 六大功能模块：")]),s._v(" "),a("p",[s._v("Scikit-learn将所有的评估器和函数功能分为六大类，分别是")]),s._v(" "),a("ul",[a("li",[s._v("分类模型（Classification）")]),s._v(" "),a("li",[s._v("回归模型（Regression）")]),s._v(" "),a("li",[s._v("聚类模型（Clustering）")]),s._v(" "),a("li",[s._v("降维方法（Dimensionality reduction）")]),s._v(" "),a("li",[s._v("模型选择（Model selection）")]),s._v(" "),a("li",[s._v("数据预处理（Preprocessing）")])]),s._v(" "),a("h3",{attrs:{id:"user-guide"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#user-guide"}},[s._v("#")]),s._v(" User Guide")]),s._v(" "),a("p",[s._v("User Guide：sklearn所有内容的合集文档")]),s._v(" "),a("blockquote",[a("p",[s._v("最上方的User Guide一栏进入sklearn所有内容的合集页面，其中包含了sklearn的所有内容按照使用顺序进行的排序。如果点击左上方的Other versions，则可以下载sklearn所有版本的User Guide的PDF版本。")])]),s._v(" "),a("h3",{attrs:{id:"api"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#api"}},[s._v("#")]),s._v(" API")]),s._v(" "),a("p",[s._v("API：按照二级模块首字母排序的接口查询文档")]),s._v(" "),a("blockquote",[a("p",[s._v("如果想根据评估器或实用函数的名字去查找相关API说明文档，则可以点击最上方的API一栏进入到根据二极模块首字母排序的API查询文档中。其中二级模块指的是类似包含线性回归的linear_model模块或者包含MSE的metrics模块。")])]),s._v(" "),a("h2",{attrs:{id:"_3-安装与设置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-安装与设置"}},[s._v("#")]),s._v(" 3. 安装与设置")]),s._v(" "),a("p",[s._v("Scikit-learn需要Python (>= 3.6) 和pip。")]),s._v(" "),a("div",{staticClass:"language-sh line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sh"}},[a("code",[s._v("pip "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" numpy scipy\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -U 代表更新最新的版本")]),s._v("\npip "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" -U scikit-learn\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("h2",{attrs:{id:"_4-快速入门"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-快速入门"}},[s._v("#")]),s._v(" 4. 快速入门")]),s._v(" "),a("h3",{attrs:{id:"数据集导入和处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据集导入和处理"}},[s._v("#")]),s._v(" 数据集导入和处理")]),s._v(" "),a("blockquote",[a("p",[s._v("Scikit-learn提供了非常多的内置数据集，并且还提供了一些创建数据集的方法，这些数据集常用于演示各种机器学习算法的使用方法。这些数据集分为两种类型：小规模的玩具数据集（Toy Datasets）和大规模的真实世界数据集（Real-World Datasets）。")])]),s._v(" "),a("p",[s._v("以下是几个常见的玩具数据集：")]),s._v(" "),a("ol",[a("li",[a("strong",[s._v("Iris（鸢尾花）")]),s._v("：一个分类问题的数据集，包含了三种鸢尾花的四个特征，目标是根据这些特征预测鸢尾花的种类。")]),s._v(" "),a("li",[a("strong",[s._v("Digits（手写数字）")]),s._v("：一个多分类问题的数据集，包含了手写数字的8x8像素图像，目标是识别这些图像对应的数字。")]),s._v(" "),a("li",[a("strong",[s._v("Boston House Prices（波士顿房价）")]),s._v("：这是一个回归问题的数据集，包含了波士顿各个区域的房价和其他13个特征，目标是预测房价。")]),s._v(" "),a("li",[a("strong",[s._v("Breast Cancer（乳腺癌）")]),s._v("：这是一个二分类问题的数据集，包含了乳腺肿瘤的30个特征，目标是预测肿瘤是良性还是恶性。")])]),s._v(" "),a("p",[s._v("sklearn中的数据集相关功能都在datasets模块下，可以通过API文档中的datasets模块所包含的内容对所有的数据集和创建数据集的方法进行概览。")]),s._v(" "),a("p",[s._v("要在Scikit-learn中加载这些数据集，可以使用"),a("code",[s._v("sklearn.datasets")]),s._v("模块中的相关函数，例如：")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" load_iris\n\niris "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" load_iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("这个函数会返回一个"),a("code",[s._v("Bunch")]),s._v("对象，包含了数据、目标和其他信息。例如，"),a("code",[s._v("iris.data")]),s._v("是一个包含了特征的二维数组，"),a("code",[s._v("iris.target")]),s._v("是一个包含了目标的一维数组。")]),s._v(" "),a("table",[a("thead",[a("tr",[a("th",[s._v("名称")]),s._v(" "),a("th",[s._v("描述")])])]),s._v(" "),a("tbody",[a("tr",[a("td",[s._v("data")]),s._v(" "),a("td",[s._v("数据集特征矩阵")])]),s._v(" "),a("tr",[a("td",[s._v("target")]),s._v(" "),a("td",[s._v("数据集标签数组")])]),s._v(" "),a("tr",[a("td",[s._v("feature_names")]),s._v(" "),a("td",[s._v("各列名称")])]),s._v(" "),a("tr",[a("td",[s._v("target_names")]),s._v(" "),a("td",[s._v("各类别名称")])]),s._v(" "),a("tr",[a("td",[s._v("frame")]),s._v(" "),a("td",[s._v("当生成对象是DataFrame时，返回完整的DataFrame")])])])]),s._v(" "),a("p",[s._v("对应的可以使用如下代码查看：")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 数据集包含四个特征")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Features: "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("feature_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 数据集有三种分类标签")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Labels: "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("target_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将数据转换为DataFrame以便于查看")]),s._v("\niris_df "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" columns"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("feature_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加分类标签到DataFrame")]),s._v("\niris_df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'label'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("target\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 显示数据的前五行")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br")])]),a("p",[s._v("Scikit-learn也提供了一些真实世界的数据集，但由于规模较大，通常需要下载。这些数据集可以用于更复杂的任务和算法的测试。例如，"),a("code",[s._v("fetch_20newsgroups")]),s._v("函数可以下载20 Newsgroups文本数据集，用于文本分类等任务。")]),s._v(" "),a("h3",{attrs:{id:"数据集切分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据集切分"}},[s._v("#")]),s._v(" 数据集切分")]),s._v(" "),a("p",[s._v("在Scikit-learn中，通常将原始数据集切分为训练集和测试集，这样做可以评估模型在未见过的数据上的性能。数据集切分的目的是为了更好的进行模型性能评估，而更好的进行模型性能评估则是为了更好的进行模型挑选，Scikit-learn提供了"),a("code",[s._v("train_test_split")]),s._v("函数来帮助完成这一任务，train_test_split在model_selection模块下。")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" train_test_split\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 假设X是特征，y是目标")]),s._v("\nX_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" train_test_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" test_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[a("code",[s._v("train_test_split")]),s._v("函数的主要参数有：")]),s._v(" "),a("ul",[a("li",[a("code",[s._v("X, y")]),s._v("：需要被切分的数据。")]),s._v(" "),a("li",[a("code",[s._v("test_size")]),s._v("：代表测试集的比例。在上面的例子中，我们将20%的数据用作测试集。")]),s._v(" "),a("li",[a("code",[s._v("random_state")]),s._v("：随机种子，可以确保每次运行代码时数据的切分方式相同。")])]),s._v(" "),a("p",[a("strong",[s._v("这里面有两个参数需要关注一下")]),s._v("：")]),s._v(" "),a("ul",[a("li",[s._v("随机数种子的设置，random_state取值不同，切分结果就会各有不同")]),s._v(" "),a("li",[a("code",[s._v("stratify")]),s._v("参数是控制训练集和测试集不同类别样本所占比例的参数，若希望切分后的训练集和测试集中0、1两类的比例和原始数据相同（1:1），则可另stratify=y。")])]),s._v(" "),a("h3",{attrs:{id:"数值数据的标准化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数值数据的标准化"}},[s._v("#")]),s._v(" 数值数据的标准化")]),s._v(" "),a("blockquote",[a("p",[s._v("Scikit-learn中的预处理模块"),a("code",[s._v("sklearn.preprocessing")]),s._v("提供了许多实用的特征缩放功能，包括数据归一化（Normalization）和标准化（Standardization）。这两种技术都用于改变特征的尺度，以便在训练机器学习模型时保证它们在相同的范围内。")]),s._v(" "),a("p",[a("strong",[s._v("从功能上划分，Scikit-learn中的归一化其实是分为标准化（Standardization）和归一化（Normalization）两类。Z-Score标准化和0-1标准化，都属于Standardization的范畴，Normalization则特指针对单个样本（一行数据）利用其范数进行放缩的过程。")])])]),s._v(" "),a("p",[a("strong",[s._v("数据归一化")]),s._v("：归一化通常意味着将数据缩放到[0, 1]的范围内，或者使得所有数据的范围都在[-1, 1]之间。可以使用Scikit-learn的"),a("code",[s._v("MinMaxScaler")]),s._v("来实现。")]),s._v(" "),a("p",[a("strong",[s._v("数据标准化")]),s._v("：标准化则是将数据缩放，使得它们的均值为0，标准差为1。这可以通过Scikit-learn的"),a("code",[s._v("StandardScaler")]),s._v("来实现。")]),s._v(" "),a("p",[s._v("在机器学习中，训练集和测试集应当是分开处理的。具体地说，应当在训练集上训练模型，而测试集应当模拟真实世界中模型未曾见过的数据，以此来评估模型的真实性能。因此，任何形式的预处理（包括特征缩放）都应当只以训练集的数据为基准来完成。")]),s._v(" "),a("p",[s._v("当在训练集上调用"),a("code",[s._v("fit_transform")]),s._v("方法时，"),a("code",[s._v("fit")]),s._v("方法会计算训练集数据的均值和标准差，然后"),a("code",[s._v("transform")]),s._v("方法会使用这些计算出的参数（均值和标准差）来对训练集进行标准化。")]),s._v(" "),a("p",[s._v("然后，当在测试集上调用"),a("code",[s._v("transform")]),s._v("方法时，Scikit-learn会使用之前在训练集上计算得到的均值和标准差来进行标准化。这样做的原因是，假设测试集是模型未曾见过的新数据，因此，不能使用测试集数据的任何信息（包括它的均值和标准差）来影响模型。换句话说，必须假设在预处理阶段，测试集数据是不可见的。")]),s._v(" "),a("p",[s._v("总的来说，在预处理数据时，训练集应当使用"),a("code",[s._v("fit_transform")]),s._v("方法，而测试集应当只使用"),a("code",[s._v("transform")]),s._v("方法，这样可以保证不会在预处理阶段就“泄露”测试集的信息。")]),s._v(" "),a("h3",{attrs:{id:"数值数据的归一化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数值数据的归一化"}},[s._v("#")]),s._v(" 数值数据的归一化")]),s._v(" "),a("p",[s._v("在Scikit-learn中，"),a("code",[s._v("preprocessing.normalize")]),s._v('是另一种类型的"归一化"。')]),s._v(" "),a("p",[a("code",[s._v("preprocessing.normalize")]),s._v("的功能是按照向量空间模型（Vector Space Model）对特征向量进行转换，使得每个特征向量的欧几里得长度（L2范数）等于1，或者每个元素的绝对值之和（L1范数）等于1。换句话说："),a("strong",[s._v("和标准化不同，Scikit-learn中的归一化特指将单个样本（一行数据）放缩为单位范数（1范数或者2范数为单位范数）的过程，该操作常见于核方法或者衡量样本之间相似性的过程中。")])]),s._v(" "),a("h3",{attrs:{id:"核心对象类型-评估器-estimator"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#核心对象类型-评估器-estimator"}},[s._v("#")]),s._v(" 核心对象类型-评估器(estimator)")]),s._v(" "),a("p",[s._v("许多功能强大的第三方库都定义了自己的核心对象类型，这些对象类型实际上都是源码中定义的特定类的实例。例如，NumPy的核心是数组（Array），Pandas的核心是DataFrame，PyTorch的核心则是张量（Tensor）。这些对象类型为数据分析和机器学习提供了强大的工具。")]),s._v(" "),a("p",[s._v("对于Scikit-learn来说，它的核心对象类型是评估器（Estimator）。可以将评估器看作是一种封装了各种机器学习模型的工具。在Scikit-learn中进行模型训练的过程，其核心就是围绕着这些评估器展开的。")]),s._v(" "),a("p",[s._v('总的来说，这些不同库的核心对象类型都为处理特定任务提供了便捷，使得可以更加专注于问题的解决，而不需要深入底层去处理复杂的细节。"')]),s._v(" "),a("p",[s._v("围绕评估器的使用也基本分为两步，其一是实例化该对象，其二则是围绕某数据进行模型训练。")]),s._v(" "),a("h3",{attrs:{id:"高级特性-管道-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#高级特性-管道-pipeline"}},[s._v("#")]),s._v(" 高级特性-管道(Pipeline)")]),s._v(" "),a("p",[s._v("在Scikit-learn中，Pipeline是一种方便地将多个步骤组织在一起的工具，常常用于包含多个步骤的数据预处理和建模过程。Pipeline在确保步骤顺序执行，代码整洁，并在进行交叉验证时防止数据泄露方面有很大的优势。")]),s._v(" "),a("p",[s._v("Pipeline工作流程类似于生产线，每个步骤都是独立的，但所有的步骤都依次串联起来，上一步的输出作为下一步的输入。一个典型的Pipeline可能包括数据的缩放（如归一化或标准化）、特征选择、降维以及最后的模型训练等步骤。")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pipeline "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Pipeline\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("preprocessing "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" StandardScaler\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" LinearRegression\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" load_diabetes\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" train_test_split\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 加载糖尿病数据集")]),s._v("\ndiabetes "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" load_diabetes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nX_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" train_test_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("diabetes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" diabetes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建一个Pipeline")]),s._v("\npipe "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Pipeline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'scaler'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" StandardScaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 第一步是标准化")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'regressor'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" LinearRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 第二步是线性回归")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用Pipeline进行训练")]),s._v("\npipe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用Pipeline进行预测")]),s._v("\ny_pred "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pipe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\ny_pred\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br")])]),a("h3",{attrs:{id:"模型保存"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模型保存"}},[s._v("#")]),s._v(" 模型保存")]),s._v(" "),a("p",[s._v("模型保存（model persistence）是一种将训练好的机器学习模型保存到磁盘，然后在以后的时间点（可能是在不同的环境中）加载和使用的技术。这是非常有用的，因为通常训练一个好的模型可能需要大量的时间和计算资源。一旦模型被训练，我们可能希望在未来重新使用它，而不是每次需要时都重新训练。")]),s._v(" "),a("p",[s._v("在Scikit-learn中，可以使用Python的内置库"),a("code",[s._v("pickle")]),s._v("，或者"),a("code",[s._v("joblib")]),s._v("库（一种特别针对大数据的pickle）来实现模型保存和加载。")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ensemble "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" RandomForestClassifier\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" load_iris\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" joblib "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" dump"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" load\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 加载iris数据集并训练一个随机森林分类器")]),s._v("\niris "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" load_iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nclf "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" RandomForestClassifier"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nclf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("target"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将模型保存到磁盘")]),s._v("\ndump"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'randomforest_model.joblib'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在需要的时候加载模型")]),s._v("\nclf_loaded "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" load"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'randomforest_model.joblib'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用加载的模型进行预测")]),s._v("\ny_pred "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" clf_loaded"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("p",[s._v("以上代码中，"),a("code",[s._v("dump")]),s._v("函数将模型保存到指定的文件中，而"),a("code",[s._v("load")]),s._v("函数则从文件中加载模型。注意，保存和加载模型的代码通常不会在同一脚本或同一会话中运行，这里只是为了演示。")]),s._v(" "),a("p",[s._v("如果模型包含了大量的numpy数组（例如，神经网络或随机森林等模型），使用"),a("code",[s._v("joblib")]),s._v("可能比使用"),a("code",[s._v("pickle")]),s._v("更高效。因此，Scikit-learn官方文档推荐使用"),a("code",[s._v("joblib")]),s._v("来保存和加载模型。")]),s._v(" "),a("h2",{attrs:{id:"_5-使用scikit-learn实现线性回归建模"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-使用scikit-learn实现线性回归建模"}},[s._v("#")]),s._v(" 5. 使用Scikit-learn实现线性回归建模")]),s._v(" "),a("h3",{attrs:{id:"建模流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#建模流程"}},[s._v("#")]),s._v(" 建模流程")]),s._v(" "),a("p",[s._v("Step 1："),a("strong",[s._v("准备数据，生成1000个基本规律满足$y=2x_1-x_2+1$分布回归类数据集")])]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 科学计算模块")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" pd\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 绘图模块")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" mpl\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 回归数据创建函数")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("arrayGenReg")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_examples "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" bias "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" delta "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" deg "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""回归类数据集创建函数。\n\n    :param num_examples: 创建数据集的数据量\n    :param w: 包括截距的（如果存在）特征系数向量\n    :param bias：是否需要截距\n    :param delta：扰动项取值\n    :param deg：方程最高项次数\n    :return: 生成的特征张和标签张量\n    """')]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" bias "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        num_inputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("                                                           "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 数据集特征个数")]),s._v("\n        features_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("randn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_examples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                       "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 原始特征")]),s._v("\n        w_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 自变量系数")]),s._v("\n        b_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                                                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 截距")]),s._v("\n        labels_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("power"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" deg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" b_true                 "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 严格满足人造规律的标签")]),s._v("\n        features "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("concatenate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ones_like"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 加上全为1的一列之后的特征")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n        num_inputs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        features "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("randn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_examples"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_inputs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n        w_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("         \n        labels_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("power"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" deg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("w_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" labels_true "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("size "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" labels_true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" delta\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br")])]),a("p",[s._v("这段代码的目的是创建一个回归类数据集。它定义了一个函数"),a("code",[s._v("arrayGenReg")]),s._v("，用于生成具有特定规律的回归类数据集。该函数根据给定的参数生成特征和标签数据，并可以选择是否添加截距项。特征数据根据正态分布随机生成，而标签数据根据设定的规律进行计算，并添加了服从正态分布的扰动项。这个函数的目的是方便生成用于回归问题的人工数据集。")]),s._v(" "),a("p",[a("strong",[s._v("Step 2 : 根据函数生成特征和标签数据。")])]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置随机数种子")]),s._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("24")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 扰动项取值为0.01")]),s._v("\nfeatures"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" arrayGenReg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("delta"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("在这一步中，通过使用"),a("code",[s._v("np.random.seed(24)")]),s._v("设置了随机数种子为24。这样做的目的是确保接下来的随机生成过程可重复，即每次运行代码都会得到相同的随机数序列。然后，调用"),a("code",[s._v("arrayGenReg")]),s._v("函数生成回归类数据集的特征和标签。在这个例子中，将扰动项的取值设置为0.01，即"),a("code",[s._v("delta=0.01")]),s._v("。")]),s._v(" "),a("p",[a("strong",[s._v("Step3 : 绘制两个子图，观察数据集在不同特征维度上的分布情况")])]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 可视化数据分布")]),s._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("subplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("121")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'o'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("subplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("122")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'o'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("分别绘制特征矩阵"),a("code",[s._v("features")]),s._v("的第一列（"),a("code",[s._v("features[:, 0]")]),s._v("）、第二列（"),a("code",[s._v("features[:, 1]")]),s._v("）与标签列"),a("code",[s._v("labels")]),s._v("之间的关系。")]),s._v(" "),a("p",[a("strong",[s._v("Step 4：调用Scikit-learn中的线性回归评估器")])]),s._v(" "),a("p",[s._v("首先，从Scikit-learn库中导入线性回归评估器，使用"),a("code",[s._v("LinearRegression")]),s._v("评估器进行线性回归建模。")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" LinearRegression\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" LinearRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("接下来，从之前生成的数据集中提取特征矩阵和标签，特征矩阵选取了前两个特征（"),a("code",[s._v("features[:, :2]")]),s._v("），并将其赋值给"),a("code",[s._v("X")]),s._v("变量。将标签数组赋值给"),a("code",[s._v("y")]),s._v("变量。")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[s._v("codeX "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 特征矩阵，选择前两个特征")]),s._v("\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" labels  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 标签数组")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("最后，通过调用评估器中的"),a("code",[s._v("fit()")]),s._v("方法对模型进行训练：")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("通过这些步骤，线性回归模型将被训练并学习数据集中的模式和关联。")]),s._v(" "),a("p",[s._v("在机器学习中，评估器（Estimator）是用于学习数据模式和进行预测的对象。"),a("strong",[s._v("线性回归评估器（LinearRegression）是一种用于拟合线性模型的评估器。")])]),s._v(" "),a("p",[s._v("实例化评估器是为了创建一个可供使用的评估器对象。"),a("strong",[s._v("通过实例化，可以设置评估器的参数和属性，以便进行后续的训练和预测操作")]),s._v("。在这段代码中，通过使用"),a("code",[s._v("LinearRegression()")]),s._v("创建了一个线性回归评估器的实例，并将其赋值给"),a("code",[s._v("model")]),s._v("变量。")]),s._v(" "),a("p",[a("code",[s._v("fit()")]),s._v("方法是评估器的一个重要方法，用于对模型进行训练。"),a("strong",[s._v("在训练过程中，评估器根据提供的特征矩阵和标签数据，通过最小化损失函数来调整模型的参数，使其能够更好地拟合数据")]),s._v("。通过训练过程，模型能够学习特征与标签之间的关系，并建立一个预测模型。")]),s._v(" "),a("p",[s._v("综上所述，通过实例化评估器、提供特征矩阵和标签数据，以及调用"),a("code",[s._v("fit()")]),s._v("方法来进行模型训练，才能够使用评估器拟合数据，并得到一个能够预测未知样本的线性回归模型。")]),s._v(" "),a("p",[a("strong",[s._v("Step 5： 查看模型训练参数")])]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"自变量参数:"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("coef_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"模型截距:"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("intercept_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[a("strong",[s._v("Step 6: 结果解读")])]),s._v(" "),a("p",[s._v("自变量参数：模型学习到的自变量参数为 [[1.99961892, -0.99985281]]，接近于基本规律中的 [2, -1]。这表示模型能够很好地学习到数据生成的规律，并对特征之间的关系进行准确建模。")]),s._v(" "),a("p",[s._v("模型截距：模型学习到的截距为 [0.99970541]，接近于基本规律中的 1。这意味着即使没有特征输入时，模型预测的输出值仍接近于1。")]),s._v(" "),a("p",[s._v("因此，根据模型的自变量参数和截距结果，可以得出结论：线性回归模型成功地学习到了基本规律中的特征之间的关系，并能够对未知样本进行准确的预测。")]),s._v(" "),a("p",[a("strong",[s._v("Step 7: 使用MSE做模型评估")])]),s._v(" "),a("p",[s._v("可以使用Scikit-learn库中的均方误差（Mean Squared Error，MSE）计算函数，计算了预测值和真实标签之间的均方误差。")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在metrics模块下导入MSE计算函数")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("metrics "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" mean_squared_error\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输入数据，进行计算")]),s._v("\nmean_squared_error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("至此就完成了调用Scikit-learn的线性回归模型进行建模的流程")]),s._v(" "),a("h3",{attrs:{id:"超参数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#超参数"}},[s._v("#")]),s._v(" 超参数")]),s._v(" "),a("p",[s._v("超参数，指的是无法通过数学过程进行最优值求解、但却能够很大程度上影响模型形式和建模结果的因素，例如线性回归中，方程中自变量系数和截距项的取值是通过最小二乘法或者梯度下降算法求出的最优解，而是否带入带入截距项、是否对数据进行归一化等，这些因素同样会影响模型形态和建模结果，但却是“人工判断”然后做出决定的选项，而这些就是所谓的超参数。\n而Scikit-learn中，对每个评估器进行超参数设置的时机就在评估器类实例化的过程中。可以查看LinearRegression评估器的相关说明，其中Parameters部分就是当前模型超参数的相关说明：")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/python%2Fsk-learn_super_param.png",alt:""}})]),s._v(" "),a("p",[s._v("在上述Step 4过程中，直接使用的是：")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[s._v("model "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" LinearRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("这是因为使用的都是默认的参数，这些超参数可以在实例化过程中进行设置和修改，例如可以创建一个不包含截距项的线性方程模型：")]),s._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[s._v("model1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" LinearRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fit_intercept"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmodel1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("对于一个已经实例化好的评估器，可以通过get_params来获取其建模所用的参数")]),s._v(" "),a("p",[s._v("在实例化模型的过程中必须谨慎的选择模型超参数，以达到最终模型训练的预期。"),a("strong",[s._v("不同的模型，有不同的超参数，这也是在后面学习建模过程中非常重要的一点。")])]),s._v(" "),a("h2",{attrs:{id:"_6-模型保存"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-模型保存"}},[s._v("#")]),s._v(" 6. 模型保存")]),s._v(" "),a("blockquote",[a("p",[s._v("模型保存（model persistence）是一种将训练好的机器学习模型保存到磁盘，然后在以后的时间点（可能是在不同的环境中）加载和使用的技术。这是非常有用的，因为通常训练一个好的模型可能需要大量的时间和计算资源。一旦模型被训练，我们可能希望在未来重新使用它，而不是每次需要时都重新训练。")]),s._v(" "),a("p",[s._v("在Scikit-learn中，可以使用Python的内置库"),a("code",[s._v("pickle")]),s._v("，或者"),a("code",[s._v("joblib")]),s._v("库（一种特别针对大数据的pickle）来实现模型保存和加载。")])]),s._v(" "),a("h2",{attrs:{id:"_7-模型相关属性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-模型相关属性"}},[s._v("#")]),s._v(" 7. 模型相关属性")]),s._v(" "),a("p",[a("code",[s._v("coef_")]),s._v("是模型的系数(也称为权重或斜率)")]),s._v(" "),a("p",[a("code",[s._v("intercept_")]),s._v("是截距(也称为偏差)")])])}),[],!1,null,null,null);t.default=e.exports}}]);