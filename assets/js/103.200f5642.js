(window.webpackJsonp=window.webpackJsonp||[]).push([[103],{625:function(s,a,t){"use strict";t.r(a);var n=t(4),e=Object(n.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"_1-spark-运行模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-spark-运行模式"}},[s._v("#")]),s._v(" 1. Spark 运行模式")]),s._v(" "),t("p",[s._v("（1）Local：运行在一台机器上。测试用。")]),s._v(" "),t("p",[s._v("（2）Standalone：是Spark自身的一个调度系统。 对集群性能要求非常高时用。国内很少使用。")]),s._v(" "),t("p",[s._v("（3）Yarn：采用Hadoop的资源调度器。 国内大量使用。")]),s._v(" "),t("p",[s._v("​\t\tYarn-client模式：Driver运行在Client上（不在AM里）")]),s._v(" "),t("p",[s._v("​\t\tYarn-cluster模式：Driver在AM上")]),s._v(" "),t("p",[s._v("（4）Mesos：国内很少使用。")]),s._v(" "),t("p",[s._v("（5）K8S：趋势，但是目前不成熟，需要的配置信息太多。")]),s._v(" "),t("h2",{attrs:{id:"_2-spark-常用端口号"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-spark-常用端口号"}},[s._v("#")]),s._v(" 2. Spark 常用端口号")]),s._v(" "),t("p",[s._v("（1）4040 spark-shell任务端口")]),s._v(" "),t("p",[s._v("（2）7077 内部通讯端口。类比Hadoop的8020/9000")]),s._v(" "),t("p",[s._v("（3）8080 查看任务执行情况端口。 类比Hadoop的8088")]),s._v(" "),t("p",[s._v("（4）18080 历史服务器。类比Hadoop的19888")]),s._v(" "),t("p",[s._v("注意：由于Spark只负责计算，所有并没有Hadoop中存储数据的端口9870/50070。")]),s._v(" "),t("h2",{attrs:{id:"_3-rdd-五大属性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-rdd-五大属性"}},[s._v("#")]),s._v(" 3. RDD 五大属性")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2FRDD%2Frdd_5.png",alt:""}})]),s._v(" "),t("h2",{attrs:{id:"_4-rdd弹性体现在哪里"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-rdd弹性体现在哪里"}},[s._v("#")]),s._v(" 4. RDD弹性体现在哪里")]),s._v(" "),t("p",[s._v("主要表现为存储弹性、计算弹性、任务（Task、Stage）弹性、数据位置弹性，具体如下：")]),s._v(" "),t("p",[s._v("（1）自动进行内存和磁盘切换")]),s._v(" "),t("p",[s._v("（2）基于lineage(血缘)的高效容错")]),s._v(" "),t("p",[s._v("（3）Task如果失败会特定次数的重试")]),s._v(" "),t("p",[s._v("（4）Stage如果失败会自动进行特定次数的重试，而且只计算失败的分片")]),s._v(" "),t("p",[s._v("（5）Checkpoint【每次对RDD操作都会产生新的RDD，如果链条比较长，计算比较笨重，就把数据放在硬盘中】和persist 【内存或磁盘中对数据进行复用】(检查点、持久化)")]),s._v(" "),t("p",[s._v("（6）数据调度弹性：DAG Task 和资源管理无关")]),s._v(" "),t("p",[s._v("（7）数据分片的高度弹性repartion")]),s._v(" "),t("h2",{attrs:{id:"_5-spark-的转换算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-spark-的转换算子"}},[s._v("#")]),s._v(" 5. Spark 的转换算子")]),s._v(" "),t("h3",{attrs:{id:"_5-1-单-value"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-单-value"}},[s._v("#")]),s._v(" 5.1 单 Value")]),s._v(" "),t("p",[s._v("（1）map")]),s._v(" "),t("p",[s._v("（2）mapPartitions")]),s._v(" "),t("p",[s._v("（3）mapPartitionsWithIndex")]),s._v(" "),t("p",[s._v("（4）flatMap")]),s._v(" "),t("p",[s._v("（5）groupBy")]),s._v(" "),t("p",[s._v("（6）filter")]),s._v(" "),t("p",[s._v("（7）distinct")]),s._v(" "),t("p",[s._v("（8）coalesce")]),s._v(" "),t("p",[s._v("（9）repartition")]),s._v(" "),t("p",[s._v("（10）sortBy")]),s._v(" "),t("h3",{attrs:{id:"_4-2-双-value"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-双-value"}},[s._v("#")]),s._v(" 4.2 双 Value")]),s._v(" "),t("p",[s._v("（1）intersection")]),s._v(" "),t("p",[s._v("（2）union")]),s._v(" "),t("p",[s._v("（3）subtract")]),s._v(" "),t("p",[s._v("（4）zip")]),s._v(" "),t("h3",{attrs:{id:"_4-3-key-value"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-key-value"}},[s._v("#")]),s._v(" 4.3 Key-Value")]),s._v(" "),t("p",[s._v("（1）partitionBy")]),s._v(" "),t("p",[s._v("（2）reduceByKey")]),s._v(" "),t("p",[s._v("（3）groupByKey")]),s._v(" "),t("p",[s._v("（4）sortByKey")]),s._v(" "),t("p",[s._v("（5）mapValues")]),s._v(" "),t("p",[s._v("（6）join")]),s._v(" "),t("h2",{attrs:{id:"_6-spark-的行动算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-spark-的行动算子"}},[s._v("#")]),s._v(" 6. Spark 的行动算子")]),s._v(" "),t("p",[s._v("（1）reduce")]),s._v(" "),t("p",[s._v("（2）collect")]),s._v(" "),t("p",[s._v("（3）count")]),s._v(" "),t("p",[s._v("（4）first")]),s._v(" "),t("p",[s._v("（5）take")]),s._v(" "),t("p",[s._v("（6）save")]),s._v(" "),t("p",[s._v("（7）foreach")]),s._v(" "),t("h2",{attrs:{id:"_7-map和mappartitions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-map和mappartitions"}},[s._v("#")]),s._v(" 7. map和mapPartitions")]),s._v(" "),t("p",[s._v("（1）map：每次处理一条数据")]),s._v(" "),t("p",[s._v("（2）mapPartitions：每次处理一个分区数据")]),s._v(" "),t("h2",{attrs:{id:"_8-repartition和coalesce"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-repartition和coalesce"}},[s._v("#")]),s._v(" 8. Repartition和Coalesce")]),s._v(" "),t("p",[s._v("1）关系：")]),s._v(" "),t("p",[s._v("​\t两者都是用来改变RDD的partition数量的，repartition底层调用的就是coalesce方法：coalesce（numPartitions, shuffle = true）。")]),s._v(" "),t("p",[s._v("2）区别：")]),s._v(" "),t("p",[s._v("​\trepartition一定会发生Shuffle，coalesce根据传入的参数来判断是否发生Shuffle。")]),s._v(" "),t("p",[s._v("​\t一般情况下增大rdd的partition数量使用repartition，减少partition数量时使用coalesce。")]),s._v(" "),t("h2",{attrs:{id:"_9-reducebykey和groupbykey"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-reducebykey和groupbykey"}},[s._v("#")]),s._v(" 9. reduceByKey和groupByKey")]),s._v(" "),t("p",[s._v("reduceByKey：具有预聚合操作。")]),s._v(" "),t("p",[s._v("groupByKey：没有预聚合。")]),s._v(" "),t("p",[s._v("在不影响业务逻辑的前提下，优先采用reduceByKey。")]),s._v(" "),t("h2",{attrs:{id:"_10-spark中的血缘"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-spark中的血缘"}},[s._v("#")]),s._v(" 10. Spark中的血缘")]),s._v(" "),t("p",[s._v("flatMap")]),s._v(" "),t("p",[t("code",[s._v("MapPartitionRDD (MapPartitionRDD) extends RDD[OneToOneDep...]")])]),s._v(" "),t("p",[t("code",[s._v("this(oneParent.context, List(new OneToOneDependency(oneParent)))")])]),s._v(" "),t("p",[s._v("groupBy")]),s._v(" "),t("p",[t("code",[s._v("ShuffledRDD extends RDD[Nil]")])]),s._v(" "),t("p",[t("code",[s._v("ShuffleDependency")])]),s._v(" "),t("p",[s._v("宽依赖和窄依赖。有 Shuffle 的是宽依赖")]),s._v(" "),t("h2",{attrs:{id:"_11-spark任务的划分"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-spark任务的划分"}},[s._v("#")]),s._v(" 11. Spark任务的划分")]),s._v(" "),t("p",[s._v("（1）Application：初始化一个SparkContext即生成一个Application；")]),s._v(" "),t("p",[s._v("（2）Job：一个Action算子就会生成一个Job；")]),s._v(" "),t("p",[s._v("（3）Stage：Stage是Job的子集，Stage等于宽依赖的个数加1，因为由ResultStage开始向前找宽依赖区分Stage")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fcore%2Fstage_split.png",alt:""}})]),s._v(" "),t("p",[s._v("（4）Task：Task是Stage的子集，每一个Stage阶段中，最后一个RDD的分区数量之和")]),s._v(" "),t("h2",{attrs:{id:"_12-sparksql-中rdd、df、ds"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12-sparksql-中rdd、df、ds"}},[s._v("#")]),s._v(" 12. SparkSQL 中RDD、DF、DS")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Frdd_df_ds.png",alt:""}})]),s._v(" "),t("p",[s._v("DataFrame和DataSet的区别：前者是row类型")]),s._v(" "),t("p",[s._v("RDD和DataSet及DataSet的区别：前者没有字段和表信息")]),s._v(" "),t("h2",{attrs:{id:"_13-hiveonspark和sparkonhive"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_13-hiveonspark和sparkonhive"}},[s._v("#")]),s._v(" 13. HiveOnSpark和SparkOnHive")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th"),s._v(" "),t("th",[t("strong",[s._v("元数据")])]),s._v(" "),t("th",[t("strong",[s._v("执行引擎")])]),s._v(" "),t("th",[t("strong",[s._v("语法")])]),s._v(" "),t("th",[t("strong",[s._v("生态")])])])]),s._v(" "),t("tbody",[t("tr",[t("td",[t("strong",[s._v("Hive on Spark")])]),s._v(" "),t("td",[s._v("MySQL")]),s._v(" "),t("td",[s._v("rdd")]),s._v(" "),t("td",[s._v("HQL")]),s._v(" "),t("td",[s._v("更加完善")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("Spark on Hive (Spark SQL )")])]),s._v(" "),t("td",[s._v("MySQL")]),s._v(" "),t("td",[s._v("df  ds")]),s._v(" "),t("td",[s._v("Spark SQL")]),s._v(" "),t("td",[s._v("有欠缺（权限管理、元数据管理）")])]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("内置Hive")])]),s._v(" "),t("td",[s._v("derby")]),s._v(" "),t("td"),s._v(" "),t("td"),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[t("strong",[s._v("外置Hive")])]),s._v(" "),t("td",[s._v("MySQL")]),s._v(" "),t("td"),s._v(" "),t("td"),s._v(" "),t("td")])])]),s._v(" "),t("h2",{attrs:{id:"_14-spark内核源码-重点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_14-spark内核源码-重点"}},[s._v("#")]),s._v(" 14. Spark内核源码(重点)")]),s._v(" "),t("p",[s._v("Job 切分为 Stage，Stage 切分为 Task")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fcore%2Fspark_flow.png",alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fcore%2Fspark_flow3.png",alt:""}})]),s._v(" "),t("h3",{attrs:{id:"_1-提交流程-重点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-提交流程-重点"}},[s._v("#")]),s._v(" 1）提交流程（重点）")]),s._v(" "),t("h4",{attrs:{id:"yarnclient-模式提交流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#yarnclient-模式提交流程"}},[s._v("#")]),s._v(" YarnClient 模式提交流程")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fyarnclient_submit.png",alt:""}})]),s._v(" "),t("p",[s._v("YarnCluster 模式提交流程")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fyarncluster_submit.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"stage-任务划分"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#stage-任务划分"}},[s._v("#")]),s._v(" Stage 任务划分")]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建结果阶段")]),s._v("\ncreateResultStage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" ResultStage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" partiitons"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" parents"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" jobId"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" callSite"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 获取或创建上级阶段")]),s._v("\nparents"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v("\ngetOrCreateParentStages\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("\ngetShuffleDependencies"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("map "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  shuffleDep "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v("\n  \tgetOrCreateShuffleMapStage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("shuffleDep"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" firstJobId"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toList\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 获取或创建ShuffleMap阶段")]),s._v("\ngetOrCreateShuffleMapStage\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fstage_split.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"task-任务调度执行"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#task-任务调度执行"}},[s._v("#")]),s._v(" Task 任务调度执行")]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("isEmpty"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  logInfo"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Submitting "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" stage "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('" ("')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" stage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rdd "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"), which has no missing parents"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  submitMissingTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("stage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" jobId"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("parent "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("<-")]),s._v(" missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    submitStage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("parent"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  waitingStages "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" stage\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[s._v("stage"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("findMissingParittions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" tasks"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("Task"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" ShuffleMapTask"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 计算分区，由此可得，Task数量为每个Stage中最后一个RDD的分区数量之和")]),s._v("\npartitionsToCopute\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Ftask.png",alt:""}})]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[s._v("TaskScheduler"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("submitTasks"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("taskSet"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" TaskSet"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v("\ncreateTaskManager"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("h3",{attrs:{id:"_2-shuffle流程-重点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-shuffle流程-重点"}},[s._v("#")]),s._v(" 2）Shuffle流程（重点）")]),s._v(" "),t("p",[s._v("（1）SortShuffle：减少了小文件。")]),s._v(" "),t("p",[s._v("中间落盘应该是本地磁盘")]),s._v(" "),t("p",[s._v("生成的文件数 = Task数量 * 2")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2FsortShuffle.png",alt:""}})]),s._v(" "),t("p",[s._v("​\t在溢写磁盘前，先根据key进行排序，排序过后的数据，会分批写入到磁盘文件中。默认批次为"),t("strong",[s._v("10000")]),s._v("条，数据会以每批一万条写入到磁盘文件。写入磁盘文件通过缓冲区溢写的方式，每次溢写都会产生一个磁盘文件，"),t("strong",[s._v("也就是说一个Task过程会产生多个临时文件。最后在每个Task中，将所有的临时文件合并，这就是merge过程，此过程将所有临时文件读取出来，一次写入到最终文件。")])]),s._v(" "),t("p",[s._v("（2）Hash Shuffle：大量中间磁盘文件，影响性能，Spark 1.2 以后，默认的ShuffleManager 改成了 SortShuffle")]),s._v(" "),t("p",[s._v("（3）bypassShuffle：减少了小文件，不排序，效率高。在不需要排序的场景使用。")]),s._v(" "),t("h2",{attrs:{id:"_15-spark统一内存模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_15-spark统一内存模型"}},[s._v("#")]),s._v(" 15. Spark统一内存模型")]),s._v(" "),t("p",[s._v("1）统一内存管理的堆内内存结构如下图")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fspark_heap.png",alt:""}})]),s._v(" "),t("p",[s._v("2）统一内存管理的动态占用机制如下图")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fspark_dny.png",alt:""}})]),s._v(" "),t("h2",{attrs:{id:"_16-spark为什么比mr快"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_16-spark为什么比mr快"}},[s._v("#")]),s._v(" 16. Spark为什么比MR快")]),s._v(" "),t("p",[s._v("1）内存&硬盘")]),s._v(" "),t("p",[s._v("（1）MR在Map阶段会在溢写阶段将中间结果频繁的写入磁盘，在Reduce阶段再从磁盘拉取数据。频繁的磁盘IO消耗大量时间。")]),s._v(" "),t("p",[s._v("（2）Spark不需要将计算的中间结果写入磁盘。这得益于Spark的RDD，在各个RDD的分区中，各自处理自己的中间结果即可。在迭代计算时，这一优势更为明显。")]),s._v(" "),t("p",[s._v("2）Spark DAG任务划分减少了不必要的Shuffle")]),s._v(" "),t("p",[s._v("（1）对MR来说，每一个Job的结果都会落地到磁盘。后续依赖于次Job结果的Job，会从磁盘中读取数据再进行计算。")]),s._v(" "),t("p",[s._v("（2）对于Spark来说，每一个Job的结果都可以保存到内存中，供后续Job使用。配合Spark的缓存机制，大大的减少了不必要的Shuffle。")]),s._v(" "),t("p",[s._v("3）资源申请粒度：进程&线程")]),s._v(" "),t("p",[s._v("​\t开启和调度进程的代价一般情况下大于线程的代价。")]),s._v(" "),t("p",[s._v("（1）MR任务以进程的方式运行在Yarn集群中。N个MapTask就要申请N个进程")]),s._v(" "),t("p",[s._v("（2）Spark的任务是以线程的方式运行在进程中。N个MapTask就要申请N个线程。")]),s._v(" "),t("h2",{attrs:{id:"_17-spark和hadoop的shuffle"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_17-spark和hadoop的shuffle"}},[s._v("#")]),s._v(" 17. Spark和Hadoop的shuffle")]),s._v(" "),t("p",[s._v("（1）Hadoop不用等所有的MapTask都结束后开启ReduceTask；Spark必须等到父Stage都完成，才能去Fetch数据。")]),s._v(" "),t("p",[s._v("（2）Hadoop的Shuffle是必须排序的，那么不管是Map的输出，还是Reduce的输出，都是分区内有序的，而Spark不要求这一点。")]),s._v(" "),t("h2",{attrs:{id:"_18-spark提交作业参数-重点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_18-spark提交作业参数-重点"}},[s._v("#")]),s._v(" 18. Spark提交作业参数(重点)")]),s._v(" "),t("p",[s._v("https://blog.csdn.net/gamer_gyt/article/details/79135118")]),s._v(" "),t("p",[s._v("1）在提交任务时的几个重要参数")]),s._v(" "),t("p",[s._v("executor-cores —— 每个executor使用的内核数，默认为1，官方建议2-5个，我们企业是4个")]),s._v(" "),t("p",[s._v("num-executors —— 启动executors的数量，默认为2")]),s._v(" "),t("p",[s._v("executor-memory —— executor内存大小，默认1G")]),s._v(" "),t("p",[s._v("driver-cores —— driver使用内核数，默认为1")]),s._v(" "),t("p",[s._v("driver-memory —— driver内存大小，默认512M")]),s._v(" "),t("p",[s._v("2）给一个提交任务的样式")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("spark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --master local"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --driver-cores "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --driver-memory 8g "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --executor-cores "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --num-executors "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --executor-memory 8g "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --class PackageName.ClassName XXXX.jar "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  --name "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Spark Job Name"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  InputPath      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n  OutputPath\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("h2",{attrs:{id:"_19-spark-任务使用什么提交"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_19-spark-任务使用什么提交"}},[s._v("#")]),s._v(" 19. Spark 任务使用什么提交")]),s._v(" "),t("p",[s._v("Shell脚本。海豚调度器可以通过页面提交Spark任务。")]),s._v(" "),t("h2",{attrs:{id:"_20-spark中的shuffle算子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_20-spark中的shuffle算子"}},[s._v("#")]),s._v(" 20. Spark中的Shuffle算子")]),s._v(" "),t("p",[s._v("reduceBykey：")]),s._v(" "),t("p",[s._v("groupByKey：")]),s._v(" "),t("p",[s._v("…ByKey：")]),s._v(" "),t("h2",{attrs:{id:"_21-spark操作数据库时-减少连接数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_21-spark操作数据库时-减少连接数"}},[s._v("#")]),s._v(" 21. Spark操作数据库时，减少连接数")]),s._v(" "),t("p",[s._v("使用foreachPartition代替foreach，在foreachPartition内获取数据库的连接。")]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" MyDriver "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" Driver "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" Serializable "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" getParentLogger"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Logger "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 最佳实践：在此处创建一个 Driver的代理对象，全局只执行一次")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//    val agent: Driver = new DriverAgent()")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" agent "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" MyDriver"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    println"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"创建 driver-agent => "')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("agent"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toString"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    wordToOneDStream"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("foreachRDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      rdd "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 在 Driver 端执行 (JobScheduler), 一个批次一次但是会有序列化问题")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 在 JobScheduler中查找 streaming-job-executor")]),s._v("\n        println"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"222222:"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" Thread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("currentThread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//创建mysql连接对象  //driver (此处创建会有序列化问题)")]),s._v("\n\n        rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("foreachPartition "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//5.1 测试代码")]),s._v("\n          iter "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//创建mysql连接对象  //executor 在此处创建最佳? (不使用代理的情况下最佳)")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//            val driver = new Driver()")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//5.2 业务代码")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hasNext"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" s"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" iter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_1\n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" sql"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"insert into sensor values (\'"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" s "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"\', 1607527992000, 70)"')]),s._v("\n              println"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sql"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n              save"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("saveByConnection"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("agent"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" sql"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br")])]),t("h2",{attrs:{id:"_22-spark-数据倾斜"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_22-spark-数据倾斜"}},[s._v("#")]),s._v(" 22. Spark 数据倾斜")]),s._v(" "),t("p",[s._v("Hive On Spark")]),s._v(" "),t("h3",{attrs:{id:"_22-1-分组聚合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_22-1-分组聚合"}},[s._v("#")]),s._v(" 22.1 分组聚合")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n\tprovince_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("count")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" dwd_trade_order_detail_inc\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" dt"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2023-07-06'")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("group")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" province_id\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("ol",[t("li",[t("p",[s._v("判断倾斜的值是否为 null，如果是null，考虑最终结果是否需要，若不需要则提前过滤，若要保留，参考下面")])]),s._v(" "),t("li",[t("p",[s._v("Map-site 聚合")]),s._v(" "),t("blockquote",[t("p",[s._v("开启Map-Side聚合后，数据会现在Map端完成部分聚合工作。这样一来即便原始数据是倾斜的，经过Map端的初步聚合后，发往Reduce的数据也就不再倾斜了。最佳状态下，Map端聚合能完全屏蔽数据倾斜问题。")]),s._v(" "),t("p",[s._v("相关参数如下：")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.map.aggr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.map.aggr.hash.min.reduction"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.groupby.mapaggr.checkinterval"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.map.aggr.hash.force.flush.memory.threshold"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])])])]),s._v(" "),t("li",[t("p",[s._v("Skew-GroupBy 随机数分区")]),s._v(" "),t("blockquote",[t("p",[s._v("Skew-GroupBy是Hive提供的一个专门用来解决分组聚合导致的数据倾斜问题的方案。其原理是启动两个MR任务，第一个MR按照随机数分区，将数据分散发送到Reduce，并完成部分聚合，第二个MR按照分组字段分区，完成最终聚合。")]),s._v(" "),t("p",[s._v("相关参数如下：")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 启用分组聚合数据倾斜优化")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.groupby.skewindata"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])])])])]),s._v(" "),t("h3",{attrs:{id:"_22-2-join-导致"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_22-2-join-导致"}},[s._v("#")]),s._v(" 22.2 Join 导致")]),s._v(" "),t("p",[s._v("​\t若Join操作使用的是Common Join算法，就会通过一个MapReduce Job完成计算。Map端负责读取Join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。")]),s._v(" "),t("p",[s._v("​\t如果关联字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。")]),s._v(" "),t("p",[s._v("​\t由Join导致的数据倾斜问题，有如下解决思路：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("Map Join (大表 join 小表)")]),s._v(" "),t("blockquote",[t("p",[s._v("使用Map Join算法，Join操作仅在Map端就能完成，没有Shuffle操作，没有Reduce阶段，自然不会产生Reduce端的数据倾斜。该方案适用于大表Join小表时发生数据倾斜的场景。")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.auto.convert.join"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.auto.convert.join.noconditionaltask"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.auto.convert.join.noconditionaltask.size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])])])]),s._v(" "),t("li",[t("p",[s._v("Skew Join")]),s._v(" "),t("blockquote",[t("p",[s._v("​\t若参与Join的两表均为大表，Map Join就难以应对了。此时可考虑Skew Join，其核心原理是Skew Join的原理是，为倾斜的大key单独启动一个Map Join任务进行计算，其余key进行正常的Common Join。原理图如下：(参考 Hive 优化)")]),s._v(" "),t("p",[s._v("参数：")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 启用skew join优化")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.optimize.skewjoin"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 触发skew join的阈值，若某个key的行数超过该参数值，则触发")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" hive.skewjoin.key"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])])])])]),s._v(" "),t("h3",{attrs:{id:"_22-3-sql优化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_22-3-sql优化"}},[s._v("#")]),s._v(" 22.3 SQL优化")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[s._v("hive "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("default")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" A\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),s._v(" B\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" A"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("B"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("将 分组字段添加随机数")]),s._v(" "),t("div",{staticClass:"language-sql line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--打散操作")]),s._v("\n        concat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("cast"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("value")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" A\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("ta\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("join")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--扩容操作")]),s._v("\n        concat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("value")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" B\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("union")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("all")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v("\n        concat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("value")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" B\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("tb\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" ta"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("tb"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br")])]),t("h2",{attrs:{id:"_23-源码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_23-源码"}},[s._v("#")]),s._v(" 23. 源码")])])}),[],!1,null,null,null);a.default=e.exports}}]);