(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{571:function(a,s,t){"use strict";t.r(s);var n=t(4),e=Object(n.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"_1-flink"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-flink"}},[a._v("#")]),a._v(" 1. Flink")]),a._v(" "),t("blockquote",[t("p",[a._v("https://flink.apache.org/")]),a._v(" "),t("p",[a._v("​\tFlink项目的理念是：“Apache Flink是为分布式、高性能、随时可用以及准确的流处理应用程序打造的开源的有状态的流处理框架”。")]),a._v(" "),t("p",[a._v("​\tApache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fflink_work.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_1-1-事件驱动型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-事件驱动型"}},[a._v("#")]),a._v(" 1.1 事件驱动型")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。比较典型的就是以kafka为代表的消息队列几乎都是事件驱动型应用。(Flink的计算也是事件驱动型)")])]),a._v(" "),t("p",[a._v("SparkStreaming 微批次")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fsparkstreaming.png",alt:""}})]),a._v(" "),t("p",[a._v("事件驱动型：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fflink_event.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_1-2-流与批的世界观"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-流与批的世界观"}},[a._v("#")]),a._v(" 1.2 流与批的世界观")]),a._v(" "),t("ul",[t("li",[a._v("批处理的特点是有界、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。")]),a._v(" "),t("li",[a._v("流处理的特点是无界、实时,  无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。")]),a._v(" "),t("li",[a._v("在spark的世界观中，一切都是由批次组成的，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。")]),a._v(" "),t("li",[a._v("而在flink的世界观中，一切都是由流组成的，离线数据是有界限的流，实时数据是一个没有界限的流，这就是所谓的有界流和无界流。")])]),a._v(" "),t("h4",{attrs:{id:"无界数据流"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#无界数据流"}},[a._v("#")]),a._v(" 无界数据流：")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t无界数据流有一个开始但是没有结束，它们不会在生成时终止并提供数据，必须连续处理无界流，也就是说必须在获取后立即处理event。对于无界数据流我们无法等待所有数据都到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）获取event，以便能够推断结果完整性。")])]),a._v(" "),t("h4",{attrs:{id:"有界数据流"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#有界数据流"}},[a._v("#")]),a._v(" 有界数据流：")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t有界数据流有明确定义的 开始和结束，可以在执行任何计算之前通过获取所有数据来处理有界流，处理有界流不需要有序获取，因为可以始终对有界数据集进行排序，有界流的处理也称为批处理。")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fboundorunbound.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_1-3-分层-api"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-分层-api"}},[a._v("#")]),a._v(" 1.3 分层 API")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fflink_api.png",alt:""}})]),a._v(" "),t("p",[a._v("​\t最底层级的抽象仅仅提供了有状态流，它将通过过程函数（Process Function）被嵌入到DataStream API中。底层过程函数（Process Function） 与 DataStream API 相集成，使其可以对某些特定的操作进行底层的抽象，它允许用户可以自由地处理来自一个或多个数据流的事件，并使用一致的容错的状态。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以处理复杂的计算。")]),a._v(" "),t("p",[a._v("​\t实际上，大多数应用并不需要上述的底层抽象，而是针对核心API（Core APIs） 进行编程，比如DataStream API（有界或无界流数据）以及DataSet API（有界数据集）。这些API为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换（transformations），连接（joins），聚合（aggregations），窗口操作（windows）等等。DataSet API 为有界数据集提供了额外的支持，例如循环与迭代。这些API处理的数据类型以类（classes）的形式由各自的编程语言所表示。")]),a._v(" "),t("p",[a._v("​\tTable API 是以表为中心的声明式编程，其中表可能会动态变化（在表达流数据时）。Table API遵循（扩展的）关系模型：表有二维数据结构（schema）（类似于关系数据库中的表），同时API提供可比较的操作，例如select、project、join、group-by、aggregate等。Table API程序声明式地定义了什么逻辑操作应该执行，而不是准确地确定这些操作代码的看上去如何。")]),a._v(" "),t("p",[a._v("​\t尽管Table API可以通过多种类型的用户自定义函数（UDF）进行扩展，其仍不如核心API更具表达能力，但是使用起来却更加简洁（代码量更少）。除此之外，Table API程序在执行之前会经过内置优化器进行优化。")]),a._v(" "),t("p",[a._v("​\t你可以在表与 DataStream/DataSet 之间无缝切换，以允许程序将 Table API 与 DataStream 以及 DataSet 混合使用。")]),a._v(" "),t("p",[a._v("​\tFlink提供的最高层级的抽象是 SQL 。这一层抽象在语法与表达能力上与 Table API 类似，但是是以SQL查询表达式的形式表现程序。SQL抽象与Table API交互密切，同时SQL查询可以直接在Table API定义的表上执行。")]),a._v(" "),t("p",[a._v("​\t目前Flink作为批处理还不是主流，不如Spark成熟，所以DataSet使用的并不是很多。Flink Table API和Flink SQL也并不完善，大多都由各大厂商自己定制。所以我们主要学习"),t("strong",[a._v("DataStream API")]),a._v("的使用。实际上Flink作为最接近Google DataFlow模型的实现，是流批统一的观点，所以基本上使用DataStream就可以了。")]),a._v(" "),t("p",[a._v("​\t2020年12月8日发布的最新版本"),t("strong",[a._v("1.12.0")]),a._v(", 已经完成实现了真正的"),t("strong",[a._v("流批一体")]),a._v(".写好的一套代码, 即可以处理流式数据, 也可以处理离线数据. 这个与前面版本的处理有界流的方式是不一样的, Flink专门对批处理数据做了优化处理.")]),a._v(" "),t("h3",{attrs:{id:"_1-4-spark-or-flink"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-spark-or-flink"}},[a._v("#")]),a._v(" 1.4 Spark or Flink")]),a._v(" "),t("p",[a._v("​\tSpark 和 Flink 一开始都拥有着同一个梦想，他们都希望能够用同一个技术把流处理和批处理统一起来，但他们走了完全不一样的两条路前者是以批处理的技术为根本，并尝试在批处理之上支持流计算；后者则认为流计算技术是最基本的，在流计算的基础之上支持批处理。正因为这种架构上的不同，今后二者在能做的事情上会有一些细微的区别。比如在低延迟场景，Spark 基于微批处理的方式需要同步会有额外开销，因此无法在延迟上做到极致。在大数据处理的低延迟场景，Flink 已经有非常大的优势。")]),a._v(" "),t("p",[a._v("​\tSpark和Flink的主要差别就在于"),t("strong",[a._v("计算模型不同")]),a._v("。Spark采用了微批处理模型，而Flink采用了基于操作符的连续流模型。因此，对Apache Spark和Apache Flink的选择实际上变成了计算模型的选择，而这种选择需要在延迟、吞吐量和可靠性等多个方面进行权衡。")]),a._v(" "),t("p",[a._v("​\t如果企业中非要技术选型从Spark和Flink这两个主流框架中选择一个来进行流数据处理，"),t("strong",[a._v("推荐使用Flink")]),a._v("，主要的原因为：")]),a._v(" "),t("ul",[t("li",[a._v("Flink灵活的窗口")]),a._v(" "),t("li",[a._v("Exactly Once 语义保证")])]),a._v(" "),t("h2",{attrs:{id:"_2-flink-部署"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-flink-部署"}},[a._v("#")]),a._v(" 2. Flink 部署")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("Flink提交任务参数\nflink 执行任务脚本\nrun 执行作业（ApplicationMode模式除外）\nrun-Applicaiton\n-d 后台运行（断开与客户端连接）\n-m 指定JobManager\n-c 指定全类名\n-D 如果要指定其他配置，可以跟在—D后面 格式：（-D参数名"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("参数值）\n-t 指定以yarn的什么模式来提交作业 yarn-pro-job  yarn-session yarn-application\n-p 提交任务时指定并行度\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br")])]),t("h3",{attrs:{id:"_2-1-local-cluster-模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-local-cluster-模式"}},[a._v("#")]),a._v(" 2.1 local-cluster 模式")]),a._v(" "),t("p",[a._v("无需配置")]),a._v(" "),t("p",[a._v("将 WordCount jar包上传")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 启动本地集群")]),a._v("\nbin/start-cluster.sh\n\nbin/flink run -m hadoop102:8081 -c com.awaken.flink.UnBoundedStreamWordCount ./flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br")])]),t("p",[a._v("http://hadoop102:8081")]),a._v(" "),t("p",[a._v("Task Managers 查看输出情况")]),a._v(" "),t("p",[a._v("也可以在日志中查看：")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cat")]),a._v(" flink-saberlind-taskexecutor-0-hadoop102.out\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("也可以在 WEB UI 中提交应用：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fflink_webui.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_2-2-standalone-模式配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-standalone-模式配置"}},[a._v("#")]),a._v(" 2.2 Standalone 模式配置")]),a._v(" "),t("p",[a._v("vim flink-conf.yaml")]),a._v(" "),t("div",{staticClass:"language-yaml line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-yaml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("jobmanager.rpc.address")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" hadoop102\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("vim works")]),a._v(" "),t("div",{staticClass:"language-conf line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("hadoop102\nhadoop103\nhadoop104\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("xsync flink-standalone/\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("运行无界流 WordCount")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/start-cluster.sh\n\nbin/flink run -m hadoop102:8081 -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("p",[a._v("也支持 Web UI 界面提交 Flink应用")]),a._v(" "),t("h4",{attrs:{id:"standalone-高可用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone-高可用"}},[a._v("#")]),a._v(" Standalone 高可用")]),a._v(" "),t("p",[a._v("vim flink-conf.yaml")]),a._v(" "),t("div",{staticClass:"language-yaml line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-yaml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" zookeeper\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.storageDir")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" hdfs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("//hadoop102"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("8020/flink/standalone/ha\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.zookeeper.quorum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" hadoop102"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2181")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("hadoop103"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2181")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("hadoop104"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2181")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.zookeeper.path.root")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" /flink"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("-")]),a._v("standalone\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.cluster-id")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" /cluster_saberlind\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br")])]),t("p",[a._v("vim masters")]),a._v(" "),t("div",{staticClass:"language-conf line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("hadoop102:8081\nhadoop103:8081\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br")])]),t("p",[a._v("vim /etc/profile.d/my_env.sh  添加环境变量")]),a._v(" "),t("div",{staticClass:"language-sh line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),a._v("hadoop classpath"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("xsync "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(".\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("启动集群")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/start-cluster.sh\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 查看 leader")]),a._v("\nget /flink-standalone/cluster_saberlind/leader/rest_server_lock\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br")])]),t("h3",{attrs:{id:"_2-3-yarn-模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-yarn-模式"}},[a._v("#")]),a._v(" 2.3 Yarn 模式")]),a._v(" "),t("ol",[t("li",[a._v("Session 适合用于规模小短时间运行的作业")]),a._v(" "),t("li",[a._v("per-job 适合用于规模大长时间运行的作业（用于测试）")]),a._v(" "),t("li",[a._v("applicationMode模式 适合用于规模大长时间运行的作业（用于生产，但是当开启yarn模式的高可用的话有Bug，jobId全为0，因为生产模式依然用per-job）")])]),a._v(" "),t("p",[a._v("Yarn 模式配置")]),a._v(" "),t("p",[a._v("vim /etc/profile.d/my_env.sh")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")]),a._v("hadoop classpath"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("`")])]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"_2-4-flink-on-yarn-三种部署模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-flink-on-yarn-三种部署模式"}},[a._v("#")]),a._v(" 2.4 Flink On Yarn 三种部署模式")]),a._v(" "),t("h4",{attrs:{id:"per-job-cluster"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#per-job-cluster"}},[a._v("#")]),a._v(" Per-Job-Cluster")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t一个Job会对应一个Flink集群，每提交一个作业会根据自身的情况，都会单独向yarn申请资源，直到作业执行完成，一个作业的失败与否并不会影响下一个作业的正常提交和运行。独享Dispatcher和ResourceManager，按需接受资源申请；"),t("strong",[a._v("适合规模大长时间运行的作业")]),a._v("。")]),a._v(" "),t("p",[a._v("​\t每次提交都会创建一个新的flink集群，任务之间互相独立，互不影响，方便管理。任务执行完成之后创建的集群也会消失。")])]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/flink run -d -t yarn-per-job -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 提交到 Yarn 的其他队列")]),a._v("\nbin/flink run -d -m yarn-cluster -yqu hive -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar（老版本）\n\nbin/flink run -d -t yarn-per-job -Dyarn.application.queue"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("hive -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br")])]),t("h4",{attrs:{id:"session-cluster"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#session-cluster"}},[a._v("#")]),a._v(" Session-Cluster")]),a._v(" "),t("blockquote",[t("p",[a._v("​\tSession-Cluster模式需要先启动Flink集群，向Yarn申请资源。以后提交任务都向这里提交。这个Flink集群会常驻在yarn集群中，除非手工停止。\n​\t在向Flink集群提交Job的时候, 如果资源被用完了,则新的Job不能正常提交.\n缺点: 如果提交的作业中有长时间执行的大作业, 占用了该Flink集群的所有资源, 则后续无法提交新的job.\n所以, Session-Cluster"),t("strong",[a._v("适合那些需要频繁提交的多个小Job, 并且执行时间都不长的Job")]),a._v(".")])]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("yarn")]),a._v(" application -list\n\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("yarn")]),a._v(" application -kill appID\n\nflink cancel\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 启动一个 Flink-Session")]),a._v("\nbin/yarn-session.sh -d\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br")])]),t("p",[a._v("在 Session上运行 Job")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/flink run -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("会自动找到你的yarn-session启动的Flink集群.也可以手动指定你的yarn-session集群:")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/flink run -t yarn-session -Dyarn.application.id"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("application_XXXX_YY -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("注意: application_XXXX_YY 指的是在yarn上启动的yarn应用\n如果是开启了Yarn模式的高可用，上面指定yarn-session集群的命令不能用，需要去掉 -t yarn-session")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/flink run -Dyarn.application.id"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("application_XXXX_YY -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h4",{attrs:{id:"application-mode"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#application-mode"}},[a._v("#")]),a._v(" Application Mode")]),a._v(" "),t("p",[a._v("​\tApplication Mode会在Yarn上启动集群, 应用jar包的main函数(用户类的main函数)将会在JobManager上执行. 只要应用程序执行结束, Flink集群会马上被关闭. 也可以手动停止集群.")]),a._v(" "),t("p",[a._v("​\t与Per-Job-Cluster的区别：就是Application Mode下, 用户的main函数式在集群中执行的，并且当一个application中有多个job的话，"),t("strong",[a._v("per-job模式则是一个job对应一个yarn中的application，而Application Mode则这个application中对应多个job。")])]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/flink run-application -t yarn-application -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/flink run-application -t yarn-application -Dyarn.application.queue"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("hive -c com.awaken.flink.UnBoundedStreamWordCount "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("/flink-local/flink-demo.jar\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"_2-5-yarn-模式高可用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-yarn-模式高可用"}},[a._v("#")]),a._v(" 2.5 Yarn 模式高可用")]),a._v(" "),t("blockquote",[t("p",[a._v("​\tYarn模式的高可用和Standalone模式的高可用原理不一样。")]),a._v(" "),t("p",[a._v("​\tStandalone模式中, 同时启动多个Jobmanager, 一个为leader其他为standby的, 当leader挂了, 其他的才会有一个成为leader。")]),a._v(" "),t("p",[a._v("​\tyarn的高可用是同时只启动一个Jobmanager, 当这个Jobmanager挂了之后, yarn会再次启动一个, 其实是利用的yarn的重试次数来实现的高可用。")])]),a._v(" "),t("p",[a._v("配置：")]),a._v(" "),t("p",[a._v("yarn-site.xml")]),a._v(" "),t("div",{staticClass:"language-xml line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-xml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("yarn.resourcemanager.am.max-attempts"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("4"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("description")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    The maximum number of application master execution attempts.\n  "),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("description")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token tag"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br")])]),t("p",[a._v("分发，重启 yarn")]),a._v(" "),t("p",[a._v("flink-conf.xml")]),a._v(" "),t("div",{staticClass:"language-yaml line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-yaml"}},[t("code",[t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("yarn.application-attempts")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" zookeeper\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.storageDir")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" hdfs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("//hadoop102"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("8020/flink/yarn/ha\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.zookeeper.quorum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" hadoop102"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2181")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("hadoop103"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2181")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("hadoop104"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2181")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token key atrule"}},[a._v("high-availability.zookeeper.path.root")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" /flink"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("-")]),a._v("yarn\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br")])]),t("h3",{attrs:{id:"_2-6-scala-repl"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-scala-repl"}},[a._v("#")]),a._v(" 2.6 Scala REPL")]),a._v(" "),t("p",[a._v("local 模式启动 REPL")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/start-scala-shell.sh "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("local")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("yarn-session 模式启动")]),a._v(" "),t("p",[a._v("先启动一个 yarn-session，然后就可以把 shell 跑在 yarn-session上了")]),a._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[a._v("bin/start-scala-shell.sh "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("yarn")]),a._v("\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h3",{attrs:{id:"_2-7-k8s-mesos-模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-k8s-mesos-模式"}},[a._v("#")]),a._v(" 2.7 K8S & Mesos 模式")]),a._v(" "),t("p",[a._v("待补充...")]),a._v(" "),t("h2",{attrs:{id:"_3-flink-运行架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-flink-运行架构"}},[a._v("#")]),a._v(" 3. Flink 运行架构")]),a._v(" "),t("blockquote",[t("p",[a._v("Flink 运行时包含 2 种进程：1个 JobManager 和 1个 TaskManager")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fflink_work_struct.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_3-1-客户端"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-客户端"}},[a._v("#")]),a._v(" 3.1 客户端")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t严格上说, 客户端不是运行和程序执行的一部分, 而是用于准备和发送dataflow到JobManager. 然后客户端可以断开与JobManager的连接(detached mode), 也可以继续保持与JobManager的连接(attached mode)")]),a._v(" "),t("p",[a._v("​\t客户端作为触发执行的java或者scala代码的一部分运行, 也可以在命令行运行:bin/flink run ...")])]),a._v(" "),t("h3",{attrs:{id:"_3-2-jobmanager"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-jobmanager"}},[a._v("#")]),a._v(" 3.2 JobManager")]),a._v(" "),t("blockquote",[t("ul",[t("li",[t("p",[a._v("控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行。")])]),a._v(" "),t("li",[t("p",[a._v("JobManager会先接收到要执行的应用程序，这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。")])]),a._v(" "),t("li",[t("p",[a._v("JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有"),t("strong",[a._v("可以并发执行的任务")]),a._v("。JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。")])]),a._v(" "),t("li",[t("p",[a._v("而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。")])])])]),a._v(" "),t("p",[a._v("JobManager 主要作用：")]),a._v(" "),t("ol",[t("li",[a._v("接受客户端请求")]),a._v(" "),t("li",[a._v("划分任务")]),a._v(" "),t("li",[a._v("申请资源")])]),a._v(" "),t("p",[a._v("这个进程包含3个不同的组件：")]),a._v(" "),t("h4",{attrs:{id:"_3-2-1-resourcemanager"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-1-resourcemanager"}},[a._v("#")]),a._v(" 3.2.1 ResourceManager")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t负责资源的管理，在整个 Flink 集群中只有一个 ResourceManager. 注意这个ResourceManager不是Yarn中的ResourceManager, 是Flink中内置的, 只是赶巧重名了而已.")]),a._v(" "),t("p",[a._v("​\t主要负责管理任务管理器（TaskManager）的插槽（slot），TaskManger插槽是Flink中定义的处理资源单元。")]),a._v(" "),t("p",[a._v("​\t当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。另外，ResourceManager还负责终止空闲的TaskManager，释放计算资源。")])]),a._v(" "),t("h4",{attrs:{id:"_3-2-2-dispatcher"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-2-dispatcher"}},[a._v("#")]),a._v(" 3.2.2 Dispatcher")]),a._v(" "),t("blockquote",[t("p",[a._v("​\t负责接收用户提供的作业，并且负责为这个新提交的作业启动一个新的JobMaster 组件. Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。")])]),a._v(" "),t("h4",{attrs:{id:"_3-2-3-jobmaster"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-3-jobmaster"}},[a._v("#")]),a._v(" 3.2.3 JobMaster")]),a._v(" "),t("blockquote",[t("p",[a._v("​\tJobMaster负责管理单个JobGraph的执行.多个Job可以同时运行在一个Flink集群中, 每个Job都有一个自己的JobMaster.")])]),a._v(" "),t("h3",{attrs:{id:"_3-3-taskmanager"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-taskmanager"}},[a._v("#")]),a._v(" 3.3 TaskManager")]),a._v(" "),t("blockquote",[t("p",[a._v("​\tFlink中的"),t("strong",[a._v("工作进程")]),a._v("。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了TaskManager能够执行的任务数量。")]),a._v(" "),t("p",[a._v("​\t启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。")]),a._v(" "),t("p",[a._v("​\t在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。")])]),a._v(" "),t("h3",{attrs:{id:"_3-4-核心概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-核心概念"}},[a._v("#")]),a._v(" 3.4 核心概念")]),a._v(" "),t("h4",{attrs:{id:"_3-4-1-taskmanager-与-slots"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-1-taskmanager-与-slots"}},[a._v("#")]),a._v(" 3.4.1 TaskManager 与 Slots")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fstart%2Ftm_slots.png",alt:""}})]),a._v(" "),t("p",[a._v("​\tFlink中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的线程上执行一个Task。为了控制一个worker能接收多少个task，worker通过Task Slot来进行控制（一个worker至少有一个Task Slot）。")]),a._v(" "),t("p",[a._v("​\t这里的Slot如何来理解呢？很多的文章中经常会和Spark框架进行类比，将Slot类比为Core，其实简单这么类比是可以的，可实际上，可以考虑下，当Spark申请资源后，这个Core执行任务时有可能是空闲的，但是这个时候Spark并不能将这个空闲下来的Core共享给其他Job使用，所以这里的Core是Job内部共享使用的。接下来我们再回想一下，之前在Yarn Session-Cluster模式时，其实是可以并行执行多个Job的，那如果申请两个Slot，而执行Job时，只用到了一个，剩下的一个怎么办？那我们自认而然就会想到可以将这个Slot给并行的其他Job，对吗？所以Flink中的Slot和Spark中的Core还是有很大区别的。")]),a._v(" "),t("p",[a._v("​\t每个task slot表示TaskManager拥有资源的一个固定大小的子集。假如一个TaskManager有三个slot，那么它会将其管理的内存分成三份给各个slot。资源slot化意味着一个task将不需要跟来自其他job的task竞争被管理的内存，取而代之的是它将拥有一定数量的内存储备。需要注意的是，这里不会涉及到CPU的隔离，slot目前仅仅用来隔离task的受管理的内存。")]),a._v(" "),t("p",[a._v("​\t总结：")]),a._v(" "),t("ol",[t("li",[a._v("slot是可以共享的（Job内部），外部共享只有一种情况（Session）。")]),a._v(" "),t("li",[a._v("slot会均分内存资源，进而达到内存隔离，相互之间不会占用内存。但cpu资源不会隔离，可以共享cpu资源。")])]),a._v(" "),t("h4",{attrs:{id:"_3-4-2-parallelism-并行度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-2-parallelism-并行度"}},[a._v("#")]),a._v(" 3.4.2 Parallelism (并行度)")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fstart%2Fparallelism.png",alt:""}})]),a._v(" "),t("p",[a._v("​\t一个特定算子的子任务（subtask）的个数被称之为这个算子的并行度（parallelism），一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度，（如果不是yarn模式不会动态申请资源）slot个数小于并行度那么程序将会卡死一直处于create状态，等待足够资源，才运行。")]),a._v(" "),t("p",[a._v("并行度优先级：")]),a._v(" "),t("p",[a._v("算子指定 > env全局指定 > 提交参数 > 配置文件")]),a._v(" "),t("h4",{attrs:{id:"_3-4-3-task-与-subtask"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-3-task-与-subtask"}},[a._v("#")]),a._v(" 3.4.3 Task 与 SubTask")]),a._v(" "),t("p",[a._v("​\t不同算子的子任务（SubTask）经过一定的优化，串在一起，形成一个新的SubTask对TaskManager来讲，就是一个Task。")]),a._v(" "),t("p",[a._v("sum算子   print算子 ， 并行度都是 3\n⭕          ⭕\n⭕          ⭕\n⭕          ⭕")]),a._v(" "),t("p",[a._v("sum算子 跟 print算子 满足某种不可描述的关系，可以串在一起\n（⭕  ⭕） -> 新的 subtask -> 对 TaskManager来讲，就是一个 Task\n（⭕  ⭕） -> 新的 subtask -> 对 TaskManager来讲，就是一个 Task\n（⭕  ⭕） -> 新的 subtask -> 对 TaskManager来讲，就是一个 Task")]),a._v(" "),t("h4",{attrs:{id:"_3-4-4-operator-chains-任务链"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-4-operator-chains-任务链"}},[a._v("#")]),a._v(" 3.4.4 Operator Chains (任务链)")]),a._v(" "),t("p",[a._v("​\tStream在算子之间传输数据的形式可以是one-to-one(forwarding)的模式也可以是redistributing的模式，具体是哪一种形式，取决于算子的种类。")]),a._v(" "),t("p",[t("strong",[a._v("One-to-one")])]),a._v(" "),t("p",[a._v("​\tstream(比如在source和map operator之间)维护着分区以及元素的顺序。那意味着flatmap 算子的子任务看到的元素的个数以及顺序跟source 算子的子任务生产的元素的个数、顺序相同，map、fliter、flatMap等算子都是one-to-one的对应关系。")]),a._v(" "),t("p",[t("strong",[a._v("Redistributing")])]),a._v(" "),t("p",[a._v("​\tstream(map()跟keyBy/window之间或者keyBy/window跟sink之间)的分区会发生改变。每一个算子的子任务依据所选择的transformation发送数据到不同的目标任务。例如，keyBy()基于hashCode重分区、broadcast和rebalance会随机重新分区，这些算子都会引起redistribute过程，而redistribute过程就类似于Spark中的shuffle过程。")]),a._v(" "),t("p",[a._v("​\t相同并行度的one to one操作，Flink将这样相连的算子链接在一起形成一个task，原来的算子成为里面的一部分。 每个task被一个线程执行.")]),a._v(" "),t("p",[a._v("​\t将算子链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定。")]),a._v(" "),t("ul",[t("li",[a._v("算子"),t("code",[a._v(".startNewChain()")]),a._v(" => 与前面断开")]),a._v(" "),t("li",[a._v("算子"),t("code",[a._v(".disableChaining()")]),a._v(" => 与前后都断开")]),a._v(" "),t("li",[t("code",[a._v("env.disableOperatorChaining()")]),a._v(" => 全局都不串")])]),a._v(" "),t("p",[a._v("断开操作链的好处在于减少某个slot的压力。")]),a._v(" "),t("p",[t("strong",[a._v("共享组")]),a._v(" "),t("code",[a._v('.slotSharingGroup("group1")')]),a._v("\n​\t设置共享组后，slot的使用个数并不仅仅是与程序中最大算子的并行度有关了，当算子设置共享组后会使用额外的slot来执行，默认只有一个共享组，因此在默认只有一个共享组的情况下，slot的个数等于程序中最大算子的并行度。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fstart%2Foper_chains.png",alt:""}})]),a._v(" "),t("p",[a._v("任务链以及共享组：")]),a._v(" "),t("p",[a._v("任务链的好处，避免数据跨节点传输。")]),a._v(" "),t("p",[a._v("断开任务链的好处，减少某个slot的压力。")]),a._v(" "),t("p",[a._v("默认情况下所有算子都是同一个共享组，任务所需要的slot数量：最大算子的并行度。")]),a._v(" "),t("p",[a._v("当使用共享组时，任务所需要的slot数量：每个共享组中最大并行度的和。")]),a._v(" "),t("h4",{attrs:{id:"_3-4-5-executiongraph-执行图"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-5-executiongraph-执行图"}},[a._v("#")]),a._v(" 3.4.5 ExecutionGraph (执行图)")]),a._v(" "),t("p",[a._v("​\t由Flink程序直接映射成的数据流图是StreamGraph，也被称为逻辑流图，因为它们表示的是计算逻辑的高级视图。为了执行一个流处理程序，Flink需要将逻辑流图转换为物理数据流图（也叫执行图），详细说明程序的执行方式。")]),a._v(" "),t("p",[a._v("Flink 中的执行图可以分成四层：StreamGraph -> JobGraph -> ExecutionGraph -> Physical Graph。")]),a._v(" "),t("p",[t("strong",[a._v("StreamGraph")])]),a._v(" "),t("blockquote",[t("p",[a._v("是根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的"),t("strong",[a._v("拓扑结构")]),a._v("。")])]),a._v(" "),t("p",[t("strong",[a._v("JobGraph")])]),a._v(" "),t("blockquote",[t("p",[a._v("StreamGraph经过优化后生成了 JobGraph，是提交给 JobManager 的数据结构。主要的优化为: 将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。")])]),a._v(" "),t("p",[t("strong",[a._v("ExecutionGraph")])]),a._v(" "),t("blockquote",[t("p",[a._v("JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。")])]),a._v(" "),t("p",[t("strong",[a._v("Physical Graph")])]),a._v(" "),t("blockquote",[t("p",[a._v("JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。")])]),a._v(" "),t("p",[a._v("2个并发度（Source为1个并发度）的 SocketTextStreamWordCount 四层执行图的演变过程")]),a._v(" "),t("p",[t("code",[a._v("env.socketTextStream().flatMap(…).keyBy(0).sum(1).print();")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fstart%2Fgraph.png",alt:""}})]),a._v(" "),t("h3",{attrs:{id:"_3-5-提交流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-提交流程"}},[a._v("#")]),a._v(" 3.5 提交流程")]),a._v(" "),t("h4",{attrs:{id:"_3-5-1-高级视角提交流程-通用提交流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-1-高级视角提交流程-通用提交流程"}},[a._v("#")]),a._v(" 3.5.1 高级视角提交流程 (通用提交流程)")]),a._v(" "),t("p",[a._v("一个应用提交执行时，Flink的各个组件是如何交互协作的：")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fstart%2Fsubmit_flow.png",alt:""}})]),a._v(" "),t("h4",{attrs:{id:"_3-5-2-yarn-cluster-提交流程-per-job"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-2-yarn-cluster-提交流程-per-job"}},[a._v("#")]),a._v(" 3.5.2 yarn-cluster 提交流程 per-job")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/flink%2Fstart%2Fper-job.png",alt:""}})]),a._v(" "),t("ol",[t("li",[a._v("Flink任务提交后，Client向HDFS上传Flink的Jar包和配置")]),a._v(" "),t("li",[a._v("向Yarn ResourceManager提交任务，ResourceManager分配Container资源")]),a._v(" "),t("li",[a._v("通知对应的NodeManager启动ApplicationMaster，ApplicationMaster启动后加载Flink的Jar包和配置构建环境，然后启动JobManager")]),a._v(" "),t("li",[a._v("ApplicationMaster向ResourceManager申请资源启动TaskManager")]),a._v(" "),t("li",[a._v("ResourceManager分配Container资源后，由ApplicationMaster通知资源所在节点的NodeManager启动TaskManager")]),a._v(" "),t("li",[a._v("NodeManager加载Flink的Jar包和配置构建环境并启动TaskManager")]),a._v(" "),t("li",[a._v("TaskManager启动后向JobManager发送心跳包，并等待JobManager向其分配任务。")])]),a._v(" "),t("h2",{attrs:{id:"_4-总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-总结"}},[a._v("#")]),a._v(" 4. 总结")]),a._v(" "),t("p",[a._v("Flink 是有状态的流计算框架")]),a._v(" "),t("p",[a._v("四层 API")]),a._v(" "),t("p",[a._v("运行模式：")]),a._v(" "),t("p",[a._v("开发模式")]),a._v(" "),t("p",[a._v("local（Standalone单节点模式）")]),a._v(" "),t("p",[a._v("Standalone模式（资源由Flink 自己管理，高可用）")]),a._v(" "),t("p",[a._v("Yarn：（Session&perJob&ApplicaionMode，高可用），推荐 perJob模式")]),a._v(" "),t("p",[a._v("Client、JobManager、TaskManager")]),a._v(" "),t("p",[a._v("JobManager四个组件：Dispatcher、ResourceManager、JobMaster、CheckCo...")]),a._v(" "),t("p",[a._v("TaskManger：slot个数与并行度关系")]),a._v(" "),t("p",[a._v("并行度：4个位置可以指定并行度，优先级:  算子指定 -> env ->  提交命令的参数 -> 配置文件")]),a._v(" "),t("p",[a._v("默认情况下只有一个共享组时，slot个数等于流程序的并行度（程序中最大算子的并行度）")]),a._v(" "),t("p",[a._v("有多个共享组时，slot个数等于每个算子中最大并行度之和")]),a._v(" "),t("p",[a._v("slot：资源（内存，均分TaskManager内存，作业内部是不共享的除了Session模式）")]),a._v(" "),t("p",[a._v("Task与SubTask关系")]),a._v(" "),t("p",[a._v("算子链：什么情况下才能串到一起")]),a._v(" "),t("p",[a._v("算子链：优缺点")]),a._v(" "),t("p",[a._v("如何断开算子链")]),a._v(" "),t("p",[a._v("四个图（逻辑流图，作业图，执行图，物理图）")]),a._v(" "),t("p",[a._v("任务提交流程：通用流程&perJob提交流程")]),a._v(" "),t("p",[a._v("Source、TransForm、Sink")]),a._v(" "),t("p",[a._v("Source并行度")]),a._v(" "),t("p",[a._v("TransForm富函数（初始化状态）")]),a._v(" "),t("p",[a._v("keyBy源码（两次Hash）")]),a._v(" "),t("p",[a._v("reduce（当数据只有一条时，不进入reduce）")]),a._v(" "),t("p",[a._v("max与maxBy 区别")]),a._v(" "),t("p",[a._v("重分区算子（keyBy、shuffle、rebalance、rescale）原理")]),a._v(" "),t("p",[a._v("sink（es/jdbc写数据时有个阈值，缓冲区大小？）")]),a._v(" "),t("p",[a._v("窗口：")]),a._v(" "),t("p",[a._v("时间：滚动、滑动、会话（窗口为什么是左闭右开的，窗口的开始时间是怎么得到的，滑动窗口中一条数据涉及哪些窗口）")]),a._v(" "),t("p",[a._v("元素：滚动、滑动")]),a._v(" "),t("p",[a._v("窗口设置偏移量的作用：决定窗口的开始时间和结束时间")]),a._v(" "),t("p",[a._v("既然窗口是来一条数据创建一个窗口，那为什么使用过程中不会有问题？")]),a._v(" "),t("p",[a._v("因为窗口设计单例模式，所以不会创建大量相同的对象")]),a._v(" "),t("p",[a._v("什么时候触发计算？")]),a._v(" "),t("p",[a._v("触发条件有两个依据，并且都类似，是因为考虑到了读有界数据的情况")]),a._v(" "),t("p",[a._v("什么时候关窗，关窗之后做了什么？")]),a._v(" "),t("p",[a._v("处理时间")]),a._v(" "),t("p",[a._v("事件时间")]),a._v(" "),t("p",[a._v("如果使用事件时间，需要指定 WaterMark （两种：1.单调递增，2.设置固定延迟的:乱序程度）")]),a._v(" "),t("p",[a._v("WaterMark源码解析：默认是Long的最小值，程序执行完毕，WaterMark飙升 Long 的最大值（为了将所有数据都消费的到）")]),a._v(" "),t("p",[a._v("生成 WaterMark 方式：间歇性（来一条生成一个）、周期性（默认每隔 200 ms生成,可指定，流执行环境搜索200）")]),a._v(" "),t("p",[a._v("在多并行度的情况下：WaterMark以广播方式传递，并且依据短板效应，取的最小的 WaterMark")]),a._v(" "),t("p",[a._v("允许迟到数据：延迟关窗时间")]),a._v(" "),t("p",[a._v("侧输出流：将一个流分成多个流  new OutPutTag() {}  需要的是匿名内部类，")]),a._v(" "),t("p",[a._v("定时器：分key，定时器只能用在keyedStream上，")]),a._v(" "),t("p",[a._v("状态编程：算子状态（通常用于source端，ListState、BroadcastState）&键控状态（ValueState、ListState、MapState、ReducingState、AggState）")]),a._v(" "),t("p",[a._v("状态后端：保存状态用的（MemoryStatebackend、Fs...、RocksDb...：保存大状态）")]),a._v(" "),t("p",[a._v("一致性：最多一次(丢数据)、最少一次(重复数据)、精准一次")]),a._v(" "),t("p",[a._v("Checkpoint - 分布式快照算法 (barrier)")]),a._v(" "),t("p",[a._v("barrier对齐：精准一次")]),a._v(" "),t("p",[a._v("不对齐：最少一次")]),a._v(" "),t("p",[a._v("source精准一次 （offset）")]),a._v(" "),t("p",[a._v("TransForm精准一次 (Checkpoint)")]),a._v(" "),t("p",[a._v("sink精准一次 （两阶段提交 2PC：需要外部系统支持事务，或者能模拟事务，并且故障恢复后能重启事务，例如:kafka）")]),a._v(" "),t("p",[a._v("CEP：复杂事件处理库。")]),a._v(" "),t("p",[a._v("TableAPI&SQL：")]),a._v(" "),t("p",[a._v("动态表&连续查询")]),a._v(" "),t("p",[a._v("撤回流")]),a._v(" "),t("p",[a._v("追加流")]),a._v(" "),t("p",[a._v("未注册的表&已注册的表")]),a._v(" "),t("p",[a._v("事件时间（SQL中建表时如何指定WaterMark）和处理时间的指定")]),a._v(" "),t("p",[a._v("GroupWindow")]),a._v(" "),t("p",[a._v("OverWindow")]),a._v(" "),t("p",[a._v("自定义函数：")]),a._v(" "),t("p",[a._v("标量函数 - UDF：一进一出")]),a._v(" "),t("p",[a._v("表函数 - UDTF：一进多出")]),a._v(" "),t("p",[a._v("聚合函数 - UDAF：多进一出")]),a._v(" "),t("p",[a._v("表聚合函数 - UDTAF：多进多出   如： TopN")]),a._v(" "),t("p",[a._v("HiveCataLog：通过读取 Hive 的元数据，来操作 hive 中的表")]),a._v(" "),t("h2",{attrs:{id:"_5-工作原理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-工作原理"}},[a._v("#")]),a._v(" 5. 工作原理")]),a._v(" "),t("h3",{attrs:{id:"_5-1-standalone模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-standalone模式"}},[a._v("#")]),a._v(" 5.1 Standalone模式")]),a._v(" "),t("p",[a._v("①由应用端(App)提交应用给分发器(dispatcher)")]),a._v(" "),t("p",[a._v("②Dispatcher启动并提交应用给JobManager")]),a._v(" "),t("p",[a._v("③JobManager向resourcemanager请求slots(插槽)资源")]),a._v(" "),t("p",[a._v("④resourcemanager收到了JobManager的资源请求后，就去启动TaskManager")]),a._v(" "),t("p",[a._v("⑤TaskManger启动之后，会去resourcemanager注册slots")]),a._v(" "),t("p",[a._v("⑥resourcemanager收到TaskManger的注册slots请求后，会给TaskManger发出提供slot的指令")]),a._v(" "),t("p",[a._v("⑦TaskManager接到指令后，JobManager会被告知已有所需数量的slots使用。")]),a._v(" "),t("p",[a._v("⑧JobManager得知有足够的slots可以使用后，就会提交要执行的任务给TaskManager")]),a._v(" "),t("p",[a._v("⑨与此同时，TaskManager之间也会进行数据的交换")]),a._v(" "),t("h3",{attrs:{id:"_5-2-yarn-模式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-yarn-模式"}},[a._v("#")]),a._v(" 5.2 Yarn 模式")]),a._v(" "),t("p",[a._v("①Flink客户端上传flink的jar包和配置到HDFS")]),a._v(" "),t("p",[a._v("②客户端提交job到resourcemanager(yarn)")]),a._v(" "),t("p",[a._v("③resourcemanager启动ApplicationMaster，同时ApplicationMaster启动JobManager，之后jobmanager从HDFS上加载Flink的jar包和配置环境(除了yarn的resourcemanager，flink也有自己的resourcemanager，只不过它不管理资源，而是由yarn的resourcemanager管理资源)")]),a._v(" "),t("p",[a._v("④jobmanager向resourcemanager申请资源")]),a._v(" "),t("p",[a._v("⑤jobmanager申请到资源后，启动TaskManager，同样TaskManager向flink的ResourceManager注册slot，因此jobmanager得知有足够的slots可以使用，就会将job任务提交给TaskManager去执行，同时taskmanager会从HDFS加载flink的jar包和环境配置。")])])}),[],!1,null,null,null);s.default=e.exports}}]);