(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{535:function(t,s,a){"use strict";a.r(s);var e=a(4),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"_1-linux命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-linux命令"}},[t._v("#")]),t._v(" 1. Linux命令")]),t._v(" "),a("p",[t._v("高级命令：")]),t._v(" "),a("p",[a("code",[t._v("ps -ef|grep java")])]),t._v(" "),a("p",[t._v("ps\n作用： 主要是查看服务器的进程信息\n选项含义：\n-e：等价于 ‘-A’ ，表示列出全部的进程\n-f：显示全部的列（显示全字段）")]),t._v(" "),a("p",[a("code",[t._v("netstat")])]),t._v(" "),a("p",[t._v("命令用于显示网络状态")]),t._v(" "),a("p",[a("code",[t._v("top")])]),t._v(" "),a("p",[t._v("即时显示 process 的动态")]),t._v(" "),a("p",[a("code",[t._v("iotop")])]),t._v(" "),a("p",[t._v("-o：只显示有io操作的进程\n-b：批量显示，无交互，主要用作记录到文件。\n-n NUM：显示NUM次，主要用于非交互式模式。\n-d SEC：间隔SEC秒显示一次。\n-p PID：监控的进程pid。\n-u USER：监控的进程用户。")]),t._v(" "),a("p",[a("code",[t._v("free")])]),t._v(" "),a("p",[t._v("free是指查看当前系统内存的使用情况，它显示系统中剩余及已用的物理内存和交换内存，以及共享内存和被核心使用的缓冲区。")]),t._v(" "),a("p",[a("code",[t._v("df")])]),t._v(" "),a("p",[t._v("df -a：显示所有文件系统的磁盘使用情况，包括0块（block）的文件系统。")]),t._v(" "),a("p",[t._v("df -h：以容易理解的格式输出文件系统大小，例如124KB、345MB、46GB。")]),t._v(" "),a("p",[t._v("df -i：显示i节点信息，而不是磁盘块。")]),t._v(" "),a("p",[t._v("df -t：显示各指定类型的文件系统的磁盘空间使用情况。")]),t._v(" "),a("p",[t._v("df -x：列出不是某一指定类型文件系统的磁盘空间使用情况。")]),t._v(" "),a("p",[t._v("df -T：显示文件系统类型。")]),t._v(" "),a("p",[t._v("df 以512字节为单位")]),t._v(" "),a("p",[t._v("df –k 以1024字节为单位.")]),t._v(" "),a("p",[a("code",[t._v("grep -lr xxxx *")])]),t._v(" "),a("p",[t._v("查询当前目录下面的日志中是否包含 xxxx 字符")]),t._v(" "),a("h2",{attrs:{id:"_2-shell"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-shell"}},[t._v("#")]),t._v(" 2. Shell")]),t._v(" "),a("p",[t._v("常用工具：awk  cut  sed  sorts")]),t._v(" "),a("h3",{attrs:{id:"_2-1-群启-关脚本"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-群启-关脚本"}},[t._v("#")]),t._v(" 2.1 群启/关脚本")]),t._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token shebang important"}},[t._v("#!/bin/bash")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"start"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token for-or-select variable"}},[t._v("i")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" hadoop102 hadoop103 hadoop104\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ssh")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$i")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"start"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("done")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stop"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token for-or-select variable"}},[t._v("i")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" hadoop102 hadoop103 hadoop104\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ssh")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$i")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"stop"')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("done")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("esac")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br")])]),a("h3",{attrs:{id:"_2-2-分发脚本"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-分发脚本"}},[t._v("#")]),t._v(" 2.2 分发脚本")]),t._v(" "),a("h3",{attrs:{id:"_2-3-sqoop脚本"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-sqoop脚本"}},[t._v("#")]),t._v(" 2.3 Sqoop脚本")]),t._v(" "),a("p",[t._v("导入(同步策略)")]),t._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("-query "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from t where 1 = 1 & $"')]),t._v("\n-query "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from t where create_time = '),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$do_date")]),t._v(' & $"')]),t._v("\n-query "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from t where create_time = '),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$do_date")]),t._v(" or op_time = "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$do_date")]),t._v(' & $"')]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("导出")]),t._v(" "),a("h3",{attrs:{id:"_2-4-ods-dwd-dws-dwt"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-ods-dwd-dws-dwt"}},[t._v("#")]),t._v(" 2.4 ods -> dwd -> dws -> dwt")]),t._v(" "),a("h3",{attrs:{id:"_2-5-和-的区别-嵌套时看最外层"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-和-的区别-嵌套时看最外层"}},[t._v("#")]),t._v(" 2.5 '' 和 \"\" 的区别，嵌套时看最外层")]),t._v(" "),a("h2",{attrs:{id:"_3-hadoop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-hadoop"}},[t._v("#")]),t._v(" 3. Hadoop")]),t._v(" "),a("h3",{attrs:{id:"_3-1-入门"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-入门"}},[t._v("#")]),t._v(" 3.1 入门")]),t._v(" "),a("p",[t._v("常用端口号")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[a("strong",[t._v("hadoop2.x")])]),t._v(" "),a("th",[a("strong",[t._v("hadoop3.x")])])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("strong",[t._v("访问HDFS端口")])]),t._v(" "),a("td",[t._v("50070")]),t._v(" "),a("td",[t._v("9870")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("访问MR执行情况端口")])]),t._v(" "),a("td",[t._v("8088")]),t._v(" "),a("td",[t._v("8088")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("历史服务器")])]),t._v(" "),a("td",[t._v("19888")]),t._v(" "),a("td",[t._v("19888")])]),t._v(" "),a("tr",[a("td",[a("strong",[t._v("客户端访问集群端口")])]),t._v(" "),a("td",[t._v("9000")]),t._v(" "),a("td",[t._v("8020")])])])]),t._v(" "),a("p",[t._v("端口号")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("版本")]),t._v(" "),a("th",[t._v("NN(外部访问/内部通信 )")]),t._v(" "),a("th",[t._v("RM(外部访问/内部通信 )")]),t._v(" "),a("th",[t._v("History(外部访问/内部通信 )")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("2.x")]),t._v(" "),a("td",[t._v("50070/9000")]),t._v(" "),a("td",[t._v("8088/8032")]),t._v(" "),a("td",[t._v("19888/10020")])]),t._v(" "),a("tr",[a("td",[t._v("3.x")]),t._v(" "),a("td",[t._v("9870/8020")]),t._v(" "),a("td",[t._v("8088/8032")]),t._v(" "),a("td",[t._v("19888/10020")])])])]),t._v(" "),a("p",[t._v("配置文件")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th"),t._v(" "),a("th"),t._v(" "),a("th"),t._v(" "),a("th"),t._v(" "),a("th")])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("2.x")]),t._v(" "),a("td",[t._v("core")]),t._v(" "),a("td",[t._v("hdfs")]),t._v(" "),a("td",[t._v("yarn")]),t._v(" "),a("td",[t._v("mapred")]),t._v(" "),a("td",[t._v("slaves")])]),t._v(" "),a("tr",[a("td",[t._v("3.x")]),t._v(" "),a("td",[t._v("core")]),t._v(" "),a("td",[t._v("hdfs")]),t._v(" "),a("td",[t._v("yarn")]),t._v(" "),a("td",[t._v("mapred")]),t._v(" "),a("td",[t._v("workers")])])])]),t._v(" "),a("h3",{attrs:{id:"_3-2-hdfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-hdfs"}},[t._v("#")]),t._v(" 3.2 HDFS")]),t._v(" "),a("blockquote",[a("p",[t._v("注意：HDFS写入流程时候，某台dataNode挂掉如何运行？")]),t._v(" "),a("p",[t._v("​\t当DataNode突然挂掉了，客户端接收不到这个DataNode发送的ack确认，客户端会通知NameNode，")]),t._v(" "),a("p",[t._v("NameNode检查并确认该块的副本与规定的不符，NameNode会通知闲置的DataNode去复制副本，并将挂掉的")]),t._v(" "),a("p",[t._v("DataNode作下线处理。等挂掉的DataNode节点恢复后, 删除该节点中曾经拷贝的不完整副本数据。")])]),t._v(" "),a("ol",[a("li",[t._v("读写流程\n"),a("ol",[a("li",[t._v("写流程\n"),a("ol",[a("li",[t._v("客户端通过Distributed FileSystem模块向NameNode请求上传文件，NN 检查文件和父目录是否存在")]),t._v(" "),a("li",[t._v("NN 返回是否可以上传")]),t._v(" "),a("li",[t._v("客户端请求第一个 Block ，向 NN 请求返回 DataNode")]),t._v(" "),a("li",[t._v("NN 返回 3 个 DataNode 节点，dn1,dn2,dn3")]),t._v(" "),a("li",[t._v("客户端通过 FSDataOutPutStream 模块请求 dn1 上传数据，dn1收到请求会继续调用dn2，然后dn2调用 dn3，将这个管道建立完毕")]),t._v(" "),a("li",[t._v("dn1、dn2、dn3 逐级应答客户端")]),t._v(" "),a("li",[t._v("客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个 packet 就会传给 dn2，dn2 传给 dn3，dn1每传一个packet会放入一个应答队列等待应答")]),t._v(" "),a("li",[t._v("当一个Block传输完成之后，客户端再次请求 NN 上传第二个 Block的服务器")])])]),t._v(" "),a("li",[t._v("读流程\n"),a("ol",[a("li",[t._v("客户端通过Distributed FileSystem请求下载文件，NN 通过查询元数据，找到文件所在的 DN地址")]),t._v(" "),a("li",[t._v("挑选一台 DN （就近原则，然后随机）服务器，请求读取数据")]),t._v(" "),a("li",[t._v("DN 开始传输数据给客户端（从磁盘里面读取数据输入流，以 Packet为单位来做校验）")]),t._v(" "),a("li",[t._v("客户端以 Packet 为单位接收，先在本地缓存，然后写入目标文件")])])])])]),t._v(" "),a("li",[t._v("小文件问题\n"),a("ol",[a("li",[t._v("危害\n"),a("ol",[a("li",[t._v("NN的存储效率低，小文件都会占用一个元数据")]),t._v(" "),a("li",[t._v("计算：每个小文件会单独开启一个 任务 (MapTask)，一个MapTask默认内存 1G")])])]),t._v(" "),a("li",[t._v("解决办法\n"),a("ol",[a("li",[t._v("Flume的HDFSSink从源头解决小文件问题、Map任务合并、HAR归档解决已经产生的小文件")]),t._v(" "),a("li",[t._v("采用CombineInputFormat、")]),t._v(" "),a("li",[t._v("自己写一个MR程序将产生的小文件合并成一个大文件。如果是Hive或者Spark有merge功能自动帮助我们合并。")]),t._v(" "),a("li",[t._v("有小文件场景开启JVM重用；如果没有小文件，不要开启JVM重用，因为会一直占用使用到的Task卡槽，直到任务完成才释放。JVM重用(MR引擎可用/Spark引擎不可用)")])])])])])]),t._v(" "),a("blockquote",[a("p",[t._v("JVM重用可以使得JVM实例在同一个job中重新使用N次，N的值可以在Hadoop的mapred-site.xml文件中进行配置。通常在10-20之间。")])]),t._v(" "),a("div",{staticClass:"language-xml line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mapreduce.job.jvm.numtasks"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("10"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("How many tasks to run per jvm,if set to -1 ,there is  no limit"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("ol",{attrs:{start:"3"}},[a("li",[a("strong",[t._v("块大小")]),t._v(" "),a("ol",[a("li",[t._v("1.x：64M")]),t._v(" "),a("li",[t._v("2.x：128M")]),t._v(" "),a("li",[t._v("3.x：128M")]),t._v(" "),a("li",[t._v("local：32M")]),t._v(" "),a("li",[t._v("Hive：256M")]),t._v(" "),a("li",[t._v("大厂：256M及以上")])])])]),t._v(" "),a("p",[t._v("根据：磁盘的读取速度")]),t._v(" "),a("ul",[a("li",[t._v("如果寻址时间为 10ms，即查找目标block的时间为10ms")]),t._v(" "),a("li",[t._v("寻址时间为传输时间的 1% 时，即为最佳状态。因此传输时间 = 10ms * 100 = 1s")]),t._v(" "),a("li",[t._v("而目前磁盘的传输速率普遍为 100MB/s")]),t._v(" "),a("li",[t._v("block 大小 = 1s * 100MB/s = 100MB")])]),t._v(" "),a("blockquote",[a("p",[t._v("如果HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置")]),t._v(" "),a("p",[t._v("如果块设置太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。导致程序在处理这块数据时，会非常慢。")])]),t._v(" "),a("h3",{attrs:{id:"_3-3-mr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-mr"}},[t._v("#")]),t._v(" 3.3 MR")]),t._v(" "),a("p",[t._v("Shuffle：Map方法之后到Reduce方法之前 (PPT 01)")]),t._v(" "),a("h3",{attrs:{id:"_3-4-yarn"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-yarn"}},[t._v("#")]),t._v(" 3.4 Yarn")]),t._v(" "),a("p",[t._v("调度器：FIFO、容量、公平")]),t._v(" "),a("p",[t._v("FIFO：单队列、先进先出（几乎不用）")]),t._v(" "),a("p",[t._v("容量：多队列、队列内部先进先出、可以使用其他队列的资源（大部分公司）")]),t._v(" "),a("p",[t._v("公平：多队列、队列内部按照缺额、可以使用其他队列的资源（大厂、并发度要求高）")]),t._v(" "),a("p",[t._v("队列：默认")]),t._v(" "),a("p",[t._v("按照什么分？")]),t._v(" "),a("p",[t._v("​\t业务：hive/spark/flink 每个框架的任务放入指定的队列（企业用的不是特别多）")]),t._v(" "),a("p",[t._v("​\t框架：登录注册、购物车、下单、业务部门1、业务部门2")]),t._v(" "),a("p",[t._v("​\t个人：防止菜鸟")]),t._v(" "),a("p",[t._v("提交流程(工作机制)")]),t._v(" "),a("h2",{attrs:{id:"_4-zookeeper"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-zookeeper"}},[t._v("#")]),t._v(" 4. Zookeeper")]),t._v(" "),a("h3",{attrs:{id:"_4-1-选举机制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-选举机制"}},[t._v("#")]),t._v(" 4.1 选举机制")]),t._v(" "),a("p",[t._v("多数机制")]),t._v(" "),a("h3",{attrs:{id:"_4-2-机器台数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-机器台数"}},[t._v("#")]),t._v(" 4.2 机器台数")]),t._v(" "),a("p",[t._v("奇数台")]),t._v(" "),a("p",[t._v("10台服务器\t3台")]),t._v(" "),a("p",[t._v("20台服务器\t5台")]),t._v(" "),a("p",[t._v("50台服务器\t7台")]),t._v(" "),a("p",[t._v("100台服务器\t11台")]),t._v(" "),a("p",[t._v("200台服务器\t11台")]),t._v(" "),a("p",[t._v("台数多，好处：提高可靠性；坏处：影响通信延时。")]),t._v(" "),a("h3",{attrs:{id:"_4-3-常用命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-常用命令"}},[t._v("#")]),t._v(" 4.3 常用命令")]),t._v(" "),a("p",[t._v("create\tls\tget\tdelete\tdeleteall")]),t._v(" "),a("h3",{attrs:{id:"_4-4-zk的cap"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-zk的cap"}},[t._v("#")]),t._v(" 4.4 Zk的CAP")]),t._v(" "),a("ul",[a("li",[t._v("一致性 (Consistency)\n"),a("ul",[a("li",[t._v("在分布式环境中，一致性是指数据在多个副本之间是否能够保证数据一致的特性")])])]),t._v(" "),a("li",[t._v("可用性 (Available)\n"),a("ul",[a("li",[t._v("可用性是指系统提供服务必须一直处于不可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果")])])]),t._v(" "),a("li",[t._v("分区容错性 (Partition Tolerance)\n"),a("ul",[a("li",[t._v("分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障")])])])]),t._v(" "),a("p",[t._v("Zk保证的是 CP，")]),t._v(" "),a("ol",[a("li",[t._v("Zk 不能保证每次服务请求的可用性。（注：在极端环境下，Zk可能会丢弃一些请求，消费者程序需要重新请求才能获得结果）。所以说，Zk不能保证服务可用性")]),t._v(" "),a("li",[t._v("进行 Leader 选举时集群都是不可用的")])]),t._v(" "),a("h3",{attrs:{id:"_4-5-zk脑裂"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-zk脑裂"}},[t._v("#")]),t._v(" 4.5 Zk脑裂")]),t._v(" "),a("p",[t._v("Zookeeper 采用过半选举机制，防止了脑裂")]),t._v(" "),a("h2",{attrs:{id:"_5-flume"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-flume"}},[t._v("#")]),t._v(" 5. Flume")]),t._v(" "),a("h3",{attrs:{id:"_5-1-基本组成"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-基本组成"}},[t._v("#")]),t._v(" 5.1 基本组成")]),t._v(" "),a("ol",[a("li",[t._v("Source\n"),a("ol",[a("li",[t._v("tailDirSource：断点续传、多目录多文件监控")]),t._v(" "),a("li",[t._v("KafkaSource")]),t._v(" "),a("li",[t._v("netcat")]),t._v(" "),a("li",[t._v("avro source")])])]),t._v(" "),a("li",[t._v("Channle\n"),a("ol",[a("li",[t._v("Memory")]),t._v(" "),a("li",[t._v("File")]),t._v(" "),a("li",[t._v("Kafka")])])]),t._v(" "),a("li",[t._v("Sink\n"),a("ol",[a("li",[t._v("HDFS  sink")]),t._v(" "),a("li",[t._v("avro  sink")])])])]),t._v(" "),a("p",[t._v("tailDirSource：断点续传（保留上一次读取的位置信息）")]),t._v(" "),a("p",[t._v("位置信息：[ 绝对路径+inode值 -> position ]，inode(Linux在创建一个文件时生成的一个唯一值)")]),t._v(" "),a("p",[t._v("数据重复问题：日志框架在对日志进行更名时，更名后的文件会被重新读取一次")]),t._v(" "),a("p",[t._v("key = 绝对路径 + inode值，文件更名后绝对路径变了，Flume认为是一个新的文件，就会再次读取")]),t._v(" "),a("p",[t._v("log4j：")]),t._v(" "),a("p",[t._v("​\t2023-02-09")]),t._v(" "),a("p",[t._v("​\thive.log")]),t._v(" "),a("p",[t._v("​\t2023-02-10")]),t._v(" "),a("p",[t._v("​\thive.log-2023-02-09")]),t._v(" "),a("p",[t._v("​\thive.log")]),t._v(" "),a("p",[t._v("解决：")]),t._v(" "),a("p",[t._v("​\t方案一：写死监控文件名\t\t丢数据")]),t._v(" "),a("p",[t._v("​\t\t\t原因：中途任务挂了，重启之后，日志已经更名，就会有一部分数据丢失(例如 1.50分挂，2.05分重启)")]),t._v(" "),a("p",[t._v("​\t方案二：采用不更名的日志框架或者选择当前框架不更名的模式")]),t._v(" "),a("p",[t._v("​\t\t\tlogback:")]),t._v(" "),a("p",[t._v("​\t\t\t\t2023-02-09")]),t._v(" "),a("p",[t._v("​\t\t\t\thive.log-2023-02-09")]),t._v(" "),a("p",[t._v("​\t\t\t\t2023-02-10")]),t._v(" "),a("p",[t._v("​\t\t\t\thive.log-2023-02-09")]),t._v(" "),a("p",[t._v("​\t\t\t\thive.log-2023-02-10")]),t._v(" "),a("p",[t._v("​\t方案三：修改源码、去掉路径直接以 inode 值作为 key")]),t._v(" "),a("p",[t._v("​\t\t\tTailFile.class ， updatePos")]),t._v(" "),a("h3",{attrs:{id:"_5-2-三个器-一个组"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-三个器-一个组"}},[t._v("#")]),t._v(" 5.2 三个器 + 一个组")]),t._v(" "),a("ol",[a("li",[t._v("拦截器\n"),a("ol",[a("li",[t._v("ETL拦截器：过滤掉非JSON格式的数据 (logger)")]),t._v(" "),a("li",[t._v("时间戳拦截器：零点漂移")]),t._v(" "),a("li",[t._v("自定义步骤：静态内部类构建拦截器对象")])])]),t._v(" "),a("li",[t._v("Channel选择器\n"),a("ol",[a("li",[t._v("副本：默认")]),t._v(" "),a("li",[t._v("多路复用：结合拦截器")])])]),t._v(" "),a("li",[t._v("监控器\n"),a("ol",[a("li",[t._v("尝试 Put 的条数、成功 Put 条数")]),t._v(" "),a("li",[t._v("尝试 Take 的条数、成功 Task 条数")]),t._v(" "),a("li",[t._v("Channel 中现有数据条数")])])]),t._v(" "),a("li",[t._v("Sink组\n"),a("ol",[a("li",[t._v("默认：只允许一个 Sink")]),t._v(" "),a("li",[t._v("负载均衡：轮询")]),t._v(" "),a("li",[t._v("故障转移：优先级")])])])]),t._v(" "),a("h3",{attrs:{id:"_5-3-数据丢失"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-数据丢失"}},[t._v("#")]),t._v(" 5.3 数据丢失")]),t._v(" "),a("p",[t._v("​\t首先，我们采用Ganglia监控Flume任务，发现")]),t._v(" "),a("p",[t._v("​\t成功 Put 条数 = 成功 Take 条数 + Channel 中现有数据条数，说明没有丢失数据。")]),t._v(" "),a("p",[t._v("​\t 我们采用的是(组件说明)，同时 Source与 Channel 以及 Channel 与 Sink 之间传输有事务保证")]),t._v(" "),a("h3",{attrs:{id:"_5-4-优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-优化"}},[t._v("#")]),t._v(" 5.4 优化")]),t._v(" "),a("ol",[a("li",[t._v("调整内存\n"),a("ol",[a("li",[t._v("flume-env.sh     4-6G")])])]),t._v(" "),a("li",[t._v("HDFS  Sink 小文件\n"),a("ol",[a("li",[t._v("滚动文件条件：时间(1h)、大小(128M)、事件的条数(0)")]),t._v(" "),a("li",[t._v("压缩")])])]),t._v(" "),a("li",[t._v("file channel 优化\n"),a("ol",[a("li",[t._v("能多目录（多磁盘）配置多目录，能提高吞吐量")])])])]),t._v(" "),a("p",[t._v("Flume参数调优：")]),t._v(" "),a("p",[t._v("Source：增加Source个数和batchSize")]),t._v(" "),a("p",[t._v("Channel ：增大Capacity")]),t._v(" "),a("p",[t._v("Sink ：增加Sink的个数和batciSize")]),t._v(" "),a("h3",{attrs:{id:"_5-5-taildir底层原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-5-taildir底层原理"}},[t._v("#")]),t._v(" 5.5 taildir底层原理")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/shuffle%2Ftaildir.png",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"_6-kafka"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-kafka"}},[t._v("#")]),t._v(" 6. Kafka*")]),t._v(" "),a("blockquote",[a("p",[t._v("生产者、Broker、消费者、Zookeeper。\n注意：Zookeeper中保存Broker id和controller等信息，但是没有生产者信息。")])]),t._v(" "),a("h3",{attrs:{id:"_6-1-组成"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-组成"}},[t._v("#")]),t._v(" 6.1 组成")]),t._v(" "),a("ol",[a("li",[t._v("生产者\n"),a("ol",[a("li",[t._v("发送流程    两个线程(主线程和Sender线程)    三个器(拦截器、序列化器、分区器)")]),t._v(" "),a("li",[t._v("ACK   (0  1  -1)")]),t._v(" "),a("li",[t._v("分区规则")]),t._v(" "),a("li",[t._v("幂等性    事务")])])]),t._v(" "),a("li",[t._v("集群(ZK)\n"),a("ol",[a("li",[t._v("topic：分类数据\n"),a("ol",[a("li",[t._v("分区：\n"),a("ol",[a("li",[t._v("服务端：负载均衡")]),t._v(" "),a("li",[t._v("客户端：提高效率")])])]),t._v(" "),a("li",[t._v("副本：提高可靠性\n"),a("ol",[a("li",[t._v("ISR：同步副本队列")]),t._v(" "),a("li",[t._v("AR  =  ISR + OSR")]),t._v(" "),a("li",[t._v("LEO：当前副本最大的 Offset")]),t._v(" "),a("li",[t._v("HW：同一个分区最小的 LEO，消费者可见的最大的 Offset\n"),a("ol",[a("li",[t._v("作用：保证了消费数据的一致性、保证了存储数据的一致性")])])])])])])])])]),t._v(" "),a("li",[t._v("消费者(ZK)\n"),a("ol",[a("li",[t._v("消费者组：分区分配规则")]),t._v(" "),a("li",[t._v("Offset的维护：Zookeeper、__consumer_offsets、手动维护")])])]),t._v(" "),a("li",[t._v("数据量    峰值速度\n"),a("ol",[a("li",[t._v("100万日活   *   100条数据   =  1亿")]),t._v(" "),a("li",[t._v("每条数据 ：1k")]),t._v(" "),a("li",[t._v("每天的数据量 ：100 G")]),t._v(" "),a("li",[t._v("平均每秒数据量：1 亿 / 24 * 60 * 60 = 1150 条 / s")]),t._v(" "),a("li",[t._v("峰值速度：20 M / s")])])]),t._v(" "),a("li",[t._v("集群规模\n"),a("ol",[a("li",[t._v("经验公式：2 * (峰值速度 * 副本数 / 100) + 1  =  3 台")])])]),t._v(" "),a("li",[t._v("分区数\n"),a("ol",[a("li",[t._v("一台服务器 2 ~ 3 个分区 （3 * 2 = 6）")])])]),t._v(" "),a("li",[t._v("副本数\n"),a("ol",[a("li",[t._v("2 - 3")])])]),t._v(" "),a("li",[t._v("压测\n"),a("ol",[a("li",[t._v("自带脚本：生产和消费的速率")]),t._v(" "),a("li",[t._v("生产速度  >  峰值速度")]),t._v(" "),a("li",[t._v("消费速度  >  生产速度")])])]),t._v(" "),a("li",[t._v("监控\n"),a("ol",[a("li",[t._v("Eagle")])])])]),t._v(" "),a("h3",{attrs:{id:"_6-2-挂了"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-挂了"}},[t._v("#")]),t._v(" 6.2 挂了")]),t._v(" "),a("p",[t._v("​\t副本、Flume、日志服务器的磁盘")]),t._v(" "),a("p",[t._v("​\t重启")]),t._v(" "),a("h3",{attrs:{id:"_6-3-丢了"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-丢了"}},[t._v("#")]),t._v(" 6.3 丢了")]),t._v(" "),a("ol",[a("li",[t._v("生产者：ACK   0   1\n"),a("ol",[a("li",[t._v("解决：ACK  设置  -1")])])]),t._v(" "),a("li",[t._v("消费者：先保存 Offset、后保存数据\n"),a("ol",[a("li",[t._v("解决：先保存数据、后保存 Offset")]),t._v(" "),a("li",[t._v("解决：事务")])])])]),t._v(" "),a("h3",{attrs:{id:"_6-4-重复了"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-4-重复了"}},[t._v("#")]),t._v(" 6.4 重复了")]),t._v(" "),a("ol",[a("li",[t._v("生产者：ACK 设置为 -1\n"),a("ol",[a("li",[t._v("解决：幂等性、事务")])])]),t._v(" "),a("li",[t._v("消费者：先保存数据、后保存 Offset\n"),a("ol",[a("li",[t._v("解决：下游框架幂等性")]),t._v(" "),a("li",[t._v("解决：事务")])])])]),t._v(" "),a("h3",{attrs:{id:"_6-5-积压了"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-5-积压了"}},[t._v("#")]),t._v(" 6.5 积压了")]),t._v(" "),a("ol",[a("li",[t._v("提高单次消费的数据量，同时提高处理数据程序的资源！")]),t._v(" "),a("li",[t._v("提高主题的分区数(不可逆)，同时提高下游程序的并行度")])]),t._v(" "),a("h3",{attrs:{id:"_6-6-优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-6-优化"}},[t._v("#")]),t._v(" 6.6 优化")]),t._v(" "),a("ol",[a("li",[t._v("内存：4 - 6 G")]),t._v(" "),a("li",[t._v("副本：2 - 3")]),t._v(" "),a("li",[t._v("存储：默认保留 7 天，改为 3 天")])]),t._v(" "),a("h3",{attrs:{id:"_6-7-其他"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-7-其他"}},[t._v("#")]),t._v(" 6.7 其他")]),t._v(" "),a("ol",[a("li",[t._v("高效率的原因\n"),a("ol",[a("li",[t._v("分区")]),t._v(" "),a("li",[t._v("顺序写磁盘")]),t._v(" "),a("li",[t._v("零拷贝")])])]),t._v(" "),a("li",[t._v("来了一条 2 M 的数据，会发生什么事\n"),a("ol",[a("li",[t._v("会挂掉，最大值参数限制 （replica.fetch.max.bytes、message.max.bytes，fetch.message.max.bytes）")])])]),t._v(" "),a("li",[t._v("有序性问题，单分区有序\n"),a("ol",[a("li",[t._v("按照表名做 Key，保证同一张表进同一个分区，以保证同一张表是有序的")])])]),t._v(" "),a("li",[t._v("Epoch （解决丢数据问题）\n"),a("ol",[a("li",[t._v("一个单调递增的版本号，Leader变更会增加版本号。小版本号的Leader被认为是过期的Leader，不能再行使Leader的权力。")]),t._v(" "),a("li",[t._v("Start Offset：起始位移，Leader副本在该Epoch上写入的首条消息的位移。")])])])]),t._v(" "),a("h3",{attrs:{id:"_6-8-面试题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-8-面试题"}},[t._v("#")]),t._v(" 6.8 面试题")]),t._v(" "),a("h2",{attrs:{id:"_7-hive"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-hive"}},[t._v("#")]),t._v(" 7. Hive*")]),t._v(" "),a("h3",{attrs:{id:"_7-1-组成-架构-hql翻译成mr的过程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-1-组成-架构-hql翻译成mr的过程"}},[t._v("#")]),t._v(" 7.1 组成/架构&HQL翻译成MR的过程")]),t._v(" "),a("h3",{attrs:{id:"_7-2-与mysql区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-2-与mysql区别"}},[t._v("#")]),t._v(" 7.2 与MySQL区别")]),t._v(" "),a("ol",[a("li",[t._v("相同点：SQL语法")]),t._v(" "),a("li",[t._v("不同点：OLAP、OLTP\n"),a("ol",[a("li",[t._v("数据量")])])])]),t._v(" "),a("h3",{attrs:{id:"_7-3-内外部表的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-3-内外部表的区别"}},[t._v("#")]),t._v(" 7.3 内外部表的区别")]),t._v(" "),a("ol",[a("li",[t._v("删除数据\n"),a("ol",[a("li",[t._v("内部表：数据与元数据都删除")]),t._v(" "),a("li",[t._v("外部表：只删除元数据   （绝大部分使用）")]),t._v(" "),a("li",[t._v("可以互相转换")])])])]),t._v(" "),a("h3",{attrs:{id:"_7-4-4个by对比"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-4-4个by对比"}},[t._v("#")]),t._v(" 7.4 4个By对比")]),t._v(" "),a("ol",[a("li",[t._v("order by：全局排序，只有一个Reducer（严格模式不能直接用，需要加 limit ）")]),t._v(" "),a("li",[t._v("sort by：分区内排序，结合distribute  by 使用")]),t._v(" "),a("li",[t._v("distribute by：分区")]),t._v(" "),a("li",[t._v("cluster by：当distribute by 和 sort by字段相同且增序")])]),t._v(" "),a("h3",{attrs:{id:"_7-5-函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-5-函数"}},[t._v("#")]),t._v(" 7.5 函数")]),t._v(" "),a("ol",[a("li",[t._v("系统函数\n"),a("ol",[a("li",[t._v("日期：date_add、date_sub、date_format、datediff、next_day、last_day")]),t._v(" "),a("li",[t._v("窗口函数：over()\n"),a("ol",[a("li",[t._v("lead、lag、rank、dense_rank、row_number")]),t._v(" "),a("li",[t._v("partition by、order by、rows、between")])])]),t._v(" "),a("li",[t._v("扩展：first_value(开窗取第一条)、last_value\n"),a("ol",[a("li",[t._v("grouping sets((A,B,C),(A,B),(C),(B,C))、with cube、with rollup")])])])])]),t._v(" "),a("li",[t._v("自定义函数\n"),a("ol",[a("li",[t._v("UDF")]),t._v(" "),a("li",[t._v("UDTF")])])])]),t._v(" "),a("h3",{attrs:{id:"_7-6-优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-6-优化"}},[t._v("#")]),t._v(" 7.6 优化")]),t._v(" "),a("ol",[a("li",[t._v("DDL\n"),a("ol",[a("li",[t._v("分区表")]),t._v(" "),a("li",[t._v("分桶表")]),t._v(" "),a("li",[t._v("文件格式：ORC/parquet")]),t._v(" "),a("li",[t._v("压缩")])])]),t._v(" "),a("li",[t._v("DML\n"),a("ol",[a("li",[t._v("单表\n"),a("ol",[a("li",[t._v("行列过滤(少用 select *)")]),t._v(" "),a("li",[t._v("​")])])]),t._v(" "),a("li",[t._v("多表\n"),a("ol",[a("li",[t._v("谓词下推")]),t._v(" "),a("li",[t._v("Map  Join（大表和小表）")]),t._v(" "),a("li",[t._v("SMB  Join（大表和大表）")])])])])]),t._v(" "),a("li",[t._v("引擎\n"),a("ol",[a("li",[t._v("Spark")]),t._v(" "),a("li",[t._v("Tez")])])]),t._v(" "),a("li",[t._v("HiveJob整体优化\n"),a("ol",[a("li",[t._v("本地模式，严格模式...")])])])]),t._v(" "),a("h3",{attrs:{id:"_7-7-数据倾斜-重点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-7-数据倾斜-重点"}},[t._v("#")]),t._v(" 7.7 数据倾斜（重点）")]),t._v(" "),a("p",[t._v("产生原因：")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("单表查询时使用  GroupBy  字段")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("原因：某一组的数据过多")])]),t._v(" "),a("li",[a("p",[t._v("解决：")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("先抽样判断是单个Key还是多个Key造成的数据倾斜")])]),t._v(" "),a("li",[a("p",[t._v("解决：加随机数双重聚合")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("自动：设置参数即可解决（set hive.groupby.skewindata = true;）")])]),t._v(" "),a("li",[a("p",[t._v("手动：根据 id 聚合时加上：concat (id, '-', 随机数)")]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("order_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" table_a a "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" table_b b\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("when")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_is "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("is")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("null")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("then")]),t._v(" concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hive'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rand"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("end")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("Hive 已对此进行了优化，只需要设置参数skewinfo和skewjoin参数，不修改SQL代码，例如，由于table_B的值“0” 和“1”引起了倾斜，值需要做如下设置：即 1.自动")]),t._v(" "),a("p",[a("code",[t._v('set hive.optimize.skewinfo=table_B:(selleer_id) [ ("0") ("1") ]')])]),t._v(" "),a("p",[a("code",[t._v("set hive.optimize.skewjoin = true;")])])])])]),t._v(" "),a("li",[a("p",[t._v("如果是：count()   sum() 不影响业务逻辑的时候")]),t._v(" "),a("ol",[a("li",[t._v("使用Combiner组件   预聚合")])])]),t._v(" "),a("li",[a("p",[t._v("如果是求 平均数：使用 Combiner组件就不合适了")])]),t._v(" "),a("li",[a("p",[t._v("多个Key造成的数据倾斜，增加Reducer的个数，可以缓解数据倾斜。")])])])])])]),t._v(" "),a("li",[a("p",[t._v("多表关联时的  Join  字段")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("解决：")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("大表和小表    MapJoin (无 Reducer 阶段，则没有数据倾斜问题)")])]),t._v(" "),a("li",[a("p",[t._v("大表和大表    扩容 Join")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("A、B两张表关联字段：id，添加随机数：concat(id, '-', 随机数)")]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[t._v("A：concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nB：concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("union")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("all")]),t._v("\n   concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("union")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("all")]),t._v("\n   concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'-'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br")])])])])])])])])]),t._v(" "),a("li",[a("p",[t._v("具体描述")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("做过哪些优化？解决过哪些问题？")]),t._v(" "),a("ol",[a("li",[t._v("公司给某些城市做活动，活动之后想要统计活动收益，按照城市计算各种指标！各个城市数据量不均，发现执行当前活动相关任务时，绝大部分Task正常执行完，只有 1 个或者 2 个任务特别慢，甚至有的任务内存溢出！排查发现是数据倾斜问题")]),t._v(" "),a("li",[t._v("A表为一个汇总表，汇总的是卖家买家最近N天交易汇总信息，即对于每个卖家最近N天，其每个买家共成交了多少单，总金额是多少，假设N取90天，汇总值仅取成交单数。\n"),a("ol",[a("li",[t._v("A表的字段有：buyer_id、seller_id、pay_cnt_90day。")]),t._v(" "),a("li",[t._v("B表为卖家基本信息表，其字段有seller_id、sale_level，其中sale_levels是卖家的一个分层评级信息，比如吧卖家分为6个级别：S0、S1、S2、S3、S4和S5。")]),t._v(" "),a("li",[t._v("要获得的结果是每个买家在各个级别的卖家的成交比例信息，比如：")])])])]),t._v(" "),a("p",[t._v("某买家：S0:10%；S1:20%；S2:20%；S3:10%；S4:20%；S5:10%。")])])]),t._v(" "),a("p",[t._v("问题2：")]),t._v(" "),a("p",[t._v("问题SQL")]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n　　m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s5\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\tb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day \n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" a\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" \n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sale_level "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_B "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" b \n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" m\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v("\nm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br")])]),a("blockquote",[a("p",[t._v("​\t此SQL会引起数据倾斜，原因在于卖家的二八准则，某些卖家90天内会有几百万甚至上千万的买家，但是大部分的卖家90天内买家的数目并不多，join table_A和table_B的时候，")]),t._v(" "),a("p",[t._v("​\tODPS会按照seller_id进行分发，table_A的大卖家引起了数据倾斜。")]),t._v(" "),a("p",[t._v("​\t但是数据本身无法用mapjoin table_B解决，因为卖家超过千万条，文件大小有几个GB，超过了1GB的限制。")])]),t._v(" "),a("p",[t._v("扩容 join：")]),t._v(" "),a("ol",[a("li",[t._v("通用方案")])]),t._v(" "),a("blockquote",[a("p",[t._v("建立一个numbers表，其值只有一列int 行，比如从1到10（具体值可根据倾斜程度确定），然后放大B表10倍，再取模join。代码如下：")])]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\t　m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s5\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\tb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" a\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v("\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\t\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*+mapjoin(members)*/")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" member\n\t\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_B\n\t\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" members\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" b \n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id\n\t\t"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("AND")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("MOD")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("number\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" m\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v("\nm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br")])]),a("blockquote",[a("p",[t._v("mod(a, b) ：返回 a 除以 b 的余数")]),t._v(" "),a("p",[t._v("​\t此思路的核心在于，既然按照seller_id分发会倾斜，那么再人工增加一列进行分发，这样之前倾斜的值的倾斜程度会减少到原来的1/10，可以通过配置numbers表改放大倍数来降低倾斜程度，但这样做的一个弊端是B表也会膨胀N倍。")])]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("专用方案")])]),t._v(" "),a("blockquote",[a("p",[t._v("通用方案的思路把B表的每条数据都放大了相同的倍数，实际上这是不需要的，只需要把大卖家放大倍数即可：需要首先知道大卖家的名单，即先建立一个临时表动态存放每天最新的大卖家（比如dim_big_seller）,同时此表的大卖家要膨胀预先设定的倍数（1000倍）。")]),t._v(" "),a("p",[t._v("在A表和B表分别新建一个join列，其逻辑为：如果是大卖家，那么concat一个随机分配正整数（0到预定义的倍数之间，本例为0~1000）；如果不是，保持不变。")])]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\tm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s5 \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\tb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day \n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*+mapjoin(big)*/")]),t._v(" buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("big"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IS")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("table_A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rnd'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" rand"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("table_A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" seller_id_joinkey \n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("OUTER")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*big表seller_id有重复，请注意一定要 GROUP BY 后再 JOIN,保证 table_A的行数保持不变*/")]),t._v("\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" dim_big_seller "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("big\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" table_A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" big"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" a\n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" \n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*+mapjoin(big)*/")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\t\t\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*big表的seller_id_joinkey生成逻辑和上面的生成逻辑一样*/")]),t._v("\n\t\t\t\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("COALESCE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" seller_id_joinkey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" table_B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" seller_id_joinkey 　　　　"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_B\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("OUT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v("\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*table_B表 JOIN大卖家表后大卖家行数扩大 1000倍,其它卖家行数保持不变*/")]),t._v("\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seller_id_joinkey "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" dim_big_seller "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" big \n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" table_B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" big"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" b \n\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id_joinkey "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id_joinkey "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("AND")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("MOD")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("number\n\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" m\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v("\nm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br"),a("span",{staticClass:"line-number"},[t._v("33")]),a("br"),a("span",{staticClass:"line-number"},[t._v("34")]),a("br"),a("span",{staticClass:"line-number"},[t._v("35")]),a("br"),a("span",{staticClass:"line-number"},[t._v("36")]),a("br"),a("span",{staticClass:"line-number"},[t._v("37")]),a("br"),a("span",{staticClass:"line-number"},[t._v("38")]),a("br"),a("span",{staticClass:"line-number"},[t._v("39")]),a("br")])]),a("blockquote",[a("p",[t._v("相比通用方案，专用方案的运行效率明细好了许多，因为只是将B表中大卖家的行数放大了1000倍，其它卖家的行数保持不变，但同时代码复杂了很多，而且必须首先建立大数据表。")])]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[t._v("动态一分为二")])]),t._v(" "),a("blockquote",[a("p",[t._v("实际上方案2和3都用了一分为二的思想，但是都不彻底，对于mapjoin不能解决的问题，终极解决方案是动态一分为二，即对倾斜的键值和不倾斜的键值分开处理，不倾斜的正常join即可，倾斜的把他们找出来做mapjoin，最后union all其结果即可。")]),t._v(" "),a("p",[t._v("但是此种解决方案比较麻烦，代码复杂而且需要一个临时表存放倾斜的键值。")])]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*由于数据倾斜,先找出 90天买家超过10000的卖家*/")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" overwrite "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" temp_table_B\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" byr_cnt "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" a "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("byr_cnt "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" m\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sale_level "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_B "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" n "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*对于 90天买家超过10000的卖家直接 mapjoin,对其它卖家直接正常 JOIN即可。*/")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n　　m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n　　"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CASE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHEN")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("THEN")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("END")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" pay_cnt_90day_s5\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\tb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t\ta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day\n\t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v("\n\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" a \n\t\t  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v("\n\t\t\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A a \n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" temp_table_B b "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id\n\t\t\t\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("IS")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v("\n\t\t  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" b "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id \n\t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UNION")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALL")]),t._v(" \n\t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*+mapjoin(b)*/")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sale_level"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pay_cnt_90day\n\t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" buyer_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pay_cnt_90day "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_A "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" a\n\t "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" seller_id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sale_level "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" table_B "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" b "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seller_id\n\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" m \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v("\n\tm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("buyer_id\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br"),a("span",{staticClass:"line-number"},[t._v("33")]),a("br"),a("span",{staticClass:"line-number"},[t._v("34")]),a("br"),a("span",{staticClass:"line-number"},[t._v("35")]),a("br")])]),a("blockquote",[a("p",[a("strong",[t._v("总结：方案1、2以及方案3中的同用方案不能保证解决大表join大表问题，因为它们都存在种种不同的限制和特定使用场景。而方案3的专用方案和方案4是推荐的优化方案，但是它们都需要新建一个临时表来存储每日动态变化的大卖家。相对方案4来说，方案3的专用方案不需要对代码框架进行修改，但是B表会被放大，所以一定要是是维度表，不然统计结果会是错误的。方案4最通用，自由度最高，但是对代码的更改也最大，甚至修改更难代码框架，可以作为终极方案使用。")])])])])]),t._v(" "),a("h3",{attrs:{id:"_7-8-其他-hql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-8-其他-hql"}},[t._v("#")]),t._v(" 7.8 其他（HQL）")]),t._v(" "),a("p",[t._v("unoin 与 union all 的区别")]),t._v(" "),a("ol",[a("li",[t._v("union会对两个子查询的结果去重合并")]),t._v(" "),a("li",[t._v("union all 不会对子查询的结果去重处理")])]),t._v(" "),a("h2",{attrs:{id:"_8-sqoop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-sqoop"}},[t._v("#")]),t._v(" 8. Sqoop")]),t._v(" "),a("blockquote",[a("p",[t._v("​\t关系型数据库的数据与非关系型数据库中 (hdfs) 大量数据的迁移")]),t._v(" "),a("p",[t._v("​\tSqoop是一个在结构化数据和Hadoop之间进行批量数据迁移的工具，结构化数据可以是MySQL、Oracle等RDBMS。Sqoop底层用MapReduce程序实现抽取、转换、加载，在翻译出的MapReduce 中主要是对InputFormat和OutputFormat进行定制。MapReduce天生的特性保证了并行化和高容错率。\n  如果要用Sqoop，必须正确安装并配置Hadoop，因依赖于本地的Hadoop环境启动MR程序；MySQL、Oracle等数据库的JDBC驱动也要放到Sqoop的lib目录下。")])]),t._v(" "),a("h3",{attrs:{id:"_8-1-原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-1-原理"}},[t._v("#")]),t._v(" 8.1 原理")]),t._v(" "),a("h4",{attrs:{id:"_8-1-1-数据导入"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-1-1-数据导入"}},[t._v("#")]),t._v(" 8.1.1 数据导入")]),t._v(" "),a("ol",[a("li",[t._v("sqoop会通过jdbc来获取需要的数据库的元数据信息，例如：导入的表的列名，数据类型。")]),t._v(" "),a("li",[t._v("这些数据库的数据类型会被映射成为java的数据类型，根据这些信息，sqoop会生成一个与表名相同的类用来完成序列化工作，保存表中的每一行记录。")]),t._v(" "),a("li",[t._v("sqoop开启MapReduce作业")]),t._v(" "),a("li",[t._v("启动的作业在input的过程中，会通过jdbc读取数据表中的内容，这时，会使用sqoop生成的类进行序列化。")]),t._v(" "),a("li",[t._v("最后将这些记录写到hdfs上，在写入hdfs的过程中，同样会使用sqoop生成的类进行反序列化。")])]),t._v(" "),a("h4",{attrs:{id:"_8-1-2-数据导出"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-1-2-数据导出"}},[t._v("#")]),t._v(" 8.1.2 数据导出")]),t._v(" "),a("ol",[a("li",[t._v("首先sqoop通过jdbc访问关系型数据库获取需要导出的信息的元数据信息")]),t._v(" "),a("li",[t._v("根据获取的元数据信息，sqoop生成一个Java类，用来承载数据的传输，该类必须实现序列化")]),t._v(" "),a("li",[t._v("启动MapReduce程序")]),t._v(" "),a("li",[t._v("sqoop利用生成的这个类，并行从hdfs中获取数据")]),t._v(" "),a("li",[t._v("每个map作业都会根据读取到的导出表的元数据信息和读取到的数据，生成一批insert 语句，然后多个map作业会并行的向MySQL中插入数据。")])]),t._v(" "),a("h3",{attrs:{id:"_8-2-遇到过哪些问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-2-遇到过哪些问题"}},[t._v("#")]),t._v(" 8.2 遇到过哪些问题")]),t._v(" "),a("h4",{attrs:{id:"_8-2-1-导入的坑"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-2-1-导入的坑"}},[t._v("#")]),t._v(" 8.2.1 导入的坑")]),t._v(" "),a("p",[t._v("问题1：mysql中的 NULL 导入到 hdfs 后变成 'null' 字符串")]),t._v(" "),a("p",[t._v("解决：导入时加上参数 -null-string '\\N'  -null-non-string '\\N'")]),t._v(" "),a("p",[t._v("在hive里面。NULL是用\\N来表示的。你可以自己做个实验 insert overwrite table tb select NULL from tb1 limit 1;")]),t._v(" "),a("p",[t._v("然后在去查看原文件就可以发现了。")]),t._v(" "),a("p",[t._v("如果在导入后发现数据错位了，或者有好多原来有值的字段都变成了NULL, 这是因为你原表varchar类型的字段中可能含有\\n\\r等一些特殊字符。")]),t._v(" "),a("p",[t._v("可以加上  –hive-drop-import-delims")]),t._v(" "),a("h3",{attrs:{id:"_8-3-数据量"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8-3-数据量"}},[t._v("#")]),t._v(" 8.3 数据量")]),t._v(" "),a("h2",{attrs:{id:"_9-azkaban"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_9-azkaban"}},[t._v("#")]),t._v(" 9. Azkaban")]),t._v(" "),a("h2",{attrs:{id:"_10-hbase"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-hbase"}},[t._v("#")]),t._v(" 10. HBase")]),t._v(" "),a("h3",{attrs:{id:"_10-1-架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-1-架构"}},[t._v("#")]),t._v(" 10.1 架构")]),t._v(" "),a("ul",[a("li",[t._v("ZK、HDFS")]),t._v(" "),a("li",[t._v("Master")]),t._v(" "),a("li",[t._v("RegionServer：\n"),a("ul",[a("li",[t._v("Hlog（WAL）：预写日志，防止RegionServer故障，导致MemStore中的数据丢失")]),t._v(" "),a("li",[t._v("Region：\n"),a("ul",[a("li",[t._v("Store：\n"),a("ul",[a("li",[t._v("memoryStore：写缓存，K-V在MemStore中排序，达到阈值才会Flush到StoreFile，每次Flush生成一个新的StoreFile")]),t._v(" "),a("li",[t._v("storeFile：存储有序的K-V文件，存储在HDFS上，每个Store会有一个或多个StoreFile（HFile），数据在每个StoreFile中都是有序的。")])])])])]),t._v(" "),a("li",[t._v("BlockCache：读缓存，每次新查询的数据会缓存在BlockCache中。")])])])]),t._v(" "),a("h3",{attrs:{id:"_10-2-数据流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-2-数据流程"}},[t._v("#")]),t._v(" 10.2 数据流程")]),t._v(" "),a("blockquote",[a("p",[t._v("读比写慢")])]),t._v(" "),a("ol",[a("li",[a("p",[t._v("写")]),t._v(" "),a("ol",[a("li",[t._v("Client先访问 zookeeper，获取 hbase:meta表位于哪个Region Server。")]),t._v(" "),a("li",[t._v("访问对应的Region Server，获取hbase:meta表，根据写请求的namespace:table/rowkey，查询出目标数据位于哪个Region Server中的哪个 Region中。并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。")]),t._v(" "),a("li",[t._v("与目标Region Server 进行通讯")]),t._v(" "),a("li",[t._v("将数据顺序写入（追加）到 WAL")]),t._v(" "),a("li",[t._v("将数据写入对应的 MemStore，数据会在 MemStore 进行排序")]),t._v(" "),a("li",[t._v("向客户端发送 ack")]),t._v(" "),a("li",[t._v("等达到 MemStore 的刷写时机后"),a("strong",[t._v("hbase.hregion.memstore.flush.size（默认值128M）")]),t._v(",将数据刷写到 storeFile （HFile）。")])])]),t._v(" "),a("li",[a("p",[t._v("读")]),t._v(" "),a("ol",[a("li",[t._v("Client先访问zookeeper，获取 hbase:meta表位于哪个Region Server。")]),t._v(" "),a("li",[t._v("访问对应的 Region Server，获取 hbase:meta 表，根据读请求的 namespace:table/rowkey，查询出目标数据位于哪个 Region Server中的哪个 Region 中。并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。")]),t._v(" "),a("li",[t._v("与目标 Region Server进行通讯")]),t._v(" "),a("li",[t._v("分别在 MemStore 和 Store File（HFile）中查询目标数据，并将查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（timestamp）或者不同的类型（Pub/Delete）")]),t._v(" "),a("li",[t._v("将查询到的新的数据块（Block，HFile数据存储单元，默认大小为 64 KB）缓存到 Block Cache。")]),t._v(" "),a("li",[t._v("将合并后的最终结果返回给客户端")])])]),t._v(" "),a("li",[a("p",[t._v("刷写")]),t._v(" "),a("ol",[a("li",[t._v("regionserver：堆内存  0.4*0.95 = 0.38")]),t._v(" "),a("li",[t._v("region：memstore  128M")]),t._v(" "),a("li",[t._v("时间：1h (默认)  lastEdit")])]),t._v(" "),a("blockquote",[a("p",[t._v("MemStore刷写时机：")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("region ：当某个memstroe的大小达到了hbase.hregion.memstore.flush.size（默认值128M），其所在region的所有memstore都会刷写。")]),t._v(" "),a("p",[t._v("当memstore的大小达到了\nhbase.hregion.memstore.flush.size（默认值128M）")]),t._v(" "),a("p",[t._v("hbase.hregion.memstore.block.multiplier（默认值4）\n时，会阻止继续往该memstore写数据。")])]),t._v(" "),a("li",[a("p",[t._v("当region server中memstore的总大小达到")]),t._v(" "),a("p",[a("code",[t._v("java_heapsize * hbase.regionserver.global.memstore.size（默认值0.4）* hbase.regionserver.global.memstore.size.lower.limit（默认值0.95）")])]),t._v(" "),a("p",[t._v("region会按照其所有memstore的大小顺序（由大到小）依次进行刷写。直到region server中所有memstore的总大小减小到上述值以下。")]),t._v(" "),a("p",[t._v("当region 中memstore的总大小达到\n"),a("code",[t._v("java_heapsize * hbase.regionserver.global.memstore.size（默认值0.4）")]),t._v("\n时，会阻止继续往所有的memstore写数据。")])]),t._v(" "),a("li",[a("p",[t._v("到达自动刷写的时间，也会触发memstore flush。自动刷新的时间间隔由该属性进行配置hbase.regionserver.optionalcacheflushinterval（默认1小时）。")])]),t._v(" "),a("li",[a("p",[t._v("当WAL文件的数量超过hbase.regionserver.max.logs，region会按照时间顺序依次进行刷写，直到WAL文件数量减小到hbase.regionserver.max.log以下（该属性名已经废弃，现无需手动设置，最大值为32）。")])])])])]),t._v(" "),a("li",[a("p",[t._v("合并（StoreFile Compaction）")]),t._v(" "),a("ol",[a("li",[t._v("由于 memstore 每次刷写都会生成一个新的 HFile，且同一个字段的不同版本 (timestamp) 和不同类型(Put/Delete) 有可能会分布在不同的 HFile 中，因此查询时需要遍历所有的 HFile。为了减少 HFile 的个数，以及清理掉过期和删除的数据，会进行 StoreFile Compaction。")]),t._v(" "),a("li",[t._v("Compaction 分为两种，分别是 Minor Compaction 和 Major Compaction。\n"),a("ol",[a("li",[t._v("Minor Compaction 会将临近的若干个较小的 HFile 合并成一个较大的 HFile，并清理掉部分过期和删除的数据。")]),t._v(" "),a("li",[t._v("Major Compaction 会将一个 Store 下的所有的 HFile 合并成一个大 HFile，并且会清理掉所有过期和删除的数据。")])])])])]),t._v(" "),a("li",[a("p",[t._v("切分（Region Split）")]),t._v(" "),a("ol",[a("li",[t._v("默认情况下，每个Table起初只有一个Region，随着数据的不断写入，Region会自动进行拆分。刚拆分时，两个子Region都位于当前的Region Server，但处于负载均衡的考虑，HMaster有可能会将某个Region转移给其他的Region Server。")]),t._v(" "),a("li",[t._v("时机：\n"),a("ol",[a("li",[t._v("当1个region中的某个Store下所有StoreFile的总大小超过hbase.hregion.max.filesize （10G），该Region就会进行拆分（0.94版本之前）")]),t._v(" "),a("li",[t._v("当1个region中的某个Store下所有StoreFile的总大小超过Min(initialSize"),a("em",[t._v('R^3 ,hbase.hregion.max.filesize")，该Region就会进行拆分。其中initialSize的默认值为2')]),t._v("hbase.hregion.memstore.flush.size，R为当前Region Server中属于该Table的Region个数（0.94版本之后）")]),t._v(" "),a("li",[t._v("具体的切分策略为：\n第一次split：1^3 * 256 = 256MB\n第二次split：2^3 * 256 = 2048MB\n第三次split：3^3 * 256 = 6912MB\n第四次split：4^3 * 256 = 16384MB > 10GB，因此取较小的值10GB\n后面每次split的size都是10GB了。")]),t._v(" "),a("li",[t._v("Hbase 2.0引入了新的split策略：如果当前RegionServer上该表只有一个Region，按照2 * hbase.hregion.memstore.flush.size分裂，否则按照hbase.hregion.max.filesize分裂。")])])])])])]),t._v(" "),a("h3",{attrs:{id:"_10-3-rowkey-设计"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-3-rowkey-设计"}},[t._v("#")]),t._v(" 10.3 RowKey 设计")]),t._v(" "),a("blockquote",[a("p",[t._v("​\t一条数据的唯一标识就是rowkey，那么这条数据存储于哪个分区，取决于rowkey处于哪个一个预分区的区间内，设计rowkey的主要目的 ，就是让数据均匀的分布于所有的region中，在一定程度上防止数据倾斜。接下来我们就谈一谈rowkey常用的设计方案。")])]),t._v(" "),a("ul",[a("li",[t._v("生成随机数、hash、散列值")]),t._v(" "),a("li",[t._v("字符串反转")]),t._v(" "),a("li",[t._v("字符串拼接")])]),t._v(" "),a("h3",{attrs:{id:"_10-4-二级索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-4-二级索引"}},[t._v("#")]),t._v(" 10.4 二级索引")]),t._v(" "),a("blockquote",[a("p",[t._v("一级索引：RowKey")])]),t._v(" "),a("p",[t._v("原理：协处理器（Coprecessor）")]),t._v(" "),a("ol",[a("li",[t._v("二级索引配置文件")])]),t._v(" "),a("p",[t._v("添加如下配置到 HBase 的 HRegionserver 节点的 hbase-site.xml")]),t._v(" "),a("div",{staticClass:"language-xml line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- phoenix regionserver 配置参数--\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hbase.regionserver.wal.codec"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("ol",{attrs:{start:"2"}},[a("li",[a("p",[t._v("全局索引（global index）")])]),t._v(" "),a("li",[a("p",[t._v("使用场景：读多写少")])])]),t._v(" "),a("blockquote",[a("p",[t._v("Global Index是默认的索引格式，创建全局索引时，会在HBase中建立一张新表。也就是说索引数据和数据表是存放在不同的表中的。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("写数据的时候会消耗大量开销，因为索引表也要更新，而索引表是分布在不同的数据节点上的，跨节点的数据传输带来了较大的性能消耗。\n")])])]),a("p",[t._v("​\t在读数据的时候Phoenix会选择索引表来降低查询消耗的时间。")])]),t._v(" "),a("p",[t._v("创建单字段全局索引：")]),t._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v(" my_index "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" my_table "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("my_col"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v(" B "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 以上索引对下面查询不生效，因为索引必须包含所有列")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" A "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" age "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("index")]),t._v(" B "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" A"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" include "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br")])]),a("ol",{attrs:{start:"3"}},[a("li",[t._v("本地索引：直接将索引数据保存在原表中（原Region）\n"),a("ol",[a("li",[t._v("使用场景：写多读少")])])])]),t._v(" "),a("h2",{attrs:{id:"_11-spark"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-spark"}},[t._v("#")]),t._v(" 11. Spark")]),t._v(" "),a("h3",{attrs:{id:"_11-1-入门"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-1-入门"}},[t._v("#")]),t._v(" 11.1 入门")]),t._v(" "),a("ol",[a("li",[t._v("端口号\n"),a("ol",[a("li",[t._v("Yarn   8032   8088   10020   19888   18080(Spark)")]),t._v(" "),a("li",[t._v("7077  8080  4040")])])]),t._v(" "),a("li",[t._v("提交方式，参数，流程\n"),a("ol",[a("li",[t._v("Yark-Cluster")])])]),t._v(" "),a("li",[t._v("WordCount\n"),a("ol",[a("li",[t._v('sc.textFile("")')]),t._v(" "),a("li",[t._v('.flatMap(_.split(""))')]),t._v(" "),a("li",[t._v(".map((_,1))")]),t._v(" "),a("li",[a("code",[t._v(".reduceByKey(_+_)")])]),t._v(" "),a("li",[t._v('.saveAsTextFile(" ")')])])])]),t._v(" "),a("h3",{attrs:{id:"_11-2-sparkcore-rdd"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-2-sparkcore-rdd"}},[t._v("#")]),t._v(" 11.2 SparkCore     RDD")]),t._v(" "),a("ol",[a("li",[t._v("五大属性\n"),a("ol",[a("li",[t._v("一个分区列表")]),t._v(" "),a("li",[t._v("对于每个切片有一个计算函数")]),t._v(" "),a("li",[t._v("与其他RDD的依赖关系")]),t._v(" "),a("li",[t._v("分区器 (非必须)")]),t._v(" "),a("li",[t._v("优先计算位置     宁愿移动计算不愿移动数据")])])]),t._v(" "),a("li",[t._v("算子(面试问法)\n"),a("ol",[a("li",[t._v("直接法\n"),a("ol",[a("li",[t._v("常用的转换算子、行动算子、带有Shuffle操作的算子")])])]),t._v(" "),a("li",[t._v("比较法\n"),a("ol",[a("li",[t._v("map    mapPartitions")]),t._v(" "),a("li",[t._v("groupByKey     reduceByKey")]),t._v(" "),a("li",[t._v("aggregate    aggregateByKey")])])]),t._v(" "),a("li",[t._v("计算结果")])])]),t._v(" "),a("li",[t._v("任务切分(依赖关系)\n"),a("ol",[a("li",[t._v("宽依赖(shuffle)    窄依赖")]),t._v(" "),a("li",[t._v("Application    SparkContext")]),t._v(" "),a("li",[t._v("Job    行动算子")]),t._v(" "),a("li",[t._v("Stage    宽依赖")]),t._v(" "),a("li",[t._v("Task    当前Stage最后一个RDD的分区数")])])]),t._v(" "),a("li",[t._v("持久化\n"),a("ol",[a("li",[t._v("Cache    Checkpoint")]),t._v(" "),a("li",[t._v("使用场景：\n"),a("ol",[a("li",[t._v("RDD的复用")]),t._v(" "),a("li",[t._v("当任务联很长且中间有一个Shuffle操作，在Shuffle之后进行持久化")])])]),t._v(" "),a("li",[t._v("使用方式：结合使用")])])]),t._v(" "),a("li",[t._v("序列化    Kryo")]),t._v(" "),a("li",[t._v("共享变量\n"),a("ol",[a("li",[t._v("累加器\t\t\t共享写操作")]),t._v(" "),a("li",[t._v("广播变量      共享读操作")]),t._v(" "),a("li",[t._v("变量过大，借用第三方框架")])])])]),t._v(" "),a("h3",{attrs:{id:"_11-3-sparksql-df、ds"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-3-sparksql-df、ds"}},[t._v("#")]),t._v(" 11.3 SparkSQL     DF、DS")]),t._v(" "),a("p",[a("strong",[t._v("SQL")]),t._v("\t读写数据    SparkSession\t\tDF、DS")]),t._v(" "),a("p",[t._v("默认文件格式：Parquet")]),t._v(" "),a("p",[t._v("读：")]),t._v(" "),a("p",[t._v('SparkSession.read.json("")')]),t._v(" "),a("p",[t._v('SparkSession.read.format("json").load("")')]),t._v(" "),a("p",[t._v('SparkSession.read[.format("parquet")].load("")：默认格式')]),t._v(" "),a("p",[t._v("写：")]),t._v(" "),a("p",[t._v('df.write().json("")')]),t._v(" "),a("p",[t._v('df.write().format("json").save("")')]),t._v(" "),a("p",[t._v('df.write()[.format("parquet")].save("")')]),t._v(" "),a("p",[t._v("转换：")]),t._v(" "),a("p",[t._v("RDD <=> DF <=> DS      区别于互相转换")]),t._v(" "),a("h3",{attrs:{id:"_11-4-sparkstreamingdstream"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-4-sparkstreamingdstream"}},[t._v("#")]),t._v(" 11.4 SparkStreaming\t\tDStream")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("反压     背压")])]),t._v(" "),a("li",[a("p",[t._v("读取 Kafka 数据的方式")]),t._v(" "),a("ol",[a("li",[t._v("Receiver")]),t._v(" "),a("li",[t._v("Direct")])])]),t._v(" "),a("li",[a("p",[t._v("有状态的算子：updateStateByKey()  不推荐使用")])]),t._v(" "),a("li",[a("p",[t._v("优雅的关闭")]),t._v(" "),a("ol",[a("li",[t._v("Yarn模式：yarn命令  kill")]),t._v(" "),a("li",[t._v("监控外部系统")])])]),t._v(" "),a("li",[a("p",[t._v("开窗")]),t._v(" "),a("ol",[a("li",[t._v("滑动窗口：窗口大小，滑动步长；两者必须是批次大小的整数倍")])])]),t._v(" "),a("li",[a("p",[t._v("写库操作")]),t._v(" "),a("p",[a("code",[t._v("foreachRDD(rdd-> {")])]),t._v(" "),a("p",[t._v("​\t"),a("code",[t._v("rdd.foreachPartition(iter -> {")])]),t._v(" "),a("p",[t._v("​\t\t"),a("code",[t._v("// 1.获取连接")])]),t._v(" "),a("p",[t._v("​\t\t"),a("code",[t._v("// 2.写出数据")])]),t._v(" "),a("p",[t._v("​\t\t"),a("code",[t._v("iter.foreach(line -> {")])]),t._v(" "),a("p",[t._v("​\t\t\t"),a("code",[t._v("TODO 使用连接")])]),t._v(" "),a("p",[t._v("​\t\t\t"),a("code",[t._v("// 3.释放连接")])]),t._v(" "),a("p",[t._v("​\t\t"),a("code",[t._v("})")])]),t._v(" "),a("p",[t._v("​\t"),a("code",[t._v("})")])]),t._v(" "),a("p",[a("code",[t._v("})")])])])]),t._v(" "),a("h3",{attrs:{id:"_11-5-内核"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-5-内核"}},[t._v("#")]),t._v(" 11.5 内核")]),t._v(" "),a("p",[t._v("​\t内核文档  第 0 章  PPT")]),t._v(" "),a("h3",{attrs:{id:"_11-6-优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-6-优化"}},[t._v("#")]),t._v(" 11.6 优化")]),t._v(" "),a("h3",{attrs:{id:"_11-7-shuffle"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_11-7-shuffle"}},[t._v("#")]),t._v(" 11.7 shuffle")]),t._v(" "),a("blockquote",[a("p",[t._v("Spark的Shuffle有 Hash Shuffle和 Sort Shuffle两种。")])]),t._v(" "),a("p",[t._v("在 Spark 1.2 以前，默认的 shuffle 计算引擎是 HashShuffleManager。")]),t._v(" "),a("p",[t._v("​\tHashShuffleManager有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。因此在 Spark 1.2 以后的版本中，默认的 ShuffleManager 改成了 SortShuffleManager。")]),t._v(" "),a("p",[t._v("​\tSortShuffleManager相较于前者来说，有了一定的改进。主要就在于，每个 Task 在进行Shuffle操作时，虽然也会产生较多的临时磁盘文件，但是最后会将所有的临时文件合并 (merge) 成一个磁盘文件，因此每个 Task 就只有一个磁盘文件。在下一个 stage 的 shuffle read task 拉取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可。")]),t._v(" "),a("h2",{attrs:{id:"_12-flink"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-flink"}},[t._v("#")]),t._v(" 12. Flink")]),t._v(" "),a("h3",{attrs:{id:"_12-1-flink与sparkstreaming之间的区别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-1-flink与sparkstreaming之间的区别"}},[t._v("#")]),t._v(" 12.1 Flink与SparkStreaming之间的区别")]),t._v(" "),a("p",[t._v("本质上：Flink基于事件触发的计算，真正意义上的流式计算框架；SparkStreaming基于时间触发的计算，微批次的计算框架。")]),t._v(" "),a("p",[t._v("状态：Flink有状态的计算框架")]),t._v(" "),a("p",[t._v("CheckPoint：Flink只存储状态数据，SparkStreaming存储计算逻辑")]),t._v(" "),a("p",[a("code",[t._v('StreamingContext.getActiveOrCreate(()=>StreamingContext, "ck路径")')])]),t._v(" "),a("p",[t._v("时间语义：Flink有事件时间")]),t._v(" "),a("p",[t._v("窗口：Flink窗口种类更多")]),t._v(" "),a("p",[t._v("StreamingContext优点：微批次，吞吐量大")]),t._v(" "),a("h3",{attrs:{id:"_12-2-提交方式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-2-提交方式"}},[t._v("#")]),t._v(" 12.2 提交方式")]),t._v(" "),a("p",[t._v("Yarn-per-job模式，脚本提交")]),t._v(" "),a("p",[t._v("任务链：合并不同算子的 subTask，合并成一个 subTask")]),t._v(" "),a("p",[t._v("​\t要求： one-to-one、并行度相同、共享组相同")]),t._v(" "),a("p",[t._v("Slot 共享组：没有指定其他共享组，所有算子均为“default”组，所需的 Slot 数量为最大并行度指定有不同共享组，任务所需的Slot数量为各组最大并行度之和")]),t._v(" "),a("h3",{attrs:{id:"_12-3-算子"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-3-算子"}},[t._v("#")]),t._v(" 12.3 算子")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("分层")]),t._v(" "),a("ol",[a("li",[t._v("TableAPI/FlinkSQL")]),t._v(" "),a("li",[t._v("DataStream\n"),a("ol",[a("li",[t._v("基础函数：")]),t._v(" "),a("li",[t._v("富函数：运行时上下文(状态编程)、生命周期方法")])])]),t._v(" "),a("li",[t._v("ProcessAPI：侧输出流、定时器(窗口函数不能定义定时器)")])]),t._v(" "),a("p",[t._v("基本算子：Map、faltMap、filter")]),t._v(" "),a("p",[t._v("聚合算子：sum、max、maxBy、min、minBy、reduce")])]),t._v(" "),a("li",[a("p",[t._v("重分区")]),t._v(" "),a("p",[t._v("keyBy    shuffle    Rebalance    rescale    global   broadcast   forward")])])]),t._v(" "),a("h3",{attrs:{id:"_12-4-窗口"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-4-窗口"}},[t._v("#")]),t._v(" 12.4 窗口*")]),t._v(" "),a("ol",[a("li",[t._v("时间语义\n"),a("ol",[a("li",[t._v("处理时间")]),t._v(" "),a("li",[t._v("进入系统时间")]),t._v(" "),a("li",[t._v("事件时间：WaterMark\n"),a("ol",[a("li",[t._v("本质：在流中传输一种特殊的数据，时间戳")]),t._v(" "),a("li",[t._v("作用：处理乱序数据")]),t._v(" "),a("li",[t._v("如何产生作用：通过延迟关窗实现")]),t._v(" "),a("li",[t._v("生成：周期性、断点式")]),t._v(" "),a("li",[t._v("传递：广播传递、比上一次WM大才会向下游发送，下游的WM取决于上游最小的WM")])])])])]),t._v(" "),a("li",[t._v("窗口的分类\n"),a("ol",[a("li",[t._v("事件个数\n"),a("ol",[a("li",[t._v("滚动")]),t._v(" "),a("li",[t._v("滑动")])])]),t._v(" "),a("li",[t._v("时间\n"),a("ol",[a("li",[t._v("滚动")]),t._v(" "),a("li",[t._v("滑动")]),t._v(" "),a("li",[t._v("会话")])])])])])]),t._v(" "),a("h3",{attrs:{id:"_12-5-状态编程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-5-状态编程"}},[t._v("#")]),t._v(" 12.5 状态编程*")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("种类")]),t._v(" "),a("ol",[a("li",[t._v("Raw")]),t._v(" "),a("li",[t._v("Managered\n"),a("ol",[a("li",[t._v("算子状态\n"),a("ol",[a("li",[t._v("List、BroadCase、UnionList")])])]),t._v(" "),a("li",[t._v("键控状态\n"),a("ol",[a("li",[t._v("Value、List、Map、Reduce、Aggregate")])])])])])])]),t._v(" "),a("li",[a("p",[t._v("用法")]),t._v(" "),a("ol",[a("li",[t._v("运行时上下文")]),t._v(" "),a("li",[t._v("增删改查")]),t._v(" "),a("li",[t._v("TTL")])])]),t._v(" "),a("li",[a("p",[t._v("状态后端")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("种类")]),t._v(" "),a("ol",[a("li",[t._v("Memory")]),t._v(" "),a("li",[t._v("FS")]),t._v(" "),a("li",[t._v("RocksDB")])])]),t._v(" "),a("li",[a("p",[t._v("CheckPoint一致性")]),t._v(" "),a("p",[t._v("分布式快照算法：必须是在所有的任务处理完同一条数据之后保存状态")])]),t._v(" "),a("li",[a("p",[t._v("端到端的一致性")]),t._v(" "),a("p",[t._v("整个流的一致性取决于最弱环节")])]),t._v(" "),a("li",[a("p",[t._v("两阶段提交")])])])])]),t._v(" "),a("h3",{attrs:{id:"_12-6-cep"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-6-cep"}},[t._v("#")]),t._v(" 12.6 CEP")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("定义模式序列")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("单例模式：单个、循环")]),t._v(" "),a("p",[t._v("判断条件")])]),t._v(" "),a("li",[a("p",[t._v("模式序列：严格近邻、宽松近邻、非确定性宽松近邻")])]),t._v(" "),a("li",[a("p",[t._v("within()：限定匹配时间")])])])]),t._v(" "),a("li",[a("p",[t._v("将模式序列作用到流上")])]),t._v(" "),a("li",[a("p",[t._v("提取事件(超时事件 --\x3e  侧输出流)")])])]),t._v(" "),a("h3",{attrs:{id:"_12-7-flinksql-tableapi"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_12-7-flinksql-tableapi"}},[t._v("#")]),t._v(" 12.7 FlinkSQL&TableAPI")]),t._v(" "),a("p",[t._v("事件时间的提取、开窗")]),t._v(" "),a("p",[t._v("UDF、UDAF、UDTF、UDATF(不能在FlinkSQL中使用)")]),t._v(" "),a("h2",{attrs:{id:"_13-0-1"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_13-0-1"}},[t._v("#")]),t._v(" 13. 0 -> 1")]),t._v(" "),a("h2",{attrs:{id:"_14-实时"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_14-实时"}},[t._v("#")]),t._v(" 14. 实时")]),t._v(" "),a("h3",{attrs:{id:"_14-1-ods-原始数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_14-1-ods-原始数据"}},[t._v("#")]),t._v(" 14.1 ODS (原始数据)")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("行为数据：Flume  ->  Kafka(Pulsar)")])]),t._v(" "),a("li",[a("p",[t._v("业务数据：FlinkCDC")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("FlinkCDC")]),t._v(" "),a("th",[t._v("MaxWell")]),t._v(" "),a("th",[t._v("Canal")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("初始化(多库多表)")]),t._v(" "),a("td",[t._v("初始化(单表)")]),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td",[t._v("自定义反序列化方式(单条)")]),t._v(" "),a("td",[t._v("JSON(单条)")]),t._v(" "),a("td",[t._v("JSON(单条SQL)")])])])])])]),t._v(" "),a("p",[t._v("FlinkCDC2.x 在初始化阶段可以不加锁，同时可以多并行度读取数据")]),t._v(" "),a("h3",{attrs:{id:"_14-2-dwd-数据分流-状态识别"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_14-2-dwd-数据分流-状态识别"}},[t._v("#")]),t._v(" 14.2 DWD (数据分流/状态识别)")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("行为数据：")]),t._v(" "),a("p",[t._v("新老用户校验；")]),t._v(" "),a("p",[t._v("分流，使用侧输出流")])]),t._v(" "),a("li",[a("p",[t._v("业务数据：动态分流")]),t._v(" "),a("p",[t._v("FlinkCDC、广播流、自定义 PhoenixSink、自定义Kafka序列化器")]),t._v(" "),a("p",[t._v("HBase：查询明细数据\t行存\tRowKey设计")])])]),t._v(" "),a("h3",{attrs:{id:"_14-3-dwm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_14-3-dwm"}},[t._v("#")]),t._v(" 14.3 DWM")]),t._v(" "),a("p",[t._v("​\t日活明细：状态编程  +  状态的TTL")]),t._v(" "),a("p",[t._v("​\t跳出明细：CEP")]),t._v(" "),a("p",[t._v("​\t订单宽表：双流 join、关联维度表、旁路缓存、异步IO")]),t._v(" "),a("p",[t._v("​\t支付宽表：双流 join")]),t._v(" "),a("h3",{attrs:{id:"_14-4-dws"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_14-4-dws"}},[t._v("#")]),t._v(" 14.4 DWS")]),t._v(" "),a("p",[t._v("​\t访客主题：UNION")]),t._v(" "),a("p",[t._v("​\t商品主题：构造者设计模式、订单ID去重、关联维度表")]),t._v(" "),a("p",[t._v("​\t地区主题：FlinkSQL")]),t._v(" "),a("p",[t._v("​\t关键词主题：FlinkSQL")])])}),[],!1,null,null,null);s.default=n.exports}}]);