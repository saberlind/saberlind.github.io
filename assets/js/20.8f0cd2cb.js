(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{542:function(t,a,s){"use strict";s.r(a);var e=s(4),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"_1-数据分层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-数据分层"}},[t._v("#")]),t._v(" 1. 数据分层")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2Fdatasplit.png",alt:""}})]),t._v(" "),s("p",[t._v("分层原因：")]),t._v(" "),s("ul",[s("li",[t._v("将复杂问题简单化：将复杂的任务分解成多层来完成，每一层只处理简单的任务，方便定位问题。")]),t._v(" "),s("li",[t._v("减少重复开发：规范数据分层，通过中间层数据，能够极大减少重复计算，增加一次计算结果的复用性。")]),t._v(" "),s("li",[t._v("隔离原始数据：不论是数据的异常还是数据的敏感性，使真实数据与统计数据解耦开。")])]),t._v(" "),s("h3",{attrs:{id:"_1-1-数据集市与数仓"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-数据集市与数仓"}},[t._v("#")]),t._v(" 1.1 数据集市与数仓")]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("数据集市(Data Market) 是一种微型的数据仓库，它通常有更少的数据，更少的主题区域，以及更少的历史数据，因此是部门级的，一般只能为某个局部范围内的管理人员服务。")]),t._v(" "),s("li",[t._v("数据仓库是企业级的，能为整个企业各个部门的运行提供决策支持手段。")])])]),t._v(" "),s("h3",{attrs:{id:"_1-2-命名规范"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-命名规范"}},[t._v("#")]),t._v(" 1.2 命名规范")]),t._v(" "),s("ul",[s("li",[t._v("表命名")])]),t._v(" "),s("p",[t._v("ODS层命名为ods_表名")]),t._v(" "),s("p",[t._v("DIM层命名为dim_表名")]),t._v(" "),s("p",[t._v("DWD层命名为dwd_表名")]),t._v(" "),s("p",[t._v("DWS层命名为dws_表名")]),t._v(" "),s("p",[t._v("DWT层命名为dwt_表名")]),t._v(" "),s("p",[t._v("ADS层命名为ads_表名")]),t._v(" "),s("p",[t._v("临时表命名为tmp_表名")]),t._v(" "),s("ul",[s("li",[t._v("脚本命名")])]),t._v(" "),s("p",[t._v("数据源_to_目标_db/log.sh\n用户行为脚本以log为后缀；业务数据脚本以db为后缀。")]),t._v(" "),s("ul",[s("li",[t._v("表字段类型")])]),t._v(" "),s("p",[t._v("数量类型为bigint\n金额类型为decimal(16, 2)，表示：16位有效数字，其中小数部分2位\n字符串(名字，描述信息等)类型为string\n主键外键类型为string\n时间戳类型为bigint")]),t._v(" "),s("h2",{attrs:{id:"_2-数仓理论"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-数仓理论"}},[t._v("#")]),t._v(" 2. 数仓理论")]),t._v(" "),s("h3",{attrs:{id:"_2-1-范式理论"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-范式理论"}},[t._v("#")]),t._v(" 2.1 范式理论")]),t._v(" "),s("h4",{attrs:{id:"_2-1-1-范式概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-1-范式概念"}},[t._v("#")]),t._v(" 2.1.1 范式概念")]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("定义\n"),s("ul",[s("li",[t._v("范式可以理解为设计一张数据表的表结构，符合的标准级别、规范和要求")])])]),t._v(" "),s("li",[t._v("优点\n"),s("ul",[s("li",[t._v("采用范式，可以降低数据的冗余性")])])]),t._v(" "),s("li",[t._v("缺点\n"),s("ul",[s("li",[t._v("范式的缺点是获取数据时，需要通过 Join 拼接出最后的数据")])])]),t._v(" "),s("li",[t._v("分类\n"),s("ul",[s("li",[t._v("目前业界范式有：第一范式(1NF)、第二范式(2NF)、第三范式(3NF)、巴斯-科德范式(BCNF)、第四范式(4NF)、第五范式(5NF)")])])])])]),t._v(" "),s("h4",{attrs:{id:"_2-1-2-函数依赖"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-2-函数依赖"}},[t._v("#")]),t._v(" 2.1.2 函数依赖")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2Fdep.png",alt:""}})]),t._v(" "),s("h4",{attrs:{id:"_2-1-3-三范式区分"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-3-三范式区分"}},[t._v("#")]),t._v(" 2.1.3 三范式区分")]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("第一范式核心原则：属性不可切割")])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2F1nf.png",alt:""}})]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("第二范式核心原则：不能存在“部分函数依赖”")])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2F2nf.png",alt:""}})]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("第三范式核心原则：不能存在传递函数依赖")])])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2F3nf.png",alt:""}})]),t._v(" "),s("h3",{attrs:{id:"_2-2-关系建模与维度建模"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-关系建模与维度建模"}},[t._v("#")]),t._v(" 2.2 关系建模与维度建模")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t关系建模和维度建模是两种数据仓库的建模技术。关系建模由Bill Inmon所倡导，维度建模由Ralph Kimball所倡导。")])]),t._v(" "),s("h4",{attrs:{id:"_2-2-1-关系建模"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-1-关系建模"}},[t._v("#")]),t._v(" 2.2.1 关系建模")]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("关系建模将复杂的数据抽象为两个概念——实体和关系，并使用规范化的方式表示出来。")]),t._v(" "),s("li",[t._v("关系模型严格遵循第三范式（3NF），数据冗余程度低，数据的一致性容易得到保证。由于数据分布于众多的表中，查询会相对复杂，在大数据的场景下，查询效率相对较低。")])])]),t._v(" "),s("h4",{attrs:{id:"_2-2-2-维度建模"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-2-维度建模"}},[t._v("#")]),t._v(" 2.2.2 维度建模")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t维度模型以数据分析作为出发点，不遵循三范式，故数据存在一定的冗余。维度模型面向业务，将业务用事实表和维度表呈现出来。表结构简单，故查询简单，查询效率较高。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2Fmodel.png",alt:""}})]),t._v(" "),s("h3",{attrs:{id:"_2-3-维度表和事实表-★"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-维度表和事实表-★"}},[t._v("#")]),t._v(" 2.3 维度表和事实表（★）")]),t._v(" "),s("h4",{attrs:{id:"_2-3-1-维度表"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-1-维度表"}},[t._v("#")]),t._v(" 2.3.1 维度表")]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("维度表：一般是对事实的描述信息。每一张维表对应现实世界中的一个对象或者概念。    例如：用户、商品、日期、地区等。")]),t._v(" "),s("li",[t._v("特征：\n"),s("ul",[s("li",[t._v("维表的范围很宽（具有多个属性、列比较多）")]),t._v(" "),s("li",[t._v("跟事实表相比，行数相对较小：通常< 10万条")]),t._v(" "),s("li",[t._v("内容相对固定：编码表")])])])])]),t._v(" "),s("p",[t._v("时间维度表：")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("日期 ID")]),t._v(" "),s("th",[t._v("day of week")]),t._v(" "),s("th",[t._v("day of year")]),t._v(" "),s("th",[t._v("季度")]),t._v(" "),s("th",[t._v("节假日")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("2020-01-01")]),t._v(" "),s("td",[t._v("2")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("元旦")])]),t._v(" "),s("tr",[s("td",[t._v("2020-01-02")]),t._v(" "),s("td",[t._v("3")]),t._v(" "),s("td",[t._v("2")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("无")])]),t._v(" "),s("tr",[s("td",[t._v("2020-01-03")]),t._v(" "),s("td",[t._v("4")]),t._v(" "),s("td",[t._v("3")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("无")])]),t._v(" "),s("tr",[s("td",[t._v("2020-01-04")]),t._v(" "),s("td",[t._v("5")]),t._v(" "),s("td",[t._v("4")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("无")])]),t._v(" "),s("tr",[s("td",[t._v("2020-01-05")]),t._v(" "),s("td",[t._v("6")]),t._v(" "),s("td",[t._v("5")]),t._v(" "),s("td",[t._v("1")]),t._v(" "),s("td",[t._v("无")])])])]),t._v(" "),s("h4",{attrs:{id:"_2-3-2-事实表"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-2-事实表"}},[t._v("#")]),t._v(" 2.3.2 事实表")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t事实表中的每行数据代表一个业务事件（下单、支付、退款、评价等）。“事实”这个术语表示的是业务事件的度量值（可统计次数、个数、金额等）")]),t._v(" "),s("p",[t._v("​\t每一个事实表的行包括：具有可加性的数值型的度量值、与维表相连接的外键，通常具有两个和两个以上的外键。")]),t._v(" "),s("ul",[s("li",[t._v("特征\n"),s("ul",[s("li",[t._v("非常的大")]),t._v(" "),s("li",[t._v("内容相对的窄：列数较少（主要是外键id和度量值）")]),t._v(" "),s("li",[t._v("经常发生变化，每天会新增加很多。")])])])])]),t._v(" "),s("p",[t._v("事务型事实表")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t以每个事务或事件为单位，例如一个销售订单记录，一笔支付记录等，作为事实表里的一行数据。一旦事务被提交，事实表数据被插入，数据就不再进行更改，其更新方式为增量更新。")])]),t._v(" "),s("p",[t._v("周期型快照事实表")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t周期型快照事实表中不会保留所有数据，只保留固定时间间隔的数据，例如每天或者每月的销售额，或每月的账户余额等。\n​\t例如购物车，有加减商品，随时都有可能变化，但是我们更关心每天结束时这里面有多少商品，方便我们后期统计分析。")])]),t._v(" "),s("p",[t._v("累积型快照事实表")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t累计快照事实表用于跟踪业务事实的变化。例如，数据仓库中可能需要累积或者存储订单从下订单开始，到订单商品被打包、运输、和签收的各个业务阶段的时间点数据来跟踪订单声明周期的进展情况。当这个业务过程进行时，事实表的记录也要不断更新。")])]),t._v(" "),s("h3",{attrs:{id:"_2-4-维度模型分类"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-维度模型分类"}},[t._v("#")]),t._v(" 2.4 维度模型分类")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2Fstartandsnow.png",alt:""}})]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2Fxz.png",alt:""}})]),t._v(" "),s("h3",{attrs:{id:"_2-5-数据仓库建模-★★"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-数据仓库建模-★★"}},[t._v("#")]),t._v(" 2.5 数据仓库建模（★★）")]),t._v(" "),s("h4",{attrs:{id:"_2-5-1-ods层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-1-ods层"}},[t._v("#")]),t._v(" 2.5.1 ODS层")]),t._v(" "),s("ol",[s("li",[t._v("HDFS 用户行为数据 （/origin_data/mall/log/topic_log/2022-07-11）")]),t._v(" "),s("li",[t._v("HDFS 业务数据 （/origin_data/mall/db/activity_info/2022-07-11）")]),t._v(" "),s("li",[t._v("针对 HDFS 上的用户行为数据和业务数据：\n"),s("ol",[s("li",[t._v("保存数据原貌不做任何修改，起到备份数据的作用")]),t._v(" "),s("li",[t._v("数据采用压缩，减少磁盘存储空间（例如：原始数据100G，可以压缩到10G左右）")]),t._v(" "),s("li",[t._v("创建分区表，防止后续的全表扫描")])])])]),t._v(" "),s("h4",{attrs:{id:"_2-5-2-dim层与dwd层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-2-dim层与dwd层"}},[t._v("#")]),t._v(" 2.5.2 DIM层与DWD层")]),t._v(" "),s("blockquote",[s("ul",[s("li",[s("p",[t._v("DIM层 DWD层需构建维度模型，一般采用星型模型，呈现的状态一般为星座模型。")])]),t._v(" "),s("li",[s("p",[t._v("维度建模步骤：选择业务过程 --\x3e 声明粒度 --\x3e 确认维度 --\x3e 确认事实")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("选择业务过程：")]),t._v(" "),s("ul",[s("li",[t._v("挑选我们感兴趣的业务线，比如下单业务，支付业务，退款业务，物流业务，一条业务线对应一张事实表")])])]),t._v(" "),s("li",[s("p",[t._v("声明粒度：")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("数据粒度指数据仓库的数据中保存数据的细化程度或综合程度的级别")])]),t._v(" "),s("li",[s("p",[t._v("声明粒度意味着精确定义事实表中的一行数据表示什么，应该尽可能选择最小粒度，以此来应各种各样的需求")])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("典型的粒度声明如下：")])]),t._v(" "),s("p",[t._v("订单事实表中一行数据表示的是一个订单中的一个商品项。")]),t._v(" "),s("p",[t._v("支付事实表中一行数据表示的是一个支付记录。")])])])]),t._v(" "),s("li",[s("p",[t._v("确定维度：")]),t._v(" "),s("ul",[s("li",[t._v("维度的主要作用是描述业务是事实，主要表示的是“谁，何处，何时”等信息。")]),t._v(" "),s("li",[t._v("确定维度的原则是：后续需求中是否要分析相关维度的指标。例如，需要统计，什么时间下的订单多，哪个地区下的订单多，哪个用户下的订单多。需要确定的维度就包括：时间维度、地区维度、用户维度")])])]),t._v(" "),s("li",[s("p",[t._v("确定事实：")]),t._v(" "),s("ul",[s("li",[t._v("此处的“事实”一词，指的是业务中的度量值（次数、个数、件数、金额，可以进行累加），例如订单金额、下单次数等")]),t._v(" "),s("li",[t._v("在DWD层，以业务过程为建模驱动，基于每个具体业务过程的特点，构建最细粒度的明细层事实表。事实表可做适当的宽表化处理")])])])])])])]),t._v(" "),s("p",[t._v("事实表和维度表的关联比较灵活，但是为了应对更复杂的业务需求，可以将能关联上的表尽量关联上")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th"),t._v(" "),s("th",[t._v("时间")]),t._v(" "),s("th",[t._v("用户")]),t._v(" "),s("th",[t._v("地区")]),t._v(" "),s("th",[t._v("商品")]),t._v(" "),s("th",[t._v("优惠券")]),t._v(" "),s("th",[t._v("活动")]),t._v(" "),s("th",[t._v("度量值")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("strong",[t._v("订单")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("运费/优惠金额/原始金额/最终金额")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("订单详情")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("件数/优惠金额/原始金额/最终金额")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("支付")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("支付金额")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("加购")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("件数/金额")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("收藏")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("次数")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("评价")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("次数")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("退单")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("件数/金额")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("退款")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("件数/金额")])]),t._v(" "),s("tr",[s("td",[s("strong",[t._v("优惠券领用")])]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td"),t._v(" "),s("td",[t._v("√")]),t._v(" "),s("td"),t._v(" "),s("td",[t._v("次数")])])])]),t._v(" "),s("ul",[s("li",[t._v("DIM和DWD层是以业务过程为驱动")]),t._v(" "),s("li",[t._v("DWS层、DWT层和ADS层都是以需求为驱动，和维度建模已经没有关系了")]),t._v(" "),s("li",[t._v("DWS和DWT都是建宽表，按照主题去建表。主题相当于观察问题的角度。对应着维度表")])]),t._v(" "),s("h4",{attrs:{id:"_2-5-3-dws层与dwt层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-3-dws层与dwt层"}},[t._v("#")]),t._v(" 2.5.3 DWS层与DWT层")]),t._v(" "),s("p",[t._v("DWS层和DWT层统称宽表层，这两层的设计思想大致相同，通过以下案例进行阐述。")]),t._v(" "),s("p",[t._v("1）问题引出：两个需求，统计每个省份订单的个数、统计每个省份订单的总金额\n2）处理办法：都是将省份表和订单表进行join，group by省份，然后计算。同样数据被计算了两次，实际上类似的场景还会更多。")]),t._v(" "),s("p",[t._v("那怎么设计能避免重复计算呢？")]),t._v(" "),s("p",[t._v("针对上述场景，可以设计一张地区宽表，其主键为地区ID，字段包含为：下单次数、下单金额、支付次数、支付金额等。上述所有指标都统一进行计算，并将结果保存在该宽表中，这样就能有效避免数据的重复计算。")]),t._v(" "),s("p",[t._v("总结：\n（１）需要建哪些宽表：以维度为基准。\n（２）宽表里面的字段：是站在不同维度的角度去看事实表，重点关注事实表聚合后的度量值。\n（３）DWS和DWT层的区别：DWS层存放的所有主题对象当天的汇总行为，例如每个地区当天的下单次数，下单金额等，DWT层存放的是所有主题对象的累积行为，例如每个地区最近７天（１５天、３０天、６０天）的下单次数、下单金额等。")]),t._v(" "),s("h4",{attrs:{id:"_2-5-4-ads层"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-4-ads层"}},[t._v("#")]),t._v(" 2.5.4 ADS层")]),t._v(" "),s("p",[t._v("对系统各大主题指标分别进行分析")]),t._v(" "),s("h2",{attrs:{id:"_3-数仓环境搭建"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-数仓环境搭建"}},[t._v("#")]),t._v(" 3. 数仓环境搭建")]),t._v(" "),s("h3",{attrs:{id:"_3-1-hive-环境搭建"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-hive-环境搭建"}},[t._v("#")]),t._v(" 3.1 Hive 环境搭建")]),t._v(" "),s("h4",{attrs:{id:"_3-1-1-hive-引擎"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-1-hive-引擎"}},[t._v("#")]),t._v(" 3.1.1 Hive 引擎")]),t._v(" "),s("blockquote",[s("p",[t._v("Hive引擎包括：默认MR、tez、spark")]),t._v(" "),s("ul",[s("li",[t._v("Hive on Spark：Hive既作为存储元数据又负责SQL的解析优化，语法是HQL语法，执行引擎变成了Spark，Spark负责采用RDD执行。")]),t._v(" "),s("li",[t._v("Spark on Hive : Hive只作为存储元数据，Spark负责SQL解析优化，语法是Spark SQL语法，Spark负责采用DF和DS执行。")])])]),t._v(" "),s("h4",{attrs:{id:"_3-1-2-hive-on-spark-配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-2-hive-on-spark-配置"}},[t._v("#")]),t._v(" 3.1.2 Hive on Spark 配置")]),t._v(" "),s("p",[t._v("兼容性说明")]),t._v(" "),s("blockquote",[s("p",[t._v("​\t官网下载的Hive3.1.2和Spark3.0.0默认是不兼容的。因为Hive3.1.2支持的Spark版本是2.4.5，所以需要我们重新编译Hive3.1.2版本。")]),t._v(" "),s("p",[t._v("​\t编译步骤：官网下载Hive3.1.2源码，修改pom文件中引用的Spark版本为3.0.0，如果编译通过，直接打包获取jar包。如果报错，就根据提示，修改相关方法，直到不报错，打包获取jar包。")])]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("vim")]),t._v(" /opt/module/hive/conf/spark-defaults.conf\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("div",{staticClass:"language-conf line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("spark.master                               yarn\nspark.eventLog.enabled                   true\nspark.eventLog.dir                        hdfs://hadoop102:8020/spark-history\nspark.executor.memory                    1g\nspark.driver.memory\t\t\t\t\t   1g\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("hadoop fs -mkdir /spark-history\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("向HDFS上传Spark纯净版jar包")]),t._v(" "),s("blockquote",[s("ul",[s("li",[t._v("说明1：由于Spark3.0.0非纯净版默认支持的是hive2.3.7版本，直接使用会和安装的Hive3.1.2出现兼容性问题。所以采用Spark纯净版jar包，不包含hadoop和hive相关依赖，避免冲突。")]),t._v(" "),s("li",[t._v("说明2：Hive任务最终由Spark来执行，Spark任务资源分配由Yarn来调度，该任务有可能被分配到集群的任何一个节点。所以需要将Spark的依赖上传到HDFS集群路径，这样集群中任何一个节点都能获取到。")])])]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("tar")]),t._v(" -zxvf /opt/software/spark-3.0.0-bin-without-hadoop.tgz\n\nhadoop fs -mkdir /spark-jars\n\nhadoop fs -put spark-3.0.0-bin-without-hadoop/jars/* /spark-jars\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("p",[t._v("修改 hive-site.xml")]),t._v(" "),s("div",{staticClass:"language-xml line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[t._v("# 新增如下\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--Spark依赖位置（注意：端口号8020必须和namenode的端口号一致）--\x3e")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark.yarn.jars"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hdfs://hadoop102:8020/spark-jars/*"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  \n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--Hive执行引擎--\x3e")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hive.execution.engine"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--Hive和Spark连接超时时间--\x3e")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hive.spark.client.connect.timeout"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("10000ms"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br")])]),s("p",[t._v("注意：hive.spark.client.connect.timeout的默认值是1000ms，如果执行hive的insert语句时，抛如下异常，可以调大该参数到10000ms")]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("FAILED: SemanticException Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create Spark client "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" Spark session d9e0224c-3d14-4bf4-95bc-ee3ec56df48e\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h4",{attrs:{id:"_3-1-3-hive-on-spark-测试"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-3-hive-on-spark-测试"}},[t._v("#")]),t._v(" 3.1.3 Hive on Spark 测试")]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("hive\ncreate table student"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id int, name string"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ninsert into table student values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(","),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'abc'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("出现以下，表示成功")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/datawarehouse%2Fhive%20on%20spark.png",alt:""}})]),t._v(" "),s("h3",{attrs:{id:"_3-2-yarn-配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-yarn-配置"}},[t._v("#")]),t._v(" 3.2 Yarn 配置")]),t._v(" "),s("h4",{attrs:{id:"_3-2-1-增加-applicationmaster-资源比例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-1-增加-applicationmaster-资源比例"}},[t._v("#")]),t._v(" 3.2.1 增加 ApplicationMaster 资源比例")]),t._v(" "),s("p",[t._v("​\t容量调度器对每个资源队列中同时运行的Application Master占用的资源进行了限制，该限制通过\tyarn.scheduler.capacity.maximum-am-resource-percent参数实现，其默认值是0.1，表示每个资源队列上Application Master最多可使用的资源为该队列总资源的10%，目的是防止大部分资源都被Application Master占用，而导致Map/Reduce Task无法执行。\n​\t生产环境该参数可使用默认值。但学习环境，集群资源总数很少，如果只分配10%的资源给Application Master，则可能出现，同一时刻只能运行一个Job的情况，因为一个Application Master使用的资源就可能已经达到10%的上限了。故此处可将该值适当调大。")]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("vim")]),t._v(" /opt/module/hadoop-3.1.3/etc/hadoop/capacity-scheduler.xml\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("div",{staticClass:"language-xml line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.scheduler.capacity.maximum-am-resource-percent"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("0.8"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("xsync capacity-scheduler.xml\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h3",{attrs:{id:"_3-3-数仓开发环境"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-数仓开发环境"}},[t._v("#")]),t._v(" 3.3 数仓开发环境")]),t._v(" "),s("blockquote",[s("p",[t._v("数仓开发工具可选用DBeaver或者DataGrip。两者都需要用到JDBC协议连接到Hive，故需要启动HiveServer2")])]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("@hadoop102 hive"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hiveserver2\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h3",{attrs:{id:"_3-4-数据准备"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-数据准备"}},[t._v("#")]),t._v(" 3.4 数据准备")]),t._v(" "),s("p",[t._v("用户行为日志：")]),t._v(" "),s("p",[t._v("用户行为日志，一般是没有历史数据的，所以只需要准备一天的数据。")]),t._v(" "),s("ol",[s("li",[t._v("启动日志采集通道，包括Flume、Kafka等")]),t._v(" "),s("li",[t._v("修改两个日志服务器（hadoop102、hadoop103）中的/opt/module/applog/application.yml配置文件，将mock.date参数改为2022-07-14。")]),t._v(" "),s("li",[t._v("执行日志生成脚本lg.sh。")]),t._v(" "),s("li",[t._v("查看 HDFS")])]),t._v(" "),s("p",[t._v("业务数据：")]),t._v(" "),s("p",[t._v("业务数据一般存在历史数据，此处需准备2022-07-10至2022-07-14的数据。")]),t._v(" "),s("ol",[s("li",[t._v("修改hadoop102节点上的/opt/module/db_log/application.properties文件，将mock.date、mock.clear，mock.clear.user三个参数调整")]),t._v(" "),s("li",[t._v("执行模拟生成业务数据的命令，生成第一天2022-07-10的历史数据")])]),t._v(" "),s("div",{staticClass:"language-shell line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("java -jar gmall2020-mock-db-2021-01-22.jar\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("依次执行至 14 号")]),t._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[t._v("执行mysql_to_hdfs_init.sh脚本，将模拟生成的业务数据同步到HDFS")]),t._v(" "),s("li",[t._v("查看 HDFS")])])])}),[],!1,null,null,null);a.default=n.exports}}]);