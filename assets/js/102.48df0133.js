(window.webpackJsonp=window.webpackJsonp||[]).push([[102],{623:function(s,a,t){"use strict";t.r(a);var n=t(4),r=Object(n.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"_1-spark面试题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-spark面试题"}},[s._v("#")]),s._v(" 1. Spark面试题")]),s._v(" "),t("h3",{attrs:{id:"_1-spark负责什么事情-为什么要设计自己的调度器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-spark负责什么事情-为什么要设计自己的调度器"}},[s._v("#")]),s._v(" 1.Spark负责什么事情?为什么要设计自己的调度器?")]),s._v(" "),t("p",[s._v("Spark是基于内存的快速、通用、可扩展的大数据分析计算引擎")]),s._v(" "),t("p",[s._v("Hadoop的Yarn框架比Spark框架诞生的晚，所以Spark自己也设计了一套资源调度框架。")]),s._v(" "),t("h3",{attrs:{id:"_2-spark中核心集群角色哪些-分别说明其主要功能。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-spark中核心集群角色哪些-分别说明其主要功能。"}},[s._v("#")]),s._v(" 2.Spark中核心集群角色哪些？分别说明其主要功能。")]),s._v(" "),t("h4",{attrs:{id:"_2-1-master-和-worker-集群资源管理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-master-和-worker-集群资源管理"}},[s._v("#")]),s._v(" 2.1 Master 和 Worker 集群资源管理")]),s._v(" "),t("p",[s._v("Master：")]),s._v(" "),t("p",[s._v("Spark 特有资源调度系统的 Leader。掌管着整个集群的资源信息，"),t("strong",[s._v("类似于 Yarn 框架中的 ResourceManager")])]),s._v(" "),t("p",[s._v("Worker：")]),s._v(" "),t("p",[s._v("Spark 特有资源调度系统的 Slave，有多个。每个 Slave 掌管着所在节点的资源信息，"),t("strong",[s._v("类似于 Yarn 框架中的 NodeManager")])]),s._v(" "),t("p",[s._v("​\tMaster和Worker是Spark的守护进程、集群资源管理者，即Spark在特定模式(Standalone)下正常运行必须要有的后台常驻进程。")]),s._v(" "),t("h4",{attrs:{id:"_2-2-driver-和-executor-任务的管理者"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-driver-和-executor-任务的管理者"}},[s._v("#")]),s._v(" 2.2 Driver 和 Executor 任务的管理者")]),s._v(" "),t("p",[s._v("Driver：")]),s._v(" "),t("p",[s._v("Spark Shell 中预加载的一个叫做 sc 的 SparkContext对象")]),s._v(" "),t("p",[s._v("1）把用户程序转为作业（Job）")]),s._v(" "),t("p",[s._v("2）跟踪 Executor 的任务运行状况")]),s._v(" "),t("p",[s._v("3）为执行器节点调度任务")]),s._v(" "),t("p",[s._v("4）UI 展示应用运行状况")]),s._v(" "),t("p",[s._v("Executor：")]),s._v(" "),t("p",[s._v("负责执行 Spark 的具体任务")]),s._v(" "),t("p",[s._v("Driver和Executor是临时程序，当有具体任务提交到Spark集群才会开启的程序。")]),s._v(" "),t("h3",{attrs:{id:"_3-如何提交一个spark任务-主要参数有哪些"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-如何提交一个spark任务-主要参数有哪些"}},[s._v("#")]),s._v(" 3.如何提交一个Spark任务?主要参数有哪些?")]),s._v(" "),t("p",[s._v("提交Spark任务的主要步骤包括：")]),s._v(" "),t("ol",[t("li",[s._v("构建SparkContext")]),s._v(" "),t("li",[s._v("准备Spark应用程序和任务所需的数据")]),s._v(" "),t("li",[s._v("调用相应的API")]),s._v(" "),t("li",[s._v("处理任务结果。")])]),s._v(" "),t("p",[s._v("提交任务参数：")]),s._v(" "),t("ol",[t("li",[s._v("作业名称")]),s._v(" "),t("li",[s._v("应用程序名称")]),s._v(" "),t("li",[s._v("资源要求，包括CPU、内存、磁盘空间等")]),s._v(" "),t("li",[s._v("作业类型")]),s._v(" "),t("li",[s._v("作业参数")]),s._v(" "),t("li",[s._v("作业环境变量")]),s._v(" "),t("li",[s._v("提交者的ID")]),s._v(" "),t("li",[s._v("提交时间")])]),s._v(" "),t("h3",{attrs:{id:"_4-简述你所理解的不同运行模式之间的区别。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-简述你所理解的不同运行模式之间的区别。"}},[s._v("#")]),s._v(" 4.简述你所理解的不同运行模式之间的区别。")]),s._v(" "),t("p",[s._v("Local：")]),s._v(" "),t("p",[s._v("Local 模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。")]),s._v(" "),t("p",[s._v("Standalone：")]),s._v(" "),t("p",[s._v("Standalone模式是Spark自带的资源调度引擎，构建一个由Master + Worker构成的Spark集群，Spark运行在集群中。")]),s._v(" "),t("p",[s._v("Yarn：")]),s._v(" "),t("p",[s._v("Spark有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。")]),s._v(" "),t("p",[s._v("yarn-client：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出。")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("bin/spark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--master "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yarn")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--deploy-mode client "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n./examples/jars/spark-examples_2.12-3.0.0.jar "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("yarn-cluster：Driver程序运行在由ResourceManager启动的APPMaster，适用于生产环境。")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("bin/spark-submit "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--class org.apache.spark.examples.SparkPi "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--master "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yarn")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n--deploy-mode cluster "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n./examples/jars/spark-examples_2.12-3.0.0.jar "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("h3",{attrs:{id:"_5-spark的端口号总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-spark的端口号总结"}},[s._v("#")]),s._v(" 5.Spark的端口号总结")]),s._v(" "),t("p",[s._v("1）Spark查看当前Spark-shell运行任务情况端口号：4040")]),s._v(" "),t("p",[s._v("2）Spark Master内部通信服务端口号：7077\t（类比于yarn的8032(RM和NM的内部通信)端口）")]),s._v(" "),t("p",[s._v("3）Spark Standalone模式Master Web端口号：8080（类比于Hadoop YARN任务运行情况查看端口号：8088）")]),s._v(" "),t("p",[s._v("4）Spark历史服务器端口号：18080（类比于Hadoop历史服务器端口号：19888）")]),s._v(" "),t("h3",{attrs:{id:"_6-什么是rdd"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-什么是rdd"}},[s._v("#")]),s._v(" 6.什么是RDD?")]),s._v(" "),t("p",[s._v("RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象。")]),s._v(" "),t("p",[s._v("代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。")]),s._v(" "),t("h3",{attrs:{id:"_7-wordcount代码中算子的具体工作流程-各个算子执行位置-可以画图说明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-wordcount代码中算子的具体工作流程-各个算子执行位置-可以画图说明"}},[s._v("#")]),s._v(" 7.wordCount代码中算子的具体工作流程(各个算子执行位置)?(可以画图说明)")]),s._v(" "),t("p",[s._v("（1）创建Spark编程入口SparkContext")]),s._v(" "),t("p",[s._v("（2）读取文件，将文件中的内容保存到RDD")]),s._v(" "),t("p",[s._v("（3）将工作分配到各主机节点")]),s._v(" "),t("p",[s._v("（4）各主机节点对自己分到的任务进行操作，首先进行单词划分，按空格分隔，生成flatMappedRDD")]),s._v(" "),t("p",[s._v("（5）然后将各单词生成Map键值对，输出(Word,1)")]),s._v(" "),t("p",[s._v("（6）然后将不同节点上的单词进行局部统计求和，生成局部WordCount的MapPatitionRDD")]),s._v(" "),t("p",[s._v("（7）接着对各节点间进行Shuffle，将各节点间的单词进行词频统计，生成最后的MapPatitionRDD")]),s._v(" "),t("p",[s._v("（8）最后输出结果")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fspark_wc.png",alt:""}})]),s._v(" "),t("h3",{attrs:{id:"_8-简述rdd的五大特性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-简述rdd的五大特性"}},[s._v("#")]),s._v(" 8.简述RDD的五大特性?")]),s._v(" "),t("ol",[t("li",[s._v("RDD由一到多个partition构成，有多少个partition就对应有多少个task。")]),s._v(" "),t("li",[s._v("对RDD做计算，相当于对RDD的每个split或partition做计算。")]),s._v(" "),t("li",[s._v("RDD之间有依赖关系，可溯源。")]),s._v(" "),t("li",[s._v("如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，比如可以按key的hash值分区。")]),s._v(" "),t("li",[s._v("每个split一般有多个副本，计算时优先使用本地的副本进行计算，减少数据的IO和网络传输，提高性能。")])]),s._v(" "),t("h3",{attrs:{id:"_9-rdd有几种创建方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-rdd有几种创建方式"}},[s._v("#")]),s._v(" 9.RDD有几种创建方式?")]),s._v(" "),t("ol",[t("li",[s._v("使用程序中的集合创建RDD "),t("code",[s._v("sc.parallelize(Array(1, 2, 3, 4, 5, 6, 7, 8))")])]),s._v(" "),t("li",[s._v("使用本地文件创建RDD "),t("code",[s._v('sc.textFile("input")')])]),s._v(" "),t("li",[s._v("使用HDFS文件创建RDD "),t("code",[s._v('sc.textFile("hdfs://input")')])]),s._v(" "),t("li",[s._v("使用消息源（例如 Kafka）创建RDD")])]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[s._v("    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建SparkConf")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" sparkConf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" SparkConf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" SparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setAppName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sparkstreaming"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setMaster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"local[*]"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 创建StreamingContext")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" ssc "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" StreamingContext"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Seconds"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 定义 Kafka 参数：kafka集群地址、消费者组名称、key序列化、value序列化")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" kafkaPara"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Object"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Object"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      ConsumerConfig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BOOTSTRAP_SERVERS_CONFIG "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hadoop102:9092,hadoop103:9092,hadoop104:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      ConsumerConfig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("GROUP_ID_CONFIG "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"saberlindGroup"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      ConsumerConfig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("KEY_DESERIALIZER_CLASS_CONFIG "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"org.apache.kafka.common.serialization.StringDeserializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      ConsumerConfig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("VALUE_DESERIALIZER_CLASS_CONFIG "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("->")]),s._v(" classOf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("StringDeserializer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 读取 Kafka 数据创建 DStream")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" kafkaDStream"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" InputDStream"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("ConsumerRecord"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" KafkaUtils"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createDirectStream"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      ssc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n      LocationStrategies"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PreferConsistent"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 优先位置")]),s._v("\n      ConsumerStrategies"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Subscribe"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Set"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"testTopic"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kafkaPara"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 消费策略: (订阅多个主题，配置参数)")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br")])]),t("h3",{attrs:{id:"_10-集合创建rdd-默认分区数和设置分区的算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-集合创建rdd-默认分区数和设置分区的算法"}},[s._v("#")]),s._v(" 10.集合创建RDD,默认分区数和设置分区的算法?")]),s._v(" "),t("p",[s._v("从集合创建rdd,如果不手动写分区数量的情况下,默认分区数跟本地模式的cpu核数有关")]),s._v(" "),t("p",[s._v("​\tlocal : 1个")]),s._v(" "),t("p",[s._v("​\tlocal[*] : 笔记本所有核心数")]),s._v(" "),t("p",[s._v("​\tlocal[K]: K个")]),s._v(" "),t("p",[s._v("规则：")]),s._v(" "),t("p",[s._v("分区的开始位置 = (分区号 * 数据总长度)/分区总数")]),s._v(" "),t("p",[s._v("分区的结束位置 =((分区号 + 1)* 数据总长度)/分区总数")]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("object")]),s._v(" fenqu "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" main"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Unit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" SparkConf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" SparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setMaster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"local[*]"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setAppName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SparkCoreTest"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" sc"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" SparkContext "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" SparkContext"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//1）4个数据，设置4个分区，输出：0分区->1，1分区->2，2分区->3，3分区->4")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" rdd"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" RDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("makeRDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//2）4个数据，设置3个分区，输出：0分区->1，1分区->2，2分区->3,4")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//val rdd: RDD[Int] = sc.makeRDD(Array(1, 2, 3, 4), 3)")]),s._v("\n \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//3）5个数据，设置3个分区，输出：0分区->9，1分区->2、3，2分区->4、5")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//val rdd: RDD[Int] = sc.makeRDD(Array(9, 2, 3, 4, 5), 3)")]),s._v("\n \n    rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("saveAsTextFile"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"output"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n    sc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("stop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br")])]),t("p",[t("img",{attrs:{src:"https://lskyimage-1306894954.cos.ap-nanjing.myqcloud.com/spark%2Fsummary%2Fparbyarray.png",alt:""}})]),s._v(" "),t("p",[s._v("分区1：1个，分区2：2个，分区3：2个")]),s._v(" "),t("h3",{attrs:{id:"_11-读取文件创建rdd-默认分区数和设置分区数的算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-读取文件创建rdd-默认分区数和设置分区数的算法"}},[s._v("#")]),s._v(" 11.读取文件创建RDD,默认分区数和设置分区数的算法")]),s._v(" "),t("p",[s._v("默认：")]),s._v(" "),t("p",[s._v("​\t默认取值为当前核数和2的最小值,一般为2")]),s._v(" "),t("p",[s._v("指定：")]),s._v(" "),t("p",[s._v("1).分区数量的计算方式:")]),s._v(" "),t("p",[s._v("​\ttotalSize = 10")]),s._v(" "),t("p",[s._v("​\tgoalSize = 10 / 3 = 3(byte) 表示每个分区存储3字节的数据")]),s._v(" "),t("p",[s._v("​\t分区数= totalSize/ goalSize = 10 /3 => 3,3,4")]),s._v(" "),t("p",[s._v("​\t4子节大于3子节的1.1倍,符合hadoop切片1.1倍的策略,因此会多创建一个分区,即一共有4个分区  3,3,3,1")]),s._v(" "),t("p",[s._v("2). Spark读取文件，采用的是hadoop的方式读取，所以一行一行读取，跟字节数没有关系")]),s._v(" "),t("p",[s._v("3).数据读取位置计算是以偏移量为单位来进行计算的。")]),s._v(" "),t("p",[s._v("4).数据分区的偏移量范围的计算")]),s._v(" "),t("p",[s._v("​\t0 => [0,3]         1     012        0 => 1,2")]),s._v(" "),t("p",[s._v("​\t1 => [3,6]         2     345        1 => 3")]),s._v(" "),t("p",[s._v("​\t2 => [6,9]         3     678        2 => 4")]),s._v(" "),t("p",[s._v("​\t3 => [9,9]         4      9           3 => 无")]),s._v(" "),t("h3",{attrs:{id:"_12-使用list-1-2-3-4-5-创建rdd如何控制分区个数-如果是2个分区-怎么分配"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12-使用list-1-2-3-4-5-创建rdd如何控制分区个数-如果是2个分区-怎么分配"}},[s._v("#")]),s._v(" 12.使用List(1,2,3,4,5)创建rdd如何控制分区个数,如果是2个分区,怎么分配?")]),s._v(" "),t("p",[s._v("start = (分区数 * 数据长度) / 分区数")]),s._v(" "),t("p",[s._v("end = ((分区数 + 1) * 数据长度) / 分区数")]),s._v(" "),t("p",[s._v("分区1：1，2")]),s._v(" "),t("p",[s._v("分区2：3，4，5")]),s._v(" "),t("h3",{attrs:{id:"_13-创建一个rdd-使其一个分区的数据转变为一个string"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_13-创建一个rdd-使其一个分区的数据转变为一个string"}},[s._v("#")]),s._v(" 13.创建一个RDD，使其一个分区的数据转变为一个String")]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" SparkConf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" SparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setAppName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getClass"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setMaster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"local[*]"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" sc "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" SparkContext"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" rdd"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" RDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("makeRDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"a"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"b"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"c"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"d"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将同一分区数据转为数组")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" glomRDD"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" RDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("glom"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    glomRDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("foreach"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("println"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" resRDD"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" RDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" glomRDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("map"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n      arr "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        arr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mkString"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    resRDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("foreach"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("println"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    sc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("stop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("h3",{attrs:{id:"_14-reducebykey跟groupbykey之间的区别。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_14-reducebykey跟groupbykey之间的区别。"}},[s._v("#")]),s._v(" 14.reduceByKey跟groupByKey之间的区别。")]),s._v(" "),t("p",[s._v("reduceByKey：按照key进行聚合，在shuffle之前，会对分区内数据进行预聚合操作，返回的结果是k-v类型的RDD（RDD[K,V]）。")]),s._v(" "),t("p",[s._v("groupByKey：按照key进行分组，直接进行shuffle。返回的结果是k-迭代器类型的RDD（RDD[K,Iterable[V]]）。")]),s._v(" "),t("p",[s._v("在不影响业务逻辑的情况下，优先使用reduceByKey。"),t("strong",[s._v("求和操作不影响业务逻辑，求平均值的操作影响业务逻辑。")])]),s._v(" "),t("h3",{attrs:{id:"_15-reducebykey跟aggregatebykey、foldbykey之间的区别与联系。"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_15-reducebykey跟aggregatebykey、foldbykey之间的区别与联系。"}},[s._v("#")]),s._v(" 15.reduceByKey跟aggregateByKey、foldByKey之间的区别与联系。")]),s._v(" "),t("p",[t("strong",[s._v("联系：")])]),s._v(" "),t("ul",[t("li",[s._v("都是按照key做聚合操作，都会在shuffle之前对数据做预聚合操作。")])]),s._v(" "),t("p",[t("strong",[s._v("区别：")])]),s._v(" "),t("ul",[t("li",[s._v("reduceByKey：没有初始值，分区内和分区间的计算规则一致。")]),s._v(" "),t("li",[s._v("aggregateByKey：有初始值，初始值参与分区内和分区间的计算，分区内和分区间规则可以不一致。")]),s._v(" "),t("li",[s._v("foldByKey：有初始值，初始值参与分区内的计算，分区内和分区间计算规则相同的 aggregateByKey。")])]),s._v(" "),t("h3",{attrs:{id:"_16-rdd中随便写出15个转换算子-8个行动算子-并简述其功能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_16-rdd中随便写出15个转换算子-8个行动算子-并简述其功能"}},[s._v("#")]),s._v(" 16.rdd中随便写出15个转换算子,8个行动算子,并简述其功能")]),s._v(" "),t("h3",{attrs:{id:"_17-spark中rdd的序列化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_17-spark中rdd的序列化"}},[s._v("#")]),s._v(" 17.spark中rdd的序列化")]),s._v(" "),t("p",[s._v("为什么要序列化：")]),s._v(" "),t("ul",[t("li",[s._v("从计算的角度：算子以外的代码都是 Driver 端执行，算子里面的代码都是 Executor 端执行，因此算子内经常会用到算子外的数据，因此形成"),t("strong",[s._v("闭包的效果")]),s._v("。（Scala自带闭包检查，代码未运行就报错了）")]),s._v(" "),t("li",[s._v("在调用算子外的数据时，数据需要在Driver和Executor中间通过网络进行传输，因此需要序列化")])]),s._v(" "),t("p",[s._v("怎么序列化：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("    val conf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SparkConf")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("SparkConf")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setAppName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SerDemo"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("setMaster")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"local[*]"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 替换默认的序列化机制")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.serializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"org.apache.spark.serializer.KryoSerializer"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//.registerKryoClasses(Array(classOf[KryoSerializer]))")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 注册需要使用kryo序列化的自定义类")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("registerKryoClasses")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Array")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("classOf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Searche")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Searche")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("val query"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Serializable")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n  def "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("isMatch")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("contains")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n  def "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getMatchedRDD1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("rdd"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" RDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("filter")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("isMatch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n  def "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getMatchedRDD2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("rdd"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" RDD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    rdd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("filter")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("_"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("contains")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("query"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("p",[s._v("序列化调优：")]),s._v(" "),t("ul",[t("li",[s._v("使用Kryo可以节省10倍空间以及更少cpu, 强烈建议使用kryo")]),s._v(" "),t("li",[s._v("Kryo在序列化时缓存空间默认大小是2MB, 可以根据业务模型调整大小，设置spark.kryoserilizer.buffer为10MB。")]),s._v(" "),t("li",[s._v("在Kryo注册时强烈建议写完整的包名和类名，否则每次序列化都会保存一份整个包名和类名的完整信息，会造成不必要的内存空间浪费。")])]),s._v(" "),t("h3",{attrs:{id:"_18-什么叫rdd的血缘"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_18-什么叫rdd的血缘"}},[s._v("#")]),s._v(" 18.什么叫rdd的血缘?")]),s._v(" "),t("ul",[t("li",[s._v("RDD通过转换算子生成一系列的的RDD，Spark会记录每一个RDD之间的依赖关系，此关系称为血缘，可以通过"),t("code",[s._v("toDebuString")]),s._v("算子查看RDD之间的血缘关系。")]),s._v(" "),t("li",[s._v("Spark会跟据RDD之间的血缘关系形成 "),t("strong",[s._v("DAG有向无环图")]),s._v(" ，根据此有向无环图，Spark "),t("strong",[s._v("可以高效的处理容错和数据的恢复工作")])])]),s._v(" "),t("h3",{attrs:{id:"_19-什么叫rdd的依赖关系-依赖关系有哪些-什么区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_19-什么叫rdd的依赖关系-依赖关系有哪些-什么区别"}},[s._v("#")]),s._v(" 19.什么叫rdd的依赖关系? 依赖关系有哪些? 什么区别?")]),s._v(" "),t("p",[s._v("RDD通过转换算子生成一系列的的RDD，上一级RDD即为当前RDD的父RDD")]),s._v(" "),t("p",[s._v("依赖关系：")]),s._v(" "),t("ul",[t("li",[s._v("窄依赖：(独生子女)\n"),t("ul",[t("li",[s._v("窄依赖指的是每一个父RDD 的Partition 最多被子RDD 的一个Partition 使用")])])]),s._v(" "),t("li",[s._v("宽依赖：(超生)\n"),t("ul",[t("li",[s._v("宽依赖指的是多个子RDD 的Partition 会依赖同一个父RDD 的Partition")])])])]),s._v(" "),t("p",[t("strong",[s._v("shuffle 不一定产生宽依赖,但是宽依赖一定是由 shuffle 产生的。")])]),s._v(" "),t("blockquote",[t("p",[s._v("​\tshuffle过程不一定会产生宽依赖，形如groupByKey，reduceByKey，foldByKey，aggregateByKey，combineByKey等算子有可能不会产生宽依赖，也许相同的key在此前的RDD中已经放到相同的分区了，故不用shuffle也已经达到了聚合的目标。")])]),s._v(" "),t("h3",{attrs:{id:"_20-什么情况下rdd会进行shuffle"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_20-什么情况下rdd会进行shuffle"}},[s._v("#")]),s._v(" 20.什么情况下rdd会进行shuffle?")]),s._v(" "),t("p",[s._v("​\t首先，RDD的计算是分布式的，在需要对发布在不同节点的所有数据进行聚合计算时，需要进行Shuffle将数据落磁盘，将数据根据不同分区进行聚合计算，最终重新将数据根据分区发送到不同的节点上。")]),s._v(" "),t("h3",{attrs:{id:"_21-创建一个rdd-自定义一种分区规则并实现。spark中是否可以按照value分区"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_21-创建一个rdd-自定义一种分区规则并实现。spark中是否可以按照value分区"}},[s._v("#")]),s._v(" 21.创建一个RDD，自定义一种分区规则并实现。Spark中是否可以按照Value分区？")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 自定义分区")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyPartitioner")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Partitioner")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 设置的分区数")]),s._v("\n    override def numPartitions"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" num\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 具体分区逻辑")]),s._v("\n    override def "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Any")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("isInstanceOf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n            val keyInt"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("asInstanceOf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("keyInt "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v("\n                "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br")])]),t("p",[t("strong",[s._v("按照Value分区：")])]),s._v(" "),t("ul",[t("li",[s._v("RDD通过map映射，把value和key的位置调换。")])]),s._v(" "),t("h3",{attrs:{id:"_22-spark读取hdfs文件默认的切片机制。-1-1倍原则"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_22-spark读取hdfs文件默认的切片机制。-1-1倍原则"}},[s._v("#")]),s._v(" 22.Spark读取HDFS文件默认的切片机制。(1.1倍原则)")]),s._v(" "),t("ul",[t("li",[s._v("创建RDD时，会将文件路径和最小分区数minPartitions传递到HadoopRDD中。")]),s._v(" "),t("li",[s._v("调用FileInputFormat中的getSplits方法计算切片信息。")]),s._v(" "),t("li",[s._v("首先计算目标切片大小goalSize：目标切片大小 = 文件大小 / 最小分区数 。")]),s._v(" "),t("li",[s._v("再计算切片最小值minSize：max(FileInputFormat.SPLIT_MINSIZE,minSplitSize)，最小值为1。")]),s._v(" "),t("li",[s._v("接着计算splitSize = Math.max(minSize, Math.min(goalSize, blockSize)),所以SplitSize一般为goalSize和blockSize两者的最小值。")]),s._v(" "),t("li",[s._v("如果剩余待处理文件大小 / splitSize > 1.1，那么就切一片。")])]),s._v(" "),t("h3",{attrs:{id:"_23-说说spark中累加器和广播变量的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_23-说说spark中累加器和广播变量的区别"}},[s._v("#")]),s._v(" 23.说说spark中累加器和广播变量的区别")]),s._v(" "),t("p",[s._v("**累加器：**分布式共享只写变量")]),s._v(" "),t("p",[s._v("**广播变量：**分布式共享只读变量")]),s._v(" "),t("h3",{attrs:{id:"_24-sparksql底层有什么编程抽象"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_24-sparksql底层有什么编程抽象"}},[s._v("#")]),s._v(" 24.SparkSQL底层有什么编程抽象?")]),s._v(" "),t("p",[s._v("datafarme (可以看做特殊类型的dataset  row类型)有列名 没有列的数据类型")]),s._v(" "),t("p",[s._v("dataset      有列名 同时有数据类型")]),s._v(" "),t("h3",{attrs:{id:"_25-hive-on-spark-和-spark-on-hive-区别-我们学的sparksql是什么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_25-hive-on-spark-和-spark-on-hive-区别-我们学的sparksql是什么"}},[s._v("#")]),s._v(" 25.hive on spark 和 spark on hive 区别? 我们学的SparkSQL是什么?")]),s._v(" "),t("p",[s._v("hive on spark本体使用的是hive,只需要修改hive中的运算引擎即可")]),s._v(" "),t("p",[s._v("spark on hive 中spark是本体  只需要使用到hive作为元数据的管理 直接使用spark进行编写")]),s._v(" "),t("p",[s._v("SparkSQL  属于spark on hive")]),s._v(" "),t("h3",{attrs:{id:"_26-df、ds、rdd三者直接的区别和联系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_26-df、ds、rdd三者直接的区别和联系"}},[s._v("#")]),s._v(" 26.DF、DS、RDD三者直接的区别和联系?")]),s._v(" "),t("blockquote",[t("p",[s._v("在实际开发的时候，很少会把序列转换成DataSet，更多是通过RDD和DataFrame转换来得到DataSet")])]),s._v(" "),t("p",[t("strong",[s._v("联系：")])]),s._v(" "),t("p",[s._v("1）都是spark中得弹性分布式数据集，轻量级")]),s._v(" "),t("p",[s._v("2）都是惰性机制，延迟计算")]),s._v(" "),t("p",[s._v("3）根据内存情况，自动缓存，加快计算速度")]),s._v(" "),t("p",[s._v("4）都有partition分区概念")]),s._v(" "),t("p",[s._v("5）众多相同得算子：map flatmap 等等")]),s._v(" "),t("p",[t("strong",[s._v("区别：")])]),s._v(" "),t("ul",[t("li",[t("p",[s._v("RDD")]),s._v(" "),t("ul",[t("li",[s._v("优点: 编译时类型安全 编译时就能检查出类型错误 面向对象的编程风格 直接通过类名点的方式来操作数据")]),s._v(" "),t("li",[s._v("缺点: 序列化和反序列化的性能开销 无论是集群间的通信, 还是IO操作都需要对对象的结构和数据进行序列化和反序列化 GC的性能开销，频繁的创建和销毁对象, 势必会增加GC")])])]),s._v(" "),t("li",[t("p",[s._v("DataFrame（DataFrame引入了schema和off-heap）")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("schema : RDD每一行的数据, 结构都是一样的.")]),s._v(" "),t("p",[s._v("这个结构就存储在schema中. Spark通过schame就能够读懂数据, 因此在通信和IO时就只需要序列化和反序列化数据，而结构的部分就可以省略了。")])]),s._v(" "),t("li",[t("p",[s._v("off-heap : 意味着JVM堆以外的内存")]),s._v(" "),t("p",[s._v("这些内存直接受操作系统管理（而不是JVM）。Spark能够以二进制的形式序列化数据(不包括结构)到off-heap中，当要操作数据时，就直接操作off-heap内存。由于Spark理解schema, 所以知道该如何操作 其API不是面向对象的")]),s._v(" "),t("p",[s._v("这里我们就可以看出spark为了解决RDD的问题进行的取舍")])])])]),s._v(" "),t("li",[t("p",[s._v("RDD是分布式的Java对象的集合。DataFrame是分布式的Row对象的集合")])]),s._v(" "),t("li",[t("p",[s._v("DataFrame除了提供了比RDD更丰富的算子以外，更重要的特点是提升执行效率、减少数据读取以及执行计划的优化，比如filter下推、裁剪等")])]),s._v(" "),t("li",[t("p",[s._v("Dataset和DataFrame拥有完全相同的成员函数，区别只是每一行的数据类型不同")])]),s._v(" "),t("li",[t("p",[s._v("DataFrame也可以叫Dataset[Row],每一行的类型是Row，不解析，每一行究竟有哪些字段，各个字段又是什么类型都无从得知，只能用getAS方法或者共性中的第七条提到的模式匹配拿出特定字段")])]),s._v(" "),t("li",[t("p",[s._v("而Dataset中，每一行是什么类型是不一定的，在自定义了case class之后可以很自由的获得每一行的信息")])])]),s._v(" "),t("h3",{attrs:{id:"_27-sparksql中有两种什么语法-简述两种语法的区别和练习"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_27-sparksql中有两种什么语法-简述两种语法的区别和练习"}},[s._v("#")]),s._v(" 27.SparkSQL中有两种什么语法? 简述两种语法的区别和练习")]),s._v(" "),t("ol",[t("li",[s._v("SQL风格语法")])]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[s._v(" # 临时视图\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"user"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" sqlDF "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SELECT * FROM user"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n # 新的 Session 无法获取临时视图的数据\n spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("newSession"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SELECT avg(age) from user "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n# 全局视图\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceGlobalTempView "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"user2"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nspark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("newSession"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SELECT * FROM global_temp.user2"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br")])]),t("ol",{attrs:{start:"2"}},[t("li",[s._v("DSL风格语法")])]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[s._v("# 只查看某一列的数据\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token symbol"}},[s._v("'name")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n# 条件查询\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("where"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age>18"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n# 全查询\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"*"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n\n# 运算查询：涉及到运算的时候，每列都必须使用$，或者采用单引号表达式：单引号"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("字段名\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name, '")]),s._v("age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name, '")]),s._v("age "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" as "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"newage"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n # 过滤\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("filter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age>19"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n # 分组\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("groupBy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n # 平均值\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("agg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("avg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n # 求和\n df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("agg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"age"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br")])]),t("h3",{attrs:{id:"_28-sparksql中自定义udaf实现求平均年龄"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_28-sparksql中自定义udaf实现求平均年龄"}},[s._v("#")]),s._v(" 28.SparkSQL中自定义UDAF实现求平均年龄")]),s._v(" "),t("div",{staticClass:"language-scala line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-scala"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("object")]),s._v(" SparkSQL06_UDAF "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" main"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("args"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Unit")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 1 创建上下文环境配置对象")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" conf"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" SparkConf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" SparkConf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setMaster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"local[*]"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("setAppName"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"SparkSQLTest"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 2 创建SparkSession对象")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" spark"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" SparkSession "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SparkSession"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("builder"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("config"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("conf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getOrCreate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 3 读取数据")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" df"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("json"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"input/user.json"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 4 创建DataFrame临时视图")]),s._v("\n        df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"user"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 5 注册UDAF")]),s._v("\n        spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("udf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("register"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"myAvg"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" functions"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("udaf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" MyAvgUDAF"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 6 调用自定义UDAF函数")]),s._v("\n        spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"select myAvg(age) from user"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 7 释放资源")]),s._v("\n        spark"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("stop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//输入数据类型")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" sum"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" count"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/**\n * 1,20岁； 2,19岁； 3,18岁\n * IN:聚合函数的输入类型：Long\n * Buff : sum = (18+19+20)  count = 1+1+1\n * OUT:聚合函数的输出类型：Double  (18+19+20) / 3\n */")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" MyAvgUDAF "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("extends")]),s._v(" Aggregator"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 初始化缓冲区")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" zero"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0L")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0L")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 将输入的年龄和缓冲区的数据进行聚合")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" reduce"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("buff"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" age"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" age\n        buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n        buff\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 多个缓冲区数据合并")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" merge"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("buff1"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" buff2"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        buff1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" buff1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" buff2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sum\n        buff1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" buff1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" buff2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count\n        buff1\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 完成聚合操作，获取最终结果")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" finish"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("buff"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Double")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sum"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toDouble "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// SparkSQL对传递的对象的序列化操作（编码）")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 自定义类型就是product   自带类型根据类型选择")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" bufferEncoder"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Encoder"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("Buff"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Encoders"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("product\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("override")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" outputEncoder"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Encoder"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Encoders"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scalaDouble\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br")])]),t("h3",{attrs:{id:"_29-rdd实现join的多种方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_29-rdd实现join的多种方式"}},[s._v("#")]),s._v(" 29. RDD实现Join的多种方式")]),s._v(" "),t("ul",[t("li",[s._v("rdd1.join(rdd2)：将相同的key对应的value关联到一起。如果key只是某个RDD存在，那么不返回。")]),s._v(" "),t("li",[s._v("rdd1.leftOuterJoin(rdd2)：返回rdd1中的全部key-value和关联后的key-value。")]),s._v(" "),t("li",[s._v("rdd1.rightOuterJoin(rdd2)：返回rdd2中的全部key-value和关联后的key-value。")]),s._v(" "),t("li",[s._v("rdd1.cogroup(rdd2)：每个rdd中先关联自己的key形成集合，然后再合并")])]),s._v(" "),t("h3",{attrs:{id:"_30-aggregatebykey与aggregate之间的区别与联系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_30-aggregatebykey与aggregate之间的区别与联系"}},[s._v("#")]),s._v(" 30. aggregateByKey与aggregate之间的区别与联系")]),s._v(" "),t("p",[t("strong",[s._v("联系：")])]),s._v(" "),t("ul",[t("li",[s._v("两者都是对分区内和分区间的元素做聚合操作，而且都有初始值。")])]),s._v(" "),t("p",[t("strong",[s._v("区别：")])]),s._v(" "),t("ul",[t("li",[s._v("aggregateByKey是转换算子，是对k-v类型的RDD进行操作，初始值参与分区内和分区间的计算，初始值会和RDD中每一个元素进行迭代并运算。")]),s._v(" "),t("li",[s._v("aggregate是行动算子，初始值参与分区内和分区间的计算，分区内计算时，初始值和RDD每个分区中的一个元素按照指定规则运算，分区间计算时，初始值只会参与一次运算。")])]),s._v(" "),t("h3",{attrs:{id:"_31-rdd的cache和checkpoint的区别和联系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_31-rdd的cache和checkpoint的区别和联系"}},[s._v("#")]),s._v(" 31. RDD的cache和checkPoint的区别和联系")]),s._v(" "),t("p",[t("strong",[s._v("联系：")])]),s._v(" "),t("ul",[t("li",[s._v("cache和checkPoint都是对RDD中的数据做缓存，后面计算逻辑相同的RDD，可以直接从缓存中取数据，而不用重新进行计算。")]),s._v(" "),t("li",[s._v("只有触发action算子时，才会真正的缓存。")])]),s._v(" "),t("p",[t("strong",[s._v("区别：")])]),s._v(" "),t("ul",[t("li",[s._v("cache不会切断RDD的血缘关系，缓存默认存储在内存中，可以设置存储在本地磁盘上，但是随着程序运行结束，cache缓存的数据都会丢失。")]),s._v(" "),t("li",[s._v("checkpoint检查点会切断RDD的血缘关系，可以把数据存储在HDFS等高可用、可靠性高的存储系统中。")]),s._v(" "),t("li",[s._v("为了确保数据的准确性，checkpoint检查点在第一次使用时，会根据RDD的血缘关系，从头到尾执行一遍。")]),s._v(" "),t("li",[s._v("一般checkpoint和cache搭配来使用。")])]),s._v(" "),t("h3",{attrs:{id:"_32-spark是如何进行任务切分的-请说明其中涉及到的相关概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_32-spark是如何进行任务切分的-请说明其中涉及到的相关概念"}},[s._v("#")]),s._v(" 32. Spark是如何进行任务切分的，请说明其中涉及到的相关概念")]),s._v(" "),t("ul",[t("li",[s._v("应用：一个spark程序就是一个应用，一个应用可以有多个job。")]),s._v(" "),t("li",[s._v("job作业：触发一次action算子就是一次job，一个job可以有多个stage。")]),s._v(" "),t("li",[s._v("stage阶段：宽依赖切分不同的stage，stage的数量=宽依赖数量+1。一个stage可以有多个task。")]),s._v(" "),t("li",[s._v("task任务：每个stage的最后一个RDD的分区数量=task的数量。")])])])}),[],!1,null,null,null);a.default=r.exports}}]);